| **Name**                                                   | **Tasks**                                                                                         | **Input types**                                       | **Encoding Representation**                                                | **Decoding Modality** | **Output types**                   | **Representation**                                          | **Latent Space**          | **Datasets Size**                                                                      | **Training / Testing Distribution**                                                                                                                        | **Dataset Source**                                     | **Techniques and Features**                                                                           | **Architecture Base**                  | **Layers**                                                                                      | **Output Evaluation Methods**                                                                     | **Evaluation Comparison**                           | **Type Designer Involvement as expert** |
| ---------------------------------------------------------- | ------------------------------------------------------------------------------------------------- | ----------------------------------------------------- | -------------------------------------------------------------------------- | --------------------- | ---------------------------------- | ----------------------------------------------------------- | ------------------------- | -------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ | ----------------------------------------------------------------------------------------------------- | -------------------------------------- | ----------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- | --------------------------------------------------- | --------------------------------------- |
| **VecFusion**                                              | interpolation, completion                                                                         | Raster images of glyphs                               | Cascaded diffusion model with vector diffusion                             | Sequential            | Vector glyphs                      | Mixed discrete-continuous representation for control points | Not specified             | 1,424 fonts, 577 distinct Unicode glyphs                                               | Train: 314K glyphs, Val: 5K glyphs, Test: 5K glyphs                                                                                                        | Google Fonts                                           | Cascaded diffusion model, Mixed discrete-continuous representation, Transformer-based vector model    | Transformer-based                      | 8 Transformer layers                                                                            | L1, Chamfer Distance (CD), Control point difference (#cp diff), Vector path difference (#vp diff) | ChiroDiff, DeepVecFont-v2                           | No                                      |
| **VQ-font**                                                | completion                                                                                        | Raster images of glyphs                               | Similarity-guided global style and quantization local style representation | Sequential            | Font glyphs                        | Discrete latent codes for component-level styles            | Not specified             | 386 Chinese fonts, 3,500 characters each                                               | Train: 370 fonts, 3,000 characters each; Test: 15 unseen fonts, 3,000 seen characters each, 15 unseen fonts, 500 unseen characters each                    | Custom dataset                                         | Global and local style aggregation, Cross-attention-based style transfer, GAN-based training          | GAN and VQ-VAE                         | 3 Transformer layers for cross-attention, 8 attention heads                                     | SSIM, RMSE, LPIPS, FID, User Study                                                                | FUNIT, MX-Font, LF-Font, DG-Font, AGIS-net, FS-Font | No                                      |
| **Joint Implicit Neural Representation**                   | interpolation                                                                                     | Pixelated font images                                 | Joint neural representation using SDF and probabilistic corner field (CF)  | Sequential            | Vector fonts                       | Embeddings of SDF and CF                                    | Not specified             | 1,425 fonts, 52 glyphs per font                                                        | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                        | Implicit neural representation, Corner field modeling, Dual contouring for vectorization              | HyperNetworks-based                    | Multi-layer perceptrons (MLPs) for SDF and CF networks                                          | L1 error, SSIM, s-mIoU                                                                            | Im2Vec, Multi-Implicit, DeepVecFont, Attr2Font      | No                                      |
| **Towards Diverse and Consistent Typography Generation**   | style transfer                                                                                    | Graphic documents with text elements                  | Autoregressive Transformer with attention mechanism                        | Sequential            | Typographic designs                | Fine-grained typographic attributes                         | Not specified             | 23,475 design templates                                                                | Train: 18,780, Test: 2,347, Val: 2,347                                                                                                                     | Crello dataset                                         | Structure-preserved sampling, Fine-grained attribute generation, Consistency and diversity in styling | Transformer-based                      | 8 Transformer blocks                                                                            | Attribute metrics (accuracy, MAE, color difference), Structure score, Diversity score             | CanvasVAE, MFC                                      | No                                      |
| **DualVector**                                             | interpolation, font completion                                                                    | Glyph images                                          | Joint vector and pixel representation                                      | Sequential            | Vector glyphs                      | Dual-part vector representation                             | Shared between modalities | Public datasets: 1,425 fonts, 52 glyphs per font                                       | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                        | Dual-part representation, Differentiable rendering, Contour refinement, UDF initialization            | Transformer-based                      | Encoder: CNN + Transformer (6 layers), Decoder: Transformer + MLP                               | SSIM, L1, s-IoU, LPIPS                                                                            | DeepVecFont, Im2Vec, Multi-Implicits                | No                                      |
| **Contour Completion by Transformers**                     | contour completion                                                                                | Contour sequences with missing points                 | Sequence embedding                                                         | Sequence-to-sequence  | Completed contour sequences        | 5D vectors (x, y, Contour ID, Point ID, curve flag)         | Not specified             | Google Fonts: 489 Serif, 1,275 Sans-Serif, 327 Display, 91 Handwriting                 | Train: 1,777 fonts, Val: 200 fonts, Test: 205 fonts                                                                                                        | Google Fonts                                           | Multi-task learning, Loss functions for contour, point, coordinate, and flags                         | Transformer-based                      | 4 Transformer layers (Encoder & Decoder)                                                        | L1 distance, Hausdorff distance                                                                   | Standard Transformer-Encoder                        | No                                      |
| **DeepVecFont-v2**                                         | interpolation, font completion                                                                    | Raster images and vector outlines                     | Relaxation representation for vector outlines                              | Sequence-to-sequence  | Vector glyphs                      | Embeddings of drawing commands and coordinates              | Not specified             | English: 8,035 fonts, Chinese: 212 fonts                                               | Train: 8,035 (EN), 212 (CN), Test: 1,425 (EN), 34 (CN)                                                                                                     | Google Fonts                                           | Transformer encoder-decoder, Bezier curve alignment, Self-refinement                                  | Transformer-based                      | 6 Transformer layers                                                                            | Reconstruction errors (L1), IoU, Bezier curve alignment loss                                      | DeepSVG, DeepVecFont                                | No                                      |
| **VecFontSDF**                                             | style transfer                                                                                    | Raster images of glyphs                               | Spatial representation                                                     | Sequential            | Font glyphs                        | Signed Distance Function (SDF)                              | Multi-scale               | Google Fonts: 143K glyph images                                                        | Train: 90%, Test: 10%                                                                                                                                      | Google Fonts                                           | SDF rendering, Style transfer, Multi-scale feature extraction                                         | CNN-based                              | 16 convolutional layers                                                                         | MSE, SSIM, FID                                                                                    | DeepSVG, Im2vec, DeepVecFont                        | No                                      |
| **DS-Font**                                                | Font completion                                                                                   | Raster images of glyphs                               | Style representation through multi-layer style projector (MSP)             | Sequential            | Font glyphs                        | Embeddings of style codes                                   | Not specified             | 1,425 fonts, 52 glyphs per font                                                        | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                        | Multi-layer style projector (MSP), multi-task patch discriminator, contrastive learning               | GAN-based                              | Multi-layer style projector, multi-task patch discriminator, generator with attention mechanism | L1 loss, LPIPS, RMSE, Acc(C), Acc(S), FID(C), FID(S)                                              | LF-Font, MX-Font, DG-Font, FTransGAN, MF-Net        | No                                      |
| **SVGformer**                                              | Reconstruction, Classification, Interpolation, Retrieval                                          | Continuous SVG commands                               | Sequential and Geometric representation                                    | Sequential            | Vector graphics (SVGs)             | Embeddings of continuous commands and geometric information | Not specified             | Google Fonts, Icons dataset: Size not specified                                        | Not specified                                                                                                                                              | Google Fonts, Icons datasets                           | Geometric self-attention, Graph convolutional network (GCN), Continuous value embedding               | Transformer-based                      | Encoder: Multiple geometric self-attention modules, Decoder: Multi-head attention               | Chamfer distance (CD), Cross-entropy (CE)                                                         | DeepSVG, LayoutTransformer                          | No                                      |
| **Character-Aware Models Improve Visual Text Rendering**   | Text rendering, Spelling                                                                          | Text inputs (character-level and token-level)         | Character-aware and character-blind representations                        | Sequential            | Visual text rendering in images    | Token and character embeddings                              | Not specified             | Not specified                                                                          | Train: 500,000 steps, Test: Not specified                                                                                                                  | Laion-400M                                             | Character-aware and character-blind text encoders, Hybrid models, Pretraining                         | T5, ByT5, Concat(T5-XXL, ByT5-Small)   | Multiple layers (sizes not specified)                                                           | OCR-based metrics (accuracy), Human ratings                                                       | Imagen, Stable Diffusion, Parti                     | No                                      |
| **GAS-NeXt**                                               | Few-shot cross-lingual font generation                                                            | Raster images and style reference images              | Layer attention and context-aware attention                                | Sequential            | Stylized glyph images              | Encoded style and content features                          | Not specified             | Li et al. dataset                                                                      | Train: 90%, Test: 10%                                                                                                                                      | Li et al. dataset, Azadi et al. dataset, CASIA dataset | Layer attention, Context-aware attention, Local discriminator                                         | AGIS-Net and Font Translator GAN based | Encoder: 6 convolutional layers, Decoder: 6 deconvolutional layers                              | FID, SSIM, Pixel-level Accuracy                                                                   | Font Translator GAN, AGIS-Net                       | No                                      |
| **Diff-Font**                                              | font completion                                                                                   | Raster images of glyphs                               | Gaussian noise representation                                              | Sequential            | Font glyphs                        | Character attributes embedding (content, stroke, style)     | Not specified             | Small: 1,000 Chinese characters, Large: 3,755 Chinese characters                       | Train: 80%, Test: 20%                                                                                                                                      | Custom dataset                                         | Diffusion model, Stroke-wise information                                                              | UNet-based DDPM                        | Multi-scale U-Net layers                                                                        | SSIM, RMSE, LPIPS, FID                                                                            | FUNIT, MX-Font, DG-Font                             | No                                      |
| **Neural Font Rendering**                                  | Reconstruction, Interpolation                                                                     | Vector glyph outlines                                 | Implicit neural representation                                             | Sequential            | Rasterized glyphs at various sizes | Implicit functions                                          | Not specified             | Not specified                                                                          | Not specified                                                                                                                                              | Custom dataset                                         | Implicit neural representation, Frequency encoding, Batch normalization adaptations                   | U-Net-based, Implicit model            | Encoder-decoder with multiple layers, Implicit model with 5 layers                              | L2 pixelwise loss, Focal loss                                                                     | Comparison between masked MLP and implicit model    | No                                      |
| **Font Representation Learning via Paired-glyph Matching** | Font retrieval, Style transfer, Completion                                                        | Glyph images                                          | Paired-glyph matching learning                                             | Sequential            | Font embeddings                    | Embeddings of glyph representations                         | Not specified             | O’Donovan: 1,088 fonts, Capitals64: 10,682 fonts, Open Font Library (OFL): 3,802 fonts | O’Donovan: Train: 1,088 fonts, Val: 28 fonts, Capitals64: Train: 7,649 fonts, Val: 1,473 fonts, Test: 1,560 fonts, OFL: Train: 3,702 fonts, Val: 100 fonts | O’Donovan dataset, Capitals64, OFL                     | Paired-glyph matching, Cross-entropy loss, L1 loss, Contrastive learning                              | ResNet18-based                         | ResNet18 backbone, additional layers for projection head                                        | Retrieval mean accuracy (MACC_Ret), Font attribute prediction (L1-error)                          | Classification, Style Transfer, Autoencoder         | No                                      |
| **FS-Font**                                                | Font completion                                                                                   | Raster images of glyphs                               | Fine-grained local style representation through cross-attention            | Sequential            | Stylized glyph images              | Fine-grained local style representation (FLS)               | Not specified             | 407 fonts, 3,396 characters                                                            | Train: 397 fonts, 2,896 characters, Test: 10 fonts, 500 unseen characters (UFUC), 2,896 seen characters (UFSC)                                             | Custom dataset                                         | Cross-attention based style aggregation, Self-reconstruction branch, Reference selection strategy     | Convolutional and Residual Blocks      | Multiple convolutional and residual layers                                                      | L1 loss, RMSE, SSIM, LPIPS, User Study                                                            | FUNIT, DG-Font, MX-Font, AGIS-net, LF-Font          | No                                      |
| **GenText**                                                | text effect transfer, font transfer, stylisation, text interpolation, text instance style editing | Content images, font images, texture reference images | Spatial and global code representation                                     | Sequence-to-sequence  | Artistic text images               | Embeddings (spatial and global code)                        | Not specified             | Artistic text benchmarks (e.g., TE141K)                                                | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                        | GAN, unsupervised learning, stylization and destylization                                             | Encoder-decoder GAN                    | 4 downsampling residual blocks, 2 convolution layers                                            | PSNR, SSIM, Perceptual loss, Style loss                                                           | AdaIN, Dpatch, NCE, CycleGAN                        | No                                      |
| **SVGVecFont**                                             | interpolation, completion                                                                         | SVG vector graphics                                   | Sequence-to-sequence                                                       | Sequence-to-sequence  | Vector glyphs                      | Commands and Coordinates                                    | Not specified             | Chinese: 407 fonts, 3396 characters                                                    | Train: 397 fonts, Test: 10 fonts                                                                                                                           | Public datasets                                        | Transformer encoder-decoder, Style Aggregation Module                                                 | Transformer-based                      | Multi-head projection, Self-reconstruction branch                                               | L1 loss, Adversarial loss, SSIM, LPIPS, FID                                                       | DeepVecFont, Diff-Font, GAS-NeXt                    | No                                      |
| **Font Generation with Missing Impression Labels** | Font generation, Style transfer | Raster images of glyphs | Conditional GAN with missing label handling | Sequential | Font glyphs | Impression label embeddings | Not specified | MyFonts: 17,202 fonts, 1,430 impression labels | Train: 90%, Test: 10% | MyFonts dataset | Co-occurrence-based missing label estimator, Impression label space compressor, Style consistency discriminator | GAN-based | Progressive GAN with auxiliary classifiers | FID, Intra-FID, mAP-train, mAP-test | C-GAN+, AC-GAN+, CP-GAN+, Imp2Font | No |

