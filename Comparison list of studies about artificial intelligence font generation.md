| **Name**                              | Bib                                          | **Tasks**                                                                           | **Input types**                                       | **Encoding Representation**                                                         | **Decoding Modality**                               | **Output types**                                 | **Representation**                                          | **Latent Space**                                            | **Datasets Size**                                                                                                                                                 | **Training / Testing Distribution**                                                                                                                        | **Dataset Source**                                                                                       | **Techniques and Features**                                                                                               | **Architecture Base**                         | **Layers**                                                                                         | **Output Evaluation Methods**                                                                                                               | **Evaluation Comparison**                                                                | **Type Designer Involvement as expert** |
| ------------------------------------- | -------------------------------------------- | ----------------------------------------------------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------------------- | --------------------------------------------------- | ------------------------------------------------ | ----------------------------------------------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------- | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | --------------------------------------- |
| **VecFusion**                         | [@vikasthamizharasanVecFusionVectorFont2023] | interpolation, completion                                                           | Raster images of glyphs                               | Cascaded diffusion model with vector diffusion                                      | Sequential                                          | Vector glyphs                                    | Mixed discrete-continuous representation for control points | Not specified                                               | 1,424 fonts, 577 distinct Unicode glyphs                                                                                                                          | Train: 314K glyphs, Val: 5K glyphs, Test: 5K glyphs                                                                                                        | Google Fonts                                                                                             | Cascaded diffusion model, Mixed discrete-continuous representation, Transformer-based vector model                        | Transformer-based                             | 8 Transformer layers                                                                               | L1, Chamfer Distance (CD), Control point difference (#cp diff), Vector path difference (#vp diff)                                           | ChiroDiff, DeepVecFont-v2                                                                | No                                      |
| **VQ-font**                           | [@VQFontFewShot2023]                         | Font completion                                                                     | Raster images of glyphs                               | Similarity-guided global style and quantization local style representation          | Sequential                                          | Font glyphs                                      | Discrete latent codes for component-level styles            | Not specified                                               | 386 Chinese fonts, 3,500 characters each                                                                                                                          | Train: 370 fonts, 3,000 characters each; Test: 15 unseen fonts, 3,000 seen characters each, 15 unseen fonts, 500 unseen characters each                    | Custom dataset                                                                                           | Global and local style aggregation, Cross-attention-based style transfer, GAN-based training                              | GAN and VQ-VAE                                | 3 Transformer layers for cross-attention, 8 attention heads                                        | SSIM, RMSE, LPIPS, FID, User Study                                                                                                          | FUNIT, MX-Font, LF-Font, DG-Font, AGIS-net, FS-Font                                      | No                                      |
| **Joint Implicit Neural**             | [@JointImplicitJointImplicit2023]            | interpolation                                                                       | Pixelated font images                                 | Joint neural representation using SDF and probabilistic corner field (CF)           | Sequential                                          | Vector fonts                                     | Embeddings of SDF and CF                                    | Not specified                                               | 1,425 fonts, 52 glyphs per font                                                                                                                                   | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | Implicit neural representation, Corner field modeling, Dual contouring for vectorization                                  | HyperNetworks-based                           | Multi-layer perceptrons (MLPs) for SDF and CF networks                                             | L1 error, SSIM, s-mIoU                                                                                                                      | Im2Vec, Multi-Implicit, DeepVecFont, Attr2Font                                           | No                                      |
| **Consistent Typography Generation**  | [@DiverseConsistentTypography2023]           | style transfer                                                                      | Graphic documents with text elements                  | Autoregressive Transformer with attention mechanism                                 | Sequential                                          | Typographic designs                              | Fine-grained typographic attributes                         | Not specified                                               | 23,475 design templates                                                                                                                                           | Train: 18,780, Test: 2,347, Val: 2,347                                                                                                                     | Crello dataset                                                                                           | Structure-preserved sampling, Fine-grained attribute generation, Consistency and diversity in styling                     | Transformer-based                             | 8 Transformer blocks                                                                               | Attribute metrics (accuracy, MAE, color difference), Structure score, Diversity score                                                       | CanvasVAE, MFC                                                                           | No                                      |
| **DualVector**                        | [@DualVectorUnsupervisedVector2023]          | interpolation, font completion                                                      | Glyph images                                          | Joint vector and pixel representation                                               | Sequential                                          | Vector glyphs                                    | Dual-part vector representation                             | Shared between modalities                                   | Public datasets: 1,425 fonts, 52 glyphs per font                                                                                                                  | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | Dual-part representation, Differentiable rendering, Contour refinement, UDF initialization                                | Transformer-based                             | Encoder: CNN + Transformer (6 layers), Decoder: Transformer + MLP                                  | SSIM, L1, s-IoU, LPIPS                                                                                                                      | DeepVecFont, Im2Vec, Multi-Implicits                                                     | No                                      |
| **Contour Completion**                | [@ContourCompletionTransformers2023]         | contour completion                                                                  | Contour sequences with missing points                 | Sequence embedding                                                                  | Sequence-to-sequence                                | Completed contour sequences                      | 5D vectors (x, y, Contour ID, Point ID, curve flag)         | Not specified                                               | Google Fonts: 489 Serif, 1,275 Sans-Serif, 327 Display, 91 Handwriting                                                                                            | Train: 1,777 fonts, Val: 200 fonts, Test: 205 fonts                                                                                                        | Google Fonts                                                                                             | Multi-task learning, Loss functions for contour, point, coordinate, and flags                                             | Transformer-based                             | 4 Transformer layers (Encoder & Decoder)                                                           | L1 distance, Hausdorff distance                                                                                                             | Standard Transformer-Encoder                                                             | No                                      |
| **DeepVecFont-v2**                    | [@DeepVecFontv2ExploitingTransformers2023]   | interpolation, font completion                                                      | Raster images and vector outlines                     | Relaxation representation for vector outlines                                       | Sequence-to-sequence                                | Vector glyphs                                    | Embeddings of drawing commands and coordinates              | Not specified                                               | English: 8,035 fonts, Chinese: 212 fonts                                                                                                                          | Train: 8,035 (EN), 212 (CN), Test: 1,425 (EN), 34 (CN)                                                                                                     | Google Fonts                                                                                             | Transformer encoder-decoder, Bezier curve alignment, Self-refinement                                                      | Transformer-based                             | 6 Transformer layers                                                                               | Reconstruction errors (L1), IoU, Bezier curve alignment loss                                                                                | DeepSVG, DeepVecFont                                                                     | No                                      |
| **VecFontSDF**                        | [@VecFontSDFLearningReconstruct2023]         | style transfer                                                                      | Raster images of glyphs                               | Spatial representation                                                              | Sequential                                          | Font glyphs                                      | Signed Distance Function (SDF)                              | Multi-scale                                                 | Google Fonts: 143K glyph images                                                                                                                                   | Train: 90%, Test: 10%                                                                                                                                      | Google Fonts                                                                                             | SDF rendering, Style transfer, Multi-scale feature extraction                                                             | CNN-based                                     | 16 convolutional layers                                                                            | MSE, SSIM, FID                                                                                                                              | DeepSVG, Im2vec, DeepVecFont                                                             | No                                      |
| **DS-Font**                           | [@DSFontFewshotFont2023]                     | Font completion                                                                     | Raster images of glyphs                               | Style representation through multi-layer style projector (MSP)                      | Sequential                                          | Font glyphs                                      | Embeddings of style codes                                   | Not specified                                               | 1,425 fonts, 52 glyphs per font                                                                                                                                   | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | Multi-layer style projector (MSP), multi-task patch discriminator, contrastive learning                                   | GAN-based                                     | Multi-layer style projector, multi-task patch discriminator, generator with attention mechanism    | L1 loss, LPIPS, RMSE, Acc(C), Acc(S), FID(C), FID(S)                                                                                        | LF-Font, MX-Font, DG-Font, FTransGAN, MF-Net                                             | No                                      |
| **SVGformer**                         | [@SVGformerRepresentationLearning2023]       | Reconstruction, Classification, Interpolation, Retrieval                            | Continuous SVG commands                               | Sequential and Geometric representation                                             | Sequential                                          | Vector graphics (SVGs)                           | Embeddings of continuous commands and geometric information | Not specified                                               | Google Fonts, Icons dataset: Size not specified                                                                                                                   | Not specified                                                                                                                                              | Google Fonts, Icons datasets                                                                             | Geometric self-attention, Graph convolutional network (GCN), Continuous value embedding                                   | Transformer-based                             | Encoder: Multiple geometric self-attention modules, Decoder: Multi-head attention                  | Chamfer distance (CD), Cross-entropy (CE)                                                                                                   | DeepSVG, LayoutTransformer                                                               | No                                      |
| **Character-Aware**                   | [@CharacterAwareModelsImprove2022]           | Text rendering, Spelling                                                            | Text inputs (character-level and token-level)         | Character-aware and character-blind representations                                 | Sequential                                          | Visual text rendering in images                  | Token and character embeddings                              | Not specified                                               | Not specified                                                                                                                                                     | Train: 500,000 steps, Test: Not specified                                                                                                                  | Laion-400M                                                                                               | Character-aware and character-blind text encoders, Hybrid models, Pretraining                                             | T5, ByT5, Concat(T5-XXL, ByT5-Small)          | Multiple layers (sizes not specified)                                                              | OCR-based metrics (accuracy), Human ratings                                                                                                 | Imagen, Stable Diffusion, Parti                                                          | No                                      |
| **GAS-NeXt**                          | [@GASNeXtFewShotCrossLingual2022]            | Few-shot cross-lingual font generation                                              | Raster images and style reference images              | Layer attention and context-aware attention                                         | Sequential                                          | Stylized glyph images                            | Encoded style and content features                          | Not specified                                               | Li et al. dataset                                                                                                                                                 | Train: 90%, Test: 10%                                                                                                                                      | Li et al. dataset, Azadi et al. dataset, CASIA dataset                                                   | Layer attention, Context-aware attention, Local discriminator                                                             | AGIS-Net and Font Translator GAN based        | Encoder: 6 convolutional layers, Decoder: 6 deconvolutional layers                                 | FID, SSIM, Pixel-level Accuracy                                                                                                             | Font Translator GAN, AGIS-Net                                                            | No                                      |
| **Diff-Font**                         | [@DiffFontDiffusionModel2022]                | font completion                                                                     | Raster images of glyphs                               | Gaussian noise representation                                                       | Sequential                                          | Font glyphs                                      | Character attributes embedding (content, stroke, style)     | Not specified                                               | Small: 1,000 Chinese characters, Large: 3,755 Chinese characters                                                                                                  | Train: 80%, Test: 20%                                                                                                                                      | Custom dataset                                                                                           | Diffusion model, Stroke-wise information                                                                                  | UNet-based DDPM                               | Multi-scale U-Net layers                                                                           | SSIM, RMSE, LPIPS, FID                                                                                                                      | FUNIT, MX-Font, DG-Font                                                                  | No                                      |
| **Neural Font Rendering**             | [@NeuralFontRendering2022]                   | Reconstruction, Interpolation                                                       | Vector glyph outlines                                 | Implicit neural representation                                                      | Sequential                                          | Rasterized glyphs at various sizes               | Implicit functions                                          | Not specified                                               | Not specified                                                                                                                                                     | Not specified                                                                                                                                              | Custom dataset                                                                                           | Implicit neural representation, Frequency encoding, Batch normalization adaptations                                       | U-Net-based, Implicit model                   | Encoder-decoder with multiple layers, Implicit model with 5 layers                                 | L2 pixelwise loss, Focal loss                                                                                                               | Comparison between masked MLP and implicit model                                         | No                                      |
| **Paired-glyph**                      | [@FontRepresentationLearning2022]            | Font retrieval, Style transfer, Completion                                          | Glyph images                                          | Paired-glyph matching learning                                                      | Sequential                                          | Font embeddings                                  | Embeddings of glyph representations                         | Not specified                                               | O’Donovan: 1,088 fonts, Capitals64: 10,682 fonts, Open Font Library (OFL): 3,802 fonts                                                                            | O’Donovan: Train: 1,088 fonts, Val: 28 fonts, Capitals64: Train: 7,649 fonts, Val: 1,473 fonts, Test: 1,560 fonts, OFL: Train: 3,702 fonts, Val: 100 fonts | O’Donovan dataset, Capitals64, OFL                                                                       | Paired-glyph matching, Cross-entropy loss, L1 loss, Contrastive learning                                                  | ResNet18-based                                | ResNet18 backbone, additional layers for projection head                                           | Retrieval mean accuracy (MACC_Ret), Font attribute prediction (L1-error)                                                                    | Classification, Style Transfer, Autoencoder                                              | No                                      |
| **FS-Font**                           | [@FSFontFewShotFont2022]                     | Font completion                                                                     | Raster images of glyphs                               | Fine-grained local style representation through cross-attention                     | Sequential                                          | Stylized glyph images                            | Fine-grained local style representation (FLS)               | Not specified                                               | 407 fonts, 3,396 characters                                                                                                                                       | Train: 397 fonts, 2,896 characters, Test: 10 fonts, 500 unseen characters (UFUC), 2,896 seen characters (UFSC)                                             | Custom dataset                                                                                           | Cross-attention based style aggregation, Self-reconstruction branch, Reference selection strategy                         | Convolutional and Residual Blocks             | Multiple convolutional and residual layers                                                         | L1 loss, RMSE, SSIM, LPIPS, User Study                                                                                                      | FUNIT, DG-Font, MX-Font, AGIS-net, LF-Font                                               | No                                      |
| **GenText**                           | [@GenTextUnsupervisedArtistic2022]           | text effect transfer, font style transfer, image style transfer, font interpolation | Content images, font images, texture reference images | Spatial and global code representation                                              | Sequence-to-sequence                                | Artistic text images                             | Embeddings (spatial and global code)                        | Not specified                                               | Artistic text benchmarks (e.g., TE141K)                                                                                                                           | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | GAN, unsupervised learning, stylization and destylization                                                                 | Encoder-decoder GAN                           | 4 downsampling residual blocks, 2 convolution layers                                               | PSNR, SSIM, Perceptual loss, Style loss                                                                                                     | AdaIN, Dpatch, NCE, CycleGAN                                                             | No                                      |
| **SVGVecFont**                        | [@SVGVecFontSVGVector2022]                   | interpolation, completion                                                           | SVG vector graphics                                   | Sequence-to-sequence                                                                | Sequence-to-sequence                                | Vector glyphs                                    | Commands and Coordinates                                    | Not specified                                               | Chinese: 407 fonts, 3396 characters                                                                                                                               | Train: 397 fonts, Test: 10 fonts                                                                                                                           | Public datasets                                                                                          | Transformer encoder-decoder, Style Aggregation Module                                                                     | Transformer-based                             | Multi-head projection, Self-reconstruction branch                                                  | L1 loss, Adversarial loss, SSIM, LPIPS, FID                                                                                                 | DeepVecFont, Diff-Font, GAS-NeXt                                                         | No                                      |
| **Impression Labels**                 | [@FontGenerationMissing2022]                 | Style transfer                                                                      | Raster images of glyphs                               | Conditional GAN with missing label handling                                         | Sequential                                          | Font glyphs                                      | Impression label embeddings                                 | Not specified                                               | MyFonts: 17,202 fonts, 1,430 impression labels                                                                                                                    | Train: 90%, Test: 10%                                                                                                                                      | MyFonts dataset                                                                                          | Co-occurrence-based missing label estimator, Impression label space compressor, Style consistency discriminator           | GAN-based                                     | Progressive GAN with auxiliary classifiers                                                         | FID, Intra-FID, mAP-train, mAP-test                                                                                                         | C-GAN+, AC-GAN+, CP-GAN+, Imp2Font                                                       | No                                      |
| **FontNet**                           | [@FontNetClosingGap2022]                     | font style transfer, font completion                                                | Font images                                           | Embedding                                                                           | Adversarial generation                              | High-resolution font images                      | Embeddings of style and content features                    | Style embedding space                                       | 90 Korean fonts, 2,350 characters                                                                                                                                 | Train: 75% fonts, Test: 25% fonts                                                                                                                          | Naver Fonts                                                                                              | StyleGAN, Separator network, Triplet loss                                                                                 | StyleGAN-based                                | Encoder-Decoder with separator network                                                             | SSIM, mFID, Top-1 accuracy                                                                                                                  | MX-Font, FUNIT                                                                           | No                                      |
| **SE-GAN**                            | [@SEGANSkeletonEnhanced2022]                 | style transfer                                                                      | Raster images of brush handwriting                    | Spatial representation                                                              | Sequential                                          | Font glyphs                                      | Skeleton-based representation                               | Multi-scale                                                 | Custom dataset: 15,799 high-resolution images                                                                                                                     | Train: 80%, Dev: 10%, Test: 10%                                                                                                                            | Custom dataset                                                                                           | GAN-based model, Self-attentive Refined Attention Module (SAttRAM), skeleton discriminator                                | GAN-based                                     | 4 residual blocks for each encoder, 2 discriminators                                               | Content accuracy, FID, User preference                                                                                                      | zi2zi, CycleGAN, StarGAN, DF-Font                                                        | Yes                                     |
| **Arbitrary Font Generation**         | [@ArbitraryFontGeneration2022]               | style transfer                                                                      | Raster images of fonts                                | Spatial representation                                                              | Sequential                                          | Font images                                      | Disentangled features of text content and font style        | N/A                                                         | Korean: 238 train, 40 test; Chinese: 185 train, 15 test; English: 185 train, 15 test                                                                              | Train: 85%, Test: 15%                                                                                                                                      | Noonnu, Internet, Chinese Font Design                                                                    | Stacked input, Consistency loss, VGG-19, AdaIN, Hallucinated stack                                                        | VGG-19 based                                  | VGG-19 layers, AdaIN layers, ConvBlock layers                                                      | FID, L1 distance, Perceptual distance                                                                                                       | FUNIT, EMD                                                                               | No                                      |
| **CVFont**                            | [@CVFontSynthesizingChinese2022]             | style transfer                                                                      | Raster images of glyphs                               | Hierarchical approach to component extraction, using CPD algorithm for registration | Sequential                                          | Chinese vector fonts                             | Components and strokes                                      | Multi-scale                                                 | GB2312 Kaiti font library (6763 characters), 70 Chinese fonts                                                                                                     | Pre-train: 60 fonts, Online: 10 fonts, Testing: 69 fonts                                                                                                   | Founder Group                                                                                            | Layout prediction with Faster R-CNN, U-Net based generator, Skeleton extraction, Shape decomposition                      | ResNet-101 + U-Net                            | ResNet-101 backbone, U-Net generator with 3 downsampling layers, Faster R-CNN detector             | IoU scores, Qualitative user study                                                                                                          | Rewrite, pix2pix, CycleGAN, EasyFont, zi2zi                                              | Yes                                     |
| **XMP-Font**                          | [@XMPFontSelfSupervisedCrossModality2022]    | Font completion                                                                     | Glyph images, stroke labels                           | Cross-modality representation                                                       | Cross-modality                                      | Glyphs                                           | Stroke-level, component-level, character-level styles       | Pre-trained with self-supervised signals                    | 100 font styles                                                                                                                                                   | Train: 90%, Test: 10%                                                                                                                                      | Founder font libraries                                                                                   | Cross-modality transformer-based encoder, ECA modules, LSTM-based stroke loss                                             | Transformer-based                             | Cross-modality encoder with BERT layers, 4 ECA modules                                             | FID, PSNR, SSIM, L1, User study                                                                                                             | StarGAN-v2, FUNIT, LF-Font, MX-Font, DG-Font                                             | No                                      |
| **Noisy Impressions**                 | [@SharedLatentSpace2022]                     | Cross-modal: shape-to-impression, impression-to-shape                               | Glyph images, impression words                        | Shared latent space representation                                                  | Cross-modal                                         | Glyph images, impression words                   | Vector representations for font shapes and impression words | Shared latent space with DeepSets                           | MyFonts: 18,815 fonts                                                                                                                                             | Train: 9,980, Validation: 2,992, Test: 1,223                                                                                                               | MyFonts dataset                                                                                          | DeepSets for shape-relevant impression filtering, cross-modal autoencoders                                                | Autoencoder, ResNet18-based encoder           | ResNet18 encoder, deconvolutional layers for decoder                                               | Precision@K, average retrieval rank, Hausdorff distance                                                                                     | Impressions2Font                                                                         | No                                      |
| **CKFont**                            | [@CKFontFewShotKorean2021]                   | Font completion                                                                     | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyphs                                           | Character-level styles                                      | Pre-trained with self-supervised signals                    | 2,350 glyphs                                                                                                                                                      | Train: 2,000, Test: 350                                                                                                                                    | Hangul standard code system (KS X 1001)                                                                  | Conditional GAN, dual encoders, style extraction from components                                                          | GAN-based                                     | 6 convolutional layers in each encoder, 6 deconvolutional layers in the decoder                    | L1, L2, SSIM, FID                                                                                                                           | zi2zi, SKFont                                                                            | No                                      |
| **Dual Latent Manifolds**             | [@ScalableFontReconstruction2021]            | Reconstruction                                                                      | Glyph images                                          | Dual latent manifolds representation                                                | Matrix factorization                                | Glyph images                                     | Vector representations for font style and character shape   | Dual latent spaces with Gaussian priors                     | Google Fonts: 2017 fonts, Chinese Simplified: 623 fonts                                                                                                           | Train: 60%, Dev: 20%, Test: 20%                                                                                                                            | Google Fonts, Chinese Simplified dataset                                                                 | Dual manifold model, adaptive wavelet loss, U-Net architecture                                                            | U-Net-based                                   | Encoder: convolutional layers, Decoder: transposed convolutional layers with MLP parameters        | SSIM, L2, Human evaluation (Amazon Mechanical Turk)                                                                                         | EMD, Nearest Neighbor                                                                    | No                                      |
| **ZiGAN**                             | [@ZiGANFinegrainedChinese2021]               | Style transfer                                                                      | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyphs                                           | Character-level styles                                      | Learned correlation between structures of different styles  | 61,151 images, 6560 characters                                                                                                                                    | Train: 100 or 200 shots, Test: remaining images                                                                                                            | Chinese calligraphy character website                                                                    | GAN-based, CAM attention module, CycleGAN                                                                                 | GAN-based                                     | Encoder: 8 convolutional layers, Decoder: 8 deconvolutional layers                                 | FID, IOU, Top-1 Accuracy, User study                                                                                                        | zi2zi, pix2pix, U-GAT-IT, CycleGAN, StarGAN, CalliGAN                                    | No                                      |
| **DeepVecFont**                       | [@DeepVecFontSynthesizingHighquality2021]    | Few-shot font generation, interpolation                                             | Raster images, vector outlines                        | Dual-modality representation                                                        | Sequential                                          | Vector glyphs                                    | Image-aspect and sequence-aspect features                   | Latent space with Gaussian priors                           | 8K fonts for training, 1.5K for testing                                                                                                                           | Train: 8K fonts, Test: 1.5K fonts                                                                                                                          | SVG-Fonts Dataset                                                                                        | Dual-modality learning, differentiable rasterization, Mixture Density Network                                             | CNN-based, RNN-based                          | Convolutional layers, LSTM layers                                                                  | L1 loss, Perceptual loss, Cross-Entropy loss, MDN loss                                                                                      | SVG-VAE, DeepSVG, Im2Vec                                                                 | No                                      |
| **CycleFont**                         | [@FontCompletionManipulation2021]            | Font completion, interpolation, manipulation                                        | Raster images, SVG curves, point sets                 | Multi-modality representation (image-to-graph-to-image)                             | Multi-modality (graph-based)                        | Glyph images                                     | Graph-based representation                                  | Latent space with graph representation                      | Google Fonts: 2693 fonts, 55,554 glyphs                                                                                                                           | Train: 95%, Test: 5%                                                                                                                                       | Google Fonts dataset                                                                                     | Cross-modality auto-encoder, graph-based representation                                                                   | Graph-based, auto-encoder                     | Image encoder (Conv2D), point set decoder, graph constructor, neural renderer                      | MSE, PSNR, SSIM                                                                                                                             | TCN                                                                                      | No                                      |
| **Implicit Glyph Shape**              | [@LearningImplicitGlyph2021]                 | Font reconstruction, interpolation, style transfer                                  | Raster images                                         | Implicit representation                                                             | Implicit function decoding                          | Glyph images                                     | Signed distance functions with quadratic curves             | Continuous 2D space                                         | 26390 glyph images                                                                                                                                                | Train: 26390 images, Validation: dataset split                                                                                                             | Custom dataset                                                                                           | Implicit representation, quadratic curves, disentangled encoder, auxiliary character classifier                           | CNN-based, ResNet-18                          | ResNet-18 encoder, MLP for curve parameters                                                        | SSIM, LPIPS, L1 distance, User study                                                                                                        | VAE, pix2pix, AGIS-Net, FANnet                                                           | No                                      |
| **Perceptual Manifold of Fonts**      | [@LearningPerceptualManifold2021]            | Font exploration, style transfer                                                    | Raster images                                         | Latent space representation                                                         | Sequential                                          | Glyph images                                     | Perceptual manifolds                                        | Continuous latent space                                     | Google Fonts: 2169 fonts                                                                                                                                          | Train: 90%, Test: 10%                                                                                                                                      | Google Fonts                                                                                             | Variational Autoencoder (VAE), t-SNE for manifold learning, kernel density estimation                                     | VAE-based                                     | Encoder: 4 convolutional layers, Decoder: 2 convolutional layers                                   | SSIM, User study                                                                                                                            | Comparison with traditional font exploration interfaces                                  | Yes                                     |
| **FontRL**                            | [@FontRLChineseFont2021]                     | Font completion                                                                     | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyph images                                     | Stroke-level styles                                         | Deep reinforcement learning with TPS transformations        | 6,763 characters in 5 styles                                                                                                                                      | Train: 775 characters, Test: 5 styles                                                                                                                      | Custom dataset                                                                                           | Deep reinforcement learning, TPS transformation, CNN-based image rendering                                                | ResNet-18, CNN-based                          | Policy network (ResNet-18), BBoxNet (ResNet-34), StyleNet for rendering                            | L1 loss, IoU, User study                                                                                                                    | SCFont, zi2zi, DCFont, FontRNN, pix2pix                                                  | No                                      |
| **LF-Font**                           | [@LFFontFewshotFont2021]                     | Font completion                                                                     | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyphs                                           | Localized style representations, factorization modules      | Factorized component and style factors                      | 19,514 characters                                                                                                                                                 | Train: 467 fonts, Test: 15 fonts                                                                                                                           | Custom collected Chinese fonts                                                                           | Component-wise style encoding, content encoder, factorization modules                                                     | CNN-based                                     | Style encoder, content encoder, generator with 4 convolutional layers                              | LPIPS, Accuracy, FID, User study                                                                                                            | SA-VAE, EMD, AGIS-Net, FUNIT, DM-Font                                                    | No                                      |
| **StrokeGAN**                         | [@StrokeGANReducingMode2021]                 | Style transfer                                                                      | Glyph images                                          | Stroke encoding representation                                                      | Sequential                                          | Glyph images                                     | Stroke-level encoding                                       | CycleGAN with stroke encoding                               | 9 different fonts datasets                                                                                                                                        | Train: 90%, Test: 10%                                                                                                                                      | Custom collected, CASIA-HWDB1.1, Internet                                                                | Stroke encoding, CycleGAN, stroke-encoding reconstruction loss                                                            | CycleGAN-based                                | 2 convolutional layers (down-sampling), 9 residual modules, 2 deconvolutional layers (up-sampling) | Content accuracy, Recognition accuracy, Stroke error                                                                                        | CycleGAN, zi2zi, Chinese Typography Transfer (CTT)                                       | No                                      |
| **DG-Font**                           | [@DGFontDeformableGenerative2021]            | Font completion                                                                     | Raster images of glyphs                               | Spatial representation                                                              | Sequential                                          | Font glyphs                                      | Spatial features and latent vector representations          | Deformable                                                  | Custom dataset: 410 fonts, 990 characters each                                                                                                                    | Train: 400 fonts, 800 chars/font; Test: 10 fonts, 190 chars/font                                                                                           | Custom dataset                                                                                           | Deformable convolution, Feature Deformation Skip Connection (FDSC), AdaIN                                                 | CNN-based                                     | Deformable convolutions, residual blocks, multi-task discriminator                                 | L1 loss, RMSE, SSIM, LPIPS, FID                                                                                                             | CycleGAN, EMD, Zi2zi, GANimorph, FUNIT                                                   | No                                      |
| **Radical Composition Network (RCN)** | [@RadicalCompositionNetwork2021]             | Cross-modal: Caption-to-font                                                        | Caption text, Raster images of radicals               | Sequential                                                                          | Sequential                                          | Chinese character images                         | Embeddings                                                  | Tree-structured                                             | Printed: 114,665 characters; Handwritten: 2,674,784 characters                                                                                                    | Train: 22,933 classes, Test: 4,172 classes                                                                                                                 | Custom dataset                                                                                           | Tree-structured encoder (TRN), DenseNet, Deconvolution, Perceptual loss                                                   | Encoder-decoder (CNN-based)                   | Tree-structured recurrent units, Deconvolution layers                                              | L1 loss, RMSE, SSIM, LPIPS                                                                                                                  | RAN, zi2zi                                                                               | No                                      |
| **SkelGAN**                           | [@SkelGANFontImage2021]                      | Skeletonization and style transfer                                                  | Font images                                           | Spatial representation                                                              | Sequential                                          | Skeletons of font glyphs                         | One-pixel-width skeletons                                   | Multi-scale                                                 | Custom dataset: 70,500 glyph images                                                                                                                               | Train: 90%, Test: 10%                                                                                                                                      | Custom dataset                                                                                           | GANs, Style classification, Character classification, Multi-scale feature extraction                                      | Modified U-Net                                | 14 layers (7 encoder, 7 decoder)                                                                   | SSIM, L1 distance                                                                                                                           | Lee’s method, Pix2pix                                                                    | No                                      |
| **FTransGAN**                         | [@chenhaoFTransGANPyTorch2023]               | style transfer, font completion                                                     | Grayscale images of glyphs                            | Multi-level attention with Context-aware and Layer Attention Networks               | Sequential                                          | Grayscale glyphs                                 | Local and global feature representation                     | Not specified                                               | 847 fonts, each with 52 English letters and ~1000 Chinese characters                                                                                              | Train: 847 fonts, Test: 29 fonts                                                                                                                           | Constructed by authors                                                                                   | Multi-level attention network, Context-aware Attention Network, Layer Attention Network                                   | GAN-based                                     | Encoder-Decoder structure with 3 Conv layers, 6 ResNet blocks, and 3 up-conv layers                | L1 loss, Style loss, Content loss, MAE, SSIM, MS-SSIM, mFID, Top-1 accuracy                                                                 | EMD, DFS                                                                                 | No                                      |
| **DeepSVG**                           | [@DeepSVGHierarchicalGenerative2020]         | interpolation, animation, manipulation                                              | SVG commands                                          | Hierarchical Transformer-based architecture                                         | Non-autoregressive                                  | SVG images                                       | Discrete continuous embedding                               | Not specified                                               | 100,000 high-quality icons                                                                                                                                        | Train/Test split not specified                                                                                                                             | SVG-Icons8, constructed by authors                                                                       | Hierarchical generative network, Non-autoregressive feed-forward model                                                    | Transformer-based                             | 4 layers in encoder and decoder with 512 feed-forward dimension                                    | Chamfer distance, Reconstruction Error (RE), Interpolation Smoothness (IS)                                                                  | One-stage autoregressive, One-stage feed-forward, SVG-VAE                                | No                                      |
| **Font2Fonts**                        | [@Font2FontsModifiedImagetoImage2020]        | style transfer, font completion                                                     | Grayscale images of glyphs                            | Conditional GAN with multi-domain translation                                       | Sequential                                          | Grayscale glyphs                                 | Local and global feature representation                     | Not specified                                               | 20 Korean fonts, 2,350 most commonly used Korean Hangul characters                                                                                                | Train: 75% (15 fonts), Test: 25% (5 fonts)                                                                                                                 | Constructed by authors                                                                                   | Conditional GAN, Multi-domain translation, Unicode-based font dataset generator                                           | GAN-based                                     | 7 down-sampling and 7 up-sampling layers with Instance Normalization                               | L1 loss, GAN loss, Style classification loss, MAE, SSIM                                                                                     | pix2pix                                                                                  | No                                      |
| **CalliGAN**                          | [@CalliGANStyleStructureaware2020]           | style transfer                                                                      | Grayscale images of glyphs                            | Component-based encoder-decoder with multi-domain translation                       | Sequential                                          | Grayscale glyphs                                 | Embedding and component encoding                            | Not specified                                               | 29 calligraphy styles, 47552 images                                                                                                                               | Train: 39815 images, Test: 7737 images                                                                                                                     | Constructed by authors                                                                                   | Component-based encoder, U-Net-based generator, multi-domain translation                                                  | GAN-based                                     | 8 encoder and 8 decoder layers, Component encoder with LSTM                                        | MSE, SSIM, Human subject study                                                                                                              | zi2zi, AEGG                                                                              | No                                      |
| **Attribute2Font**                    | [@Attribute2FontCreatingFonts2020]           | style transfer, interpolation, font completion, editing                             | Glyph images                                          | Hierarchical encoder-decoder with Attribute Attention Module (AAM)                  | Sequential                                          | Glyph images                                     | Attribute embeddings                                        | Not specified                                               | 148 labeled fonts, 968 unlabeled fonts                                                                                                                            | Train: 120 fonts, Val: 28 fonts                                                                                                                            | AttrFont-ENG (O'Donovan et al., 2014)                                                                    | Attribute Attention Module, Semi-supervised learning, Visual Style Transformer                                            | CNN-based encoder-decoder                     | 16 residual blocks, 4 up-sampling layers, AAM                                                      | IS, FID, LPIPS, SSIM, pixel-level accuracy (pix-acc), Hausdorff, Chamfer                                                                    | AttGAN, StarGAN, RelGAN, STGAN, O'Donovan et al., Chen et al.                            | Yes                                     |
| **EmoGAN**                            | [@EmoGanAutomaticChinese2020]                | style transfer, interpolation, font completion                                      | Glyph images                                          | Hierarchical encoder-decoder with Emotion Guidance Module (EGM)                     | Sequential                                          | Glyph images                                     | Emotion embeddings, Style embeddings                        | Not specified                                               | 30 fonts for training, 27 fonts for fine-tuning                                                                                                                   | Train: 27 fonts (1000 chars each), Fine-tune: 6 fonts (3000 chars each)                                                                                    | Questionnaire system (Tencent platform)                                                                  | Emotional Guidance GAN (EG-GAN), EM Distance, Gradient Penalty, Classification loss                                       | CNN-based encoder-decoder                     | Multiple convolutional layers, EGM                                                                 | SSIM, PSNR, evaluation questionnaire                                                                                                        | Zi2Zi, EG-GAN 1 (without Gradient Penalty)                                               | Yes                                     |
| **RD-GAN**                            | [@RDGANFewZeroShot2020]                      | style transfer, interpolation                                                       | Glyph images                                          | Radical decomposition-and-rendering-based GAN                                       | Sequential                                          | Stylized glyph images                            | Radical embeddings, Style embeddings                        | Not specified                                               | 1473 classes with 50 samples each (D1), 5 samples each (D2), 1473 unseen categories (D3)                                                                          | D1: same category in training and test, D2: 5 samples per category, D3: unseen categories                                                                  | TKH Dataset (Tripitaka paragraph images)                                                                 | Radical Extraction Module (REM), Radical Rendering Module (RRM), Multi-level Discriminator (MLD)                          | CNN-based encoder-decoder                     | 2-layer Bi-directional LSTM (BLSTM), convolutional layers, 2D attention mechanism                  | L1 loss, Root Mean Square Error (RMSE), Structural Similarity Index (SSIM)                                                                  | Pix2pix, Cycle-GAN, MC-GAN, Zi2zi, EMD                                                   | No                                      |
| **DM-Font**                           | [@DMFontFewShotCompositional2020]            | font completion, style transfer, interpolation                                      | Images of glyphs                                      | Dual memory-augmented structure                                                     | Sequential                                          | Glyph images                                     | Component-wise encoded features                             | Fixed persistent memory, dynamic memory                     | Korean-handwriting: 86 fonts, 2448 glyphs per font; Thai-printing: 105 fonts                                                                                      | Korean-handwriting: Train 80% fonts, 90% glyphs; Thai-printing: similar split; Korean-unrefined for validation                                             | Korean-handwriting dataset (refined by expert designer), Korean-unrefined dataset, Thai-printing dataset | Dual memory structure, compositional generator, self-attention, global-context block                                      | Dual memory-augmented font generation network | Encoder: multi-head structure; Decoder: hourglass block, multi-task discriminator                  | SSIM, MS-SSIM, perceptual distance (PD), mean FID (mFID), human preference                                                                  | EMD, FUNIT, AGIS-Net                                                                     | No                                      |
| **GlyphGAN**                          | [@GlyphGANStyleconsistentFont2019]           | style transfer, interpolation                                                       | Glyph images                                          | Deep convolutional GAN (DCGAN) architecture                                         | Sequential                                          | Glyph images                                     | Character class vector, Style vector                        | Not specified                                               | 6,561 fonts, 26 uppercase alphabet letters                                                                                                                        | Train: 90%, Test: 10% of 6,561 fonts                                                                                                                       | Self-collected from various sources                                                                      | Wasserstein GAN (WGAN), gradient penalty, DCGAN, character class and style vectors                                        | DCGAN-based                                   | Fractionally strided convolutions, strided convolutions in discriminator                           | Legibility (recognition accuracy), Diversity (pseudo-Hamming distance), Style consistency (Cs metric)                                       | DCGAN, WGAN-Clipping                                                                     | No                                      |
| **AGIS-Net**                          | [@AGISNetArtisticGlyph2019]                  | style transfer, font completion                                                     | Glyph images                                          | Two encoders for content and style, collaborative decoders for shape and texture    | Sequential                                          | Stylized glyph images                            | Disentangled content and style features                     | Not specified                                               | English: 32,046 synthetic artistic fonts, 35 professional-designed fonts; Chinese: 1,571,940 synthetic artistic glyphs, 256,410 glyphs from 35 professional fonts | Train: large-scale dataset for pre-training; Few-shot learning for fine-tuning with English (26 glyphs) and Chinese (7,326 glyphs)                         | Azadi et al. (2018), Guo et al. (2018), Jiang et al. (2017, 2019)                                        | Disentangled content and style, collaborative encoder-decoder architecture, local texture refinement loss                 | GAN (Generative Adversarial Network)          | Six convolution layers and six up-convolution layers in the generator, three discriminators        | Inception Score (IS), Fréchet Inception Distance (FID), structural similarity (SSIM), pixel-level accuracy (pix-acc), user preference study | MC-GAN, TET-GAN, BicycleGAN, MS-Pix2Pix                                                  | No                                      |
| **SVG-VAE**                           | [@SVGVAELearnedRepresentation2019]           | reconstruction, font completion                                                     | SVG commands                                          | Variational Autoencoder (VAE) with convolutional encoder                            | Autoregressive (LSTM)                               | SVG commands                                     | Latent vector z (32-dimensional)                            | Smooth, semantically meaningful                             | 14M font characters                                                                                                                                               | Train: 12.6M characters, Test: 1.4M characters                                                                                                             | Google Fonts                                                                                             | Convolutional VAE, Autoregressive SVG decoder, Mixture Density Network (MDN), UMAP visualization of latent space          | VAE and LSTM-based                            | Convolutional layers for encoder and decoder, 4 stacked LSTM layers for SVG decoder                | Negative log-likelihood, Variance of latent space z                                                                                         | Qualitative assessments, Quantitative assessment using log-likelihood and variance       | No                                      |
| **SCFont**                            | [@SCFontStructureGuidedChinese2019]          | style transfer, interpolation, font completion                                      | Glyph images                                          | Deep stacked networks with SkelNet and StyleNet                                     | Sequential                                          | Glyph images                                     | Stroke category prior, Style embeddings                     | Not specified                                               | 70 Chinese font libraries with 6763 characters each                                                                                                               | Train: 6000 characters per font, Fine-tune: 775 characters per font                                                                                        | Self-collected and manually corrected strokes                                                            | Skeleton transformation network (SkelNet), Style rendering network (StyleNet), spatial feature transformation (SFT)       | CNN-based                                     | Contracting and expanding layers, residual blocks, deconvolution layers                            | L1 loss, IOU, user study, visual quality assessment (human judgement)                                                                       | pix2pix, DCFont, zi2zi, FontSL                                                           | No                                      |
| **FontRNN**                           | [@FontRNNGeneratingLargescale2019]           | font completion, style transfer                                                     | Sequences of points, stroke skeletons                 | Sequence-to-sequence model with monotonic attention                                 | Sequential                                          | Chinese character skeletons                      | Sequences of points                                         | Not specified                                               | 775 samples for optimal set, 2000 samples for handwriting trajectories                                                                                            | Optimal set: 775 samples, Handwriting: 2000 samples                                                                                                        | Various Chinese font libraries, CASIA handwriting dataset                                                | Monotonic attention mechanism, Long Short-Term Memory (LSTM), Sequence style transfer                                     | RNN-based                                     | Encoder with 256 neurons, Decoder with 256 neurons                                                 | DTW (Dynamic Time Warping), User study, Style classification accuracy, Content evaluation via VGG19                                         | pix2pix, DCFont, zi2zi, FontSL                                                           | No                                      |
| **Stroke-Based Representation**       | [@balashovaStrokeBasedRepresentation2019]    | interpolation, font completion                                                      | Glyph outlines, stroke-based representations          | Stroke-based geometric model, Bezier curves                                         | Not specified                                       | Vector glyphs                                    | Stroke-based template, Bezier curves                        | PCA, EM-PCA                                                 | 570 fonts                                                                                                                                                         | Not specified                                                                                                                                              | Online font database                                                                                     | Stroke-based geometric model, PCA, EM-PCA                                                                                 | VAE                                           | Two fully connected layers of sizes 256 and 10                                                     | Fitting error, Interpolation quality, Qualitative analysis                                                                                  | Campbell and Kautz [CK14], Raster-based methods                                          | No                                      |
| **EasyFont**                          | [@EasyFontStyleLearningBased2018]            | style transfer, cross-modal: text-to-font, contour completion                       | Handwritten character images                          | Non-linear manifold with Gaussian Process Latent Variable Model (GP-LVM)            | Sequential                                          | Synthesized handwriting fonts                    | Stroke skeleton representation                              | Low-dimensional latent space                                | 27,533 Chinese characters for training, smaller subsets for testing                                                                                               | Train: multiple subsets (639, 266, 775 characters) for style learning and evaluation                                                                       | Manually created handwriting samples                                                                     | Stroke extraction, non-rigid point set registration, manifold learning                                                    | GP-LVM, neural networks                       | Not specified                                                                                      | MSE, R values, Turing tests                                                                                                                 | Comparison with Rewrite, pix2pix, zi2zi, NN-Fonts, NN-Manifold                           | Yes                                     |
| **FontGAN**                           | [@FontGANCreatingNew2018]                    | font generation, style transfer, interpolation, contour completion                  | Glyph images, stroke and shape vectors                | Convolutional neural networks (CNN) with manifold learning                          | Sequential                                          | Chinese glyphs                                   | Skeleton and shape vectors                                  | Non-linear manifold (GP-LVM)                                | 72 font libraries, each with 2000 manually labeled characters                                                                                                     | Train: 72 font libraries, 2000 characters each                                                                                                             | Manually labeled font libraries                                                                          | GAN-based image synthesis, non-rigid point set registration, manifold learning                                            | CNN, GP-LVM                                   | 7 convolution layers, 7 up-convolution layers                                                      | Pixel-wise loss, Adversarial loss, Qualitative analysis                                                                                     | Comparison with CK14, pix2pix                                                            | No                                      |
| **Learning to Draw Vector Graphics**  | [@LearningDrawVector2018]                    | reconstruction, font completion                                                     | SVG paths                                             | Variational Autoencoder (VAE)                                                       | Sequential                                          | SVG drawings                                     | Feature vectors for SVG commands                            | Gaussian latent space                                       | 2,552 font faces, 877 font families                                                                                                                               | Train: 1920 SVGs per glyph, Test: 240 SVGs per glyph, Validation: 240 SVGs per glyph                                                                       | Google Fonts                                                                                             | End-to-end pipeline, Variational Autoencoder, Bidirectional LSTM, GMM for pen coordinates, Feature encoding variants      | Variational Autoencoder                       | Dual RNNs with LSTM cells, Layer normalization, GMM in decoder                                     | Hausdorff Distance, Visual inspection                                                                                                       | Comparison with input images and random noise                                            | No                                      |
| **(MC-GAN)**                          | [@MCGANMultiContentGAN2017]                  | font completion, style transfer                                                     | Partial glyph images in various styles                | Stacked conditional GAN with separate networks for glyph and ornamentation          | Sequential                                          | Full glyph sets                                  | Glyph and ornamentation vectors                             | Learned low-dimensional manifold                            | 10,000 fonts with different styles                                                                                                                                | Randomly selected subsets from each font for training and testing                                                                                          | Custom dataset created for the study                                                                     | End-to-end GAN pipeline, Conditional GANs, Ornamentation transfer network                                                 | cGAN, ResNet                                  | Six ResNet blocks for each generator; LSGAN loss functions for discriminators                      | L1 loss, LSGAN loss, Perceptual evaluation via user study                                                                                   | Comparison with baseline glyph-outline inference network and text effect transfer method | No                                      |
| **DCFont**                            | [@DCFontEndtoendDeep2017]                    | font completion, style transfer                                                     | Handwritten character images                          | Convolutional neural network                                                        | Generative adversarial network (GAN)                | GB2312 font library with 6763 Chinese characters | Deep font features                                          | Not specified                                               | 775 human-written characters plus 5988 machine-generated characters                                                                                               | Train: 775 human-written characters, Test: 5988 machine-generated characters                                                                               | Not specified                                                                                            | Font feature reconstruction network, Font style transfer network, Adversarial training                                    | VGG16 and residual blocks                     | 16-layer VGG for feature extraction, 5 residual blocks for style transfer                          | MSE loss for reconstruction, Adversarial loss for style transfer                                                                            | zi2zi, FontSL, Rewrite                                                                   | No                                      |
| **zi2zi**                             | [@Zi2ziMasterChinese2017]                    | style transfer                                                                      | Character images                                      | Conditional generative adversarial network (cGAN)                                   | Sequential                                          | Character images                                 | Continuous embeddings                                       | Continuous latent space                                     | 27 different fonts, approximately 29,000 examples                                                                                                                 | Train: 29,000 examples, Fine-tune: 2,000-4,000 characters per font                                                                                         | Various sources                                                                                          | Multi-class category loss, Continuous embeddings, Conditional GAN                                                         | Encoder-Decoder with Unet                     | Encoder: 8 layers (Conv, CIN, ReLU), Decoder: 8 layers (ConvT, CIN, ReLU)                          | Reconstruction loss, Adversarial loss, Category loss                                                                                        | Rewrite, DCFont, FontSL                                                                  | No                                      |
| **A2Z**                               | [@A2ZSupervisedTransfer2016]                 | style transfer, interpolation, font completion                                      | Handwritten character images                          | Variational autoencoder (VAE)                                                       | Extrapolation, generative adversarial network (GAN) | 62-letter fonts with known content and style     | Multivariate Gaussians                                      | Organized latent space, linear combinations of latent means | 1,839 fonts                                                                                                                                                       | Train: 1,556 fonts, Val: 92 fonts, Test: 191 fonts                                                                                                         | openfontlibrary.org, Fonts used by [21]                                                                  | Extrapolation layer, SSIM cost function, Adversarial sub-networks, In-network and out-of-network image quality assessment | Variational autoencoder (VAE)                 | Two hidden layers with 500 nodes each, Multilayer perceptron as image generator                    | Mean DSSIM, Structured similarity objective (SSIM), Negative similarity as decoder loss                                                     | M2, Ours-SSIM, Ours-Adv                                                                  | No                                      |









