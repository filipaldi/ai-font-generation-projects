| **Name**                                           | **Year** | **Citkey**                                 | **Tasks**                                                                           | **Input types**                                       | **Encoding Representation**                                                         | **Decoding Modality**                               | **Output types**                                 | **Representation**                                          | **Latent Space**                                            | **Datasets Size**                                                                                                                                                                   | **Training / Testing Distribution**                                                                                                                        | **Dataset Source**                                                                                       | **Techniques and Features**                                                                                                             | **Architecture Base**                           | **Layers**                                                                                         | **Output Evaluation Methods**                                                                                                               | **Evaluation Comparison**                                                                | **Type Designer Involvement as expert** |
| -------------------------------------------------- | -------- | ------------------------------------------ | ----------------------------------------------------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------------------- | --------------------------------------------------- | ------------------------------------------------ | ----------------------------------------------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------- | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | --------------------------------------- |
| **Font Style Interpolation with Diffusion Models** | 2024     | [@FontStyleInterpolation2024]              | interpolation                                                                       | Latin alphabet images (64x64 pixels)                  | Conditional diffusion model (U-Net architecture)                                    | Iterative denoising process                         | Font images (64x64 pixels)                       | Real-valued condition vectors, noise images                 | Not specified                                               | MyFonts: 17,412 fonts; GoogleFonts: 2,545 fonts                                                                                                                                     | Train: 13,938 fonts, Val: 1,734 fonts, Test: 1,740 fonts                                                                                                   | MyFonts, GoogleFonts                                                                                     | Image-blending, condition-blending, noise-blending approaches                                                                           | U-Net (diffusion model)                         | Denoising U-Net with several layers                                                                | Recognition accuracy, qualitative comparison                                                                                                | FANnet, Diff-Font                                                                        | No                                      |
| **FTransGAN**                                      | 2023     | [@chenhaoFTransGANPyTorch2023]             | style transfer, font completion                                                     | Grayscale images of glyphs                            | Multi-level attention with Context-aware and Layer Attention Networks               | Sequential                                          | Grayscale glyphs                                 | Local and global feature representation                     | Not specified                                               | 847 fonts, each with 52 English letters and ~1000 Chinese characters                                                                                                                | Train: 847 fonts, Test: 29 fonts                                                                                                                           | Constructed by authors                                                                                   | Multi-level attention network, Context-aware Attention Network, Layer Attention Network                                                 | GAN-based                                       | Encoder-Decoder structure with 3 Conv layers, 6 ResNet blocks, and 3 up-conv layers                | L1 loss, Style loss, Content loss, MAE, SSIM, MS-SSIM, mFID, Top-1 accuracy                                                                 | EMD, DFS                                                                                 | No                                      |
| **SVGformer**                                      | 2023     | [@SVGformerRepresentationLearning2023]     | classification, interpolation, retrieval                                            | Continuous SVG commands                               | Sequential and Geometric representation                                             | Sequential                                          | Vector graphics (SVGs)                           | Embeddings of continuous commands and geometric information | Not specified                                               | Google Fonts, Icons dataset: Size not specified                                                                                                                                     | Not specified                                                                                                                                              | Google Fonts, Icons datasets                                                                             | Geometric self-attention, Graph convolutional network (GCN), Continuous value embedding                                                 | Transformer-based                               | Encoder: Multiple geometric self-attention modules, Decoder: Multi-head attention                  | Chamfer distance (CD), Cross-entropy (CE)                                                                                                   | DeepSVG, LayoutTransformer                                                               | No                                      |
| **DS-Font**                                        | 2023     | [@DSFontFewshotFont2023]                   | font completion                                                                     | Raster images of glyphs                               | Style representation through multi-layer style projector (MSP)                      | Sequential                                          | Font glyphs                                      | Embeddings of style codes                                   | Not specified                                               | 1,425 fonts, 52 glyphs per font                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | Multi-layer style projector (MSP), multi-task patch discriminator, contrastive learning                                                 | GAN-based                                       | Multi-layer style projector, multi-task patch discriminator, generator with attention mechanism    | L1 loss, LPIPS, RMSE, Acc(C), Acc(S), FID(C), FID(S)                                                                                        | LF-Font, MX-Font, DG-Font, FTransGAN, MF-Net                                             | No                                      |
| **VecFontSDF**                                     | 2023     | [@VecFontSDFLearningReconstruct2023]       | style transfer                                                                      | Raster images of glyphs                               | Spatial representation                                                              | Sequential                                          | Font glyphs                                      | Signed Distance Function (SDF)                              | Multi-scale                                                 | Google Fonts: 143K glyph images                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Google Fonts                                                                                             | SDF rendering, Style transfer, Multi-scale feature extraction                                                                           | CNN-based                                       | 16 convolutional layers                                                                            | MSE, SSIM, FID                                                                                                                              | DeepSVG, Im2vec, DeepVecFont                                                             | No                                      |
| **DeepVecFont-v2**                                 | 2023     | [@DeepVecFontv2ExploitingTransformers2023] | interpolation, font completion                                                      | Raster images and vector outlines                     | Relaxation representation for vector outlines                                       | Sequence-to-sequence                                | Vector glyphs                                    | Embeddings of drawing commands and coordinates              | Not specified                                               | English: 8,035 fonts, Chinese: 212 fonts                                                                                                                                            | Train: 8,035 (EN), 212 (CN), Test: 1,425 (EN), 34 (CN)                                                                                                     | Google Fonts                                                                                             | Transformer encoder-decoder, Bezier curve alignment, Self-refinement                                                                    | Transformer-based                               | 6 Transformer layers                                                                               | Reconstruction errors (L1), IoU, Bezier curve alignment loss                                                                                | DeepSVG, DeepVecFont                                                                     | No                                      |
| **Contour Completion**                             | 2023     | [@ContourCompletionTransformers2023]       | contour completion                                                                  | Contour sequences with missing points                 | Sequence embedding                                                                  | Sequence-to-sequence                                | Completed contour sequences                      | 5D vectors (x, y, Contour ID, Point ID, curve flag)         | Not specified                                               | Google Fonts: 489 Serif, 1,275 Sans-Serif, 327 Display, 91 Handwriting                                                                                                              | Train: 1,777 fonts, Val: 200 fonts, Test: 205 fonts                                                                                                        | Google Fonts                                                                                             | Multi-task learning, Loss functions for contour, point, coordinate, and flags                                                           | Transformer-based                               | 4 Transformer layers (Encoder & Decoder)                                                           | L1 distance, Hausdorff distance                                                                                                             | Standard Transformer-Encoder                                                             | No                                      |
| **DualVector**                                     | 2023     | [@DualVectorUnsupervisedVector2023]        | interpolation, font completion                                                      | Glyph images                                          | Joint vector and pixel representation                                               | Sequential                                          | Vector glyphs                                    | Dual-part vector representation                             | Shared between modalities                                   | Public datasets: 1,425 fonts, 52 glyphs per font                                                                                                                                    | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | Dual-part representation, Differentiable rendering, Contour refinement, UDF initialization                                              | Transformer-based                               | Encoder: CNN + Transformer (6 layers), Decoder: Transformer + MLP                                  | SSIM, L1, s-IoU, LPIPS                                                                                                                      | DeepVecFont, Im2Vec, Multi-Implicits                                                     | No                                      |
| **Consistent Typography Generation**               | 2023     | [@DiverseConsistentTypography2023]         | style transfer                                                                      | Graphic documents with text elements                  | Autoregressive Transformer with attention mechanism                                 | Sequential                                          | Typographic designs                              | Fine-grained typographic attributes                         | Not specified                                               | 23,475 design templates                                                                                                                                                             | Train: 18,780, Test: 2,347, Val: 2,347                                                                                                                     | Crello dataset                                                                                           | Structure-preserved sampling, Fine-grained attribute generation, Consistency and diversity in styling                                   | Transformer-based                               | 8 Transformer blocks                                                                               | Attribute metrics (accuracy, MAE, color difference), Structure score, Diversity score                                                       | CanvasVAE, MFC                                                                           | No                                      |
| **Joint Implicit Neural**                          | 2023     | [@JointImplicitJointImplicit2023]          | interpolation                                                                       | Pixelated font images                                 | Joint neural representation using SDF and probabilistic corner field (CF)           | Sequential                                          | Vector fonts                                     | Embeddings of SDF and CF                                    | Not specified                                               | 1,425 fonts, 52 glyphs per font                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | Implicit neural representation, Corner field modeling, Dual contouring for vectorization                                                | HyperNetworks-based                             | Multi-layer perceptrons (MLPs) for SDF and CF networks                                             | L1 error, SSIM, s-mIoU                                                                                                                      | Im2Vec, Multi-Implicit, DeepVecFont, Attr2Font                                           | No                                      |
| **VQ-font**                                        | 2023     | [@VQFontFewShot2023]                       | font completion                                                                     | Raster images of glyphs                               | Similarity-guided global style and quantization local style representation          | Sequential                                          | Font glyphs                                      | Discrete latent codes for component-level styles            | Not specified                                               | 386 Chinese fonts, 3,500 characters each                                                                                                                                            | Train: 370 fonts, 3,000 characters each; Test: 15 unseen fonts, 3,000 seen characters each, 15 unseen fonts, 500 unseen characters each                    | Custom dataset                                                                                           | Global and local style aggregation, Cross-attention-based style transfer, GAN-based training                                            | GAN and VQ-VAE                                  | 3 Transformer layers for cross-attention, 8 attention heads                                        | SSIM, RMSE, LPIPS, FID, User Study                                                                                                          | FUNIT, MX-Font, LF-Font, DG-Font, AGIS-net, FS-Font                                      | No                                      |
| **VecFusion**                                      | 2023     | [@VecFusionVectorFont2023]                 | interpolation, completion                                                           | Raster images of glyphs                               | Cascaded diffusion model with vector diffusion                                      | Sequential                                          | Vector glyphs                                    | Mixed discrete-continuous representation for control points | Not specified                                               | 1,424 fonts, 577 distinct Unicode glyphs                                                                                                                                            | Train: 314K glyphs, Val: 5K glyphs, Test: 5K glyphs                                                                                                        | Google Fonts                                                                                             | Cascaded diffusion model, Mixed discrete-continuous representation, Transformer-based vector model                                      | Transformer-based                               | 8 Transformer layers                                                                               | L1, Chamfer Distance (CD), Control point difference (#cp diff), Vector path difference (#vp diff)                                           | ChiroDiff, DeepVecFont-v2                                                                | No                                      |
| **PGM**                                            | 2022     | [@PGMFontRepresentation2022]               | font retrieval, style transfer                                                      | Glyph images of characters                            | Paired-glyph matching with contrastive learning                                     | Parametric                                          | Font embeddings                                  | Latent space with high dimensional glyph embeddings         | Not specified                                               | O’Donovan dataset: 1,088 fonts (training), 28 fonts (validation); OFL: 3,702 fonts (training), 100 fonts (validation); Capitals64: 7,649 fonts (training), 1,473 fonts (validation) | O’Donovan: train/val (1,088/28), OFL: train/val (3,702/100), Capitals64: train/val/test (7,649/1,473/1,560)                                                | O’Donovan dataset, Open Font Library (OFL), Capitals64                                                   | Paired-glyph matching, Contrastive learning, ResNet18 backbone, Retrieval accuracy, Font attribute prediction                           | ResNet18 backbone                               | Not specified                                                                                      | Retrieval mean accuracy (MACCRet), Font attribute prediction L1-error, Image L1-error                                                       | Classification, Style Transfer, Autoencoder, Srivatsan et al.                            | No                                      |
| **StrokeStyles**                                   | 2022     | [@StrokeStylesStrokebasedSegmentation2022] | style transfer                                                                      | Glyph outlines                                        | Stroke-based segmentation with curvilinear shape features and augmented medial axis | Parametric                                          | Stylized glyphs                                  | Shape components and stroke-based representation            | Not specified                                               | Not specified                                                                                                                                                                       | Not specified                                                                                                                                              | Not specified                                                                                            | Stroke-based segmentation, Curvilinear shape features, Augmented medial axis, Junction types                                            | Not specified                                   | Not specified                                                                                      | Qualitative visual inspection, User study                                                                                                   | Not specified                                                                            | No                                      |
| **Noisy Impressions**                              | 2022     | [@SharedLatentSpace2022]                   | cross-modal: shape-to-impression, impression-to-shape                               | Glyph images, impression words                        | Shared latent space representation                                                  | Cross-modal                                         | Glyph images, impression words                   | Vector representations for font shapes and impression words | Shared latent space with DeepSets                           | MyFonts: 18,815 fonts                                                                                                                                                               | Train: 9,980, Validation: 2,992, Test: 1,223                                                                                                               | MyFonts dataset                                                                                          | DeepSets for shape-relevant impression filtering, cross-modal autoencoders                                                              | Autoencoder, ResNet18-based encoder             | ResNet18 encoder, deconvolutional layers for decoder                                               | Precision@K, average retrieval rank, Hausdorff distance                                                                                     | Impressions2Font                                                                         | No                                      |
| **XMP-Font**                                       | 2022     | [@XMPFontSelfSupervisedCrossModality2022]  | font completion                                                                     | Glyph images, stroke labels                           | Cross-modality representation                                                       | Cross-modality                                      | Glyphs                                           | Stroke-level, component-level, character-level styles       | Pre-trained with self-supervised signals                    | 100 font styles                                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Founder font libraries                                                                                   | Cross-modality transformer-based encoder, ECA modules, LSTM-based stroke loss                                                           | Transformer-based                               | Cross-modality encoder with BERT layers, 4 ECA modules                                             | FID, PSNR, SSIM, L1, User study                                                                                                             | StarGAN-v2, FUNIT, LF-Font, MX-Font, DG-Font                                             | No                                      |
| **CVFont**                                         | 2022     | [@CVFontSynthesizingChinese2022]           | style transfer                                                                      | Raster images of glyphs                               | Hierarchical approach to component extraction, using CPD algorithm for registration | Sequential                                          | Chinese vector fonts                             | Components and strokes                                      | Multi-scale                                                 | GB2312 Kaiti font library (6763 characters), 70 Chinese fonts                                                                                                                       | Pre-train: 60 fonts, Online: 10 fonts, Testing: 69 fonts                                                                                                   | Founder Group                                                                                            | Layout prediction with Faster R-CNN, U-Net based generator, Skeleton extraction, Shape decomposition                                    | ResNet-101 + U-Net                              | ResNet-101 backbone, U-Net generator with 3 downsampling layers, Faster R-CNN detector             | IoU scores, Qualitative user study                                                                                                          | Rewrite, pix2pix, CycleGAN, EasyFont, zi2zi                                              | Yes                                     |
| **Arbitrary Font Generation**                      | 2022     | [@ArbitraryFontGeneration2022]             | style transfer                                                                      | Raster images of fonts                                | Spatial representation                                                              | Sequential                                          | Font images                                      | Disentangled features of text content and font style        | N/A                                                         | Korean: 238 train, 40 test; Chinese: 185 train, 15 test; English: 185 train, 15 test                                                                                                | Train: 85%, Test: 15%                                                                                                                                      | Noonnu, Internet, Chinese Font Design                                                                    | Stacked input, Consistency loss, VGG-19, AdaIN, Hallucinated stack                                                                      | VGG-19 based                                    | VGG-19 layers, AdaIN layers, ConvBlock layers                                                      | FID, L1 distance, Perceptual distance                                                                                                       | FUNIT, EMD                                                                               | No                                      |
| **SE-GAN**                                         | 2022     | [@SEGANSkeletonEnhanced2022]               | style transfer                                                                      | Raster images of brush handwriting                    | Spatial representation                                                              | Sequential                                          | Font glyphs                                      | Skeleton-based representation                               | Multi-scale                                                 | Custom dataset: 15,799 high-resolution images                                                                                                                                       | Train: 80%, Dev: 10%, Test: 10%                                                                                                                            | Custom dataset                                                                                           | GAN-based model, Self-attentive Refined Attention Module (SAttRAM), skeleton discriminator                                              | GAN-based                                       | 4 residual blocks for each encoder, 2 discriminators                                               | Content accuracy, FID, User preference                                                                                                      | zi2zi, CycleGAN, StarGAN, DF-Font                                                        | Yes                                     |
| **FontNet**                                        | 2022     | [@FontNetClosingGap2022]                   | font style transfer, font completion                                                | Font images                                           | Embedding                                                                           | Adversarial generation                              | High-resolution font images                      | Embeddings of style and content features                    | Style embedding space                                       | 90 Korean fonts, 2,350 characters                                                                                                                                                   | Train: 75% fonts, Test: 25% fonts                                                                                                                          | Naver Fonts                                                                                              | StyleGAN, Separator network, Triplet loss                                                                                               | StyleGAN-based                                  | Encoder-Decoder with separator network                                                             | SSIM, mFID, Top-1 accuracy                                                                                                                  | MX-Font, FUNIT                                                                           | No                                      |
| **Impression Labels**                              | 2022     | [@FontGenerationMissing2022]               | style transfer                                                                      | Raster images of glyphs                               | Conditional GAN with missing label handling                                         | Sequential                                          | Font glyphs                                      | Impression label embeddings                                 | Not specified                                               | MyFonts: 17,202 fonts, 1,430 impression labels                                                                                                                                      | Train: 90%, Test: 10%                                                                                                                                      | MyFonts dataset                                                                                          | Co-occurrence-based missing label estimator, Impression label space compressor, Style consistency discriminator                         | GAN-based                                       | Progressive GAN with auxiliary classifiers                                                         | FID, Intra-FID, mAP-train, mAP-test                                                                                                         | C-GAN+, AC-GAN+, CP-GAN+, Imp2Font                                                       | No                                      |
| **SVGVecFont**                                     | 2022     | [@SVGVecFontSVGVector2022]                 | interpolation, completion                                                           | SVG vector graphics                                   | Sequence-to-sequence                                                                | Sequence-to-sequence                                | Vector glyphs                                    | Commands and Coordinates                                    | Not specified                                               | Chinese: 407 fonts, 3396 characters                                                                                                                                                 | Train: 397 fonts, Test: 10 fonts                                                                                                                           | Public datasets                                                                                          | Transformer encoder-decoder, Style Aggregation Module                                                                                   | Transformer-based                               | Multi-head projection, Self-reconstruction branch                                                  | L1 loss, Adversarial loss, SSIM, LPIPS, FID                                                                                                 | DeepVecFont, Diff-Font, GAS-NeXt                                                         | No                                      |
| **GenText**                                        | 2022     | [@GenTextUnsupervisedArtistic2022]         | text effect transfer, font style transfer, image style transfer, font interpolation | Content images, font images, texture reference images | Spatial and global code representation                                              | Sequence-to-sequence                                | Artistic text images                             | Embeddings (spatial and global code)                        | Not specified                                               | Artistic text benchmarks (e.g., TE141K)                                                                                                                                             | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                          | GAN, unsupervised learning, stylization and destylization                                                                               | Encoder-decoder GAN                             | 4 downsampling residual blocks, 2 convolution layers                                               | PSNR, SSIM, Perceptual loss, Style loss                                                                                                     | AdaIN, Dpatch, NCE, CycleGAN                                                             | No                                      |
| **FS-Font**                                        | 2022     | [@FSFontFewShotFont2022]                   | font completion                                                                     | Raster images of glyphs                               | Fine-grained local style representation through cross-attention                     | Sequential                                          | Stylized glyph images                            | Fine-grained local style representation (FLS)               | Not specified                                               | 407 fonts, 3,396 characters                                                                                                                                                         | Train: 397 fonts, 2,896 characters, Test: 10 fonts, 500 unseen characters (UFUC), 2,896 seen characters (UFSC)                                             | Custom dataset                                                                                           | Cross-attention based style aggregation, Self-reconstruction branch, Reference selection strategy                                       | Convolutional and Residual Blocks               | Multiple convolutional and residual layers                                                         | L1 loss, RMSE, SSIM, LPIPS, User Study                                                                                                      | FUNIT, DG-Font, MX-Font, AGIS-net, LF-Font                                               | No                                      |
| **PGMh**                                           | 2022     | [@PGMFontRepresentation2022]               | font retrieval, style transfer, font completion                                     | Glyph images                                          | Paired-glyph matching learning                                                      | Sequential                                          | Font embeddings                                  | Embeddings of glyph representations                         | Not specified                                               | O’Donovan: 1,088 fonts, Capitals64: 10,682 fonts, Open Font Library (OFL): 3,802 fonts                                                                                              | O’Donovan: Train: 1,088 fonts, Val: 28 fonts, Capitals64: Train: 7,649 fonts, Val: 1,473 fonts, Test: 1,560 fonts, OFL: Train: 3,702 fonts, Val: 100 fonts | O’Donovan dataset, Capitals64, OFL                                                                       | Paired-glyph matching, Cross-entropy loss, L1 loss, Contrastive learning                                                                | ResNet18-based                                  | ResNet18 backbone, additional layers for projection head                                           | Retrieval mean accuracy (MACC_Ret), Font attribute prediction (L1-error)                                                                    | Classification, Style Transfer, Autoencoder                                              | No                                      |
| **Neural Font Rendering**                          | 2022     | [@NeuralFontRendering2022]                 | interpolation                                                                       | Vector glyph outlines                                 | Implicit neural representation                                                      | Sequential                                          | Rasterized glyphs at various sizes               | Implicit functions                                          | Not specified                                               | Not specified                                                                                                                                                                       | Not specified                                                                                                                                              | Custom dataset                                                                                           | Implicit neural representation, Frequency encoding, Batch normalization adaptations                                                     | U-Net-based, Implicit model                     | Encoder-decoder with multiple layers, Implicit model with 5 layers                                 | L2 pixelwise loss, Focal loss                                                                                                               | Comparison between masked MLP and implicit model                                         | No                                      |
| **Diff-Font**                                      | 2022     | [@DiffFontDiffusionModel2022]              | font completion                                                                     | Raster images of glyphs                               | Gaussian noise representation                                                       | Sequential                                          | Font glyphs                                      | Character attributes embedding (content, stroke, style)     | Not specified                                               | Small: 1,000 Chinese characters, Large: 3,755 Chinese characters                                                                                                                    | Train: 80%, Test: 20%                                                                                                                                      | Custom dataset                                                                                           | Diffusion model, Stroke-wise information                                                                                                | UNet-based DDPM                                 | Multi-scale U-Net layers                                                                           | SSIM, RMSE, LPIPS, FID                                                                                                                      | FUNIT, MX-Font, DG-Font                                                                  | No                                      |
| **GAS-NeXt**                                       | 2022     | [@GASNeXtFewShotCrossLingual2022]          | cross-lingual font completion                                                       | Raster images and style reference images              | Layer attention and context-aware attention                                         | Sequential                                          | Stylized glyph images                            | Encoded style and content features                          | Not specified                                               | Li et al. dataset                                                                                                                                                                   | Train: 90%, Test: 10%                                                                                                                                      | Li et al. dataset, Azadi et al. dataset, CASIA dataset                                                   | Layer attention, Context-aware attention, Local discriminator                                                                           | AGIS-Net and Font Translator GAN based          | Encoder: 6 convolutional layers, Decoder: 6 deconvolutional layers                                 | FID, SSIM, Pixel-level Accuracy                                                                                                             | Font Translator GAN, AGIS-Net                                                            | No                                      |
| **Character-Aware**                                | 2022     | [@CharacterAwareModelsImprove2022]         | text rendering                                                                      | Text inputs (character-level and token-level)         | Character-aware and character-blind representations                                 | Sequential                                          | Visual text rendering in images                  | Token and character embeddings                              | Not specified                                               | Not specified                                                                                                                                                                       | Train: 500,000 steps, Test: Not specified                                                                                                                  | Laion-400M                                                                                               | Character-aware and character-blind text encoders, Hybrid models, Pretraining                                                           | T5, ByT5, Concat(T5-XXL, ByT5-Small)            | Multiple layers (sizes not specified)                                                              | OCR-based metrics (accuracy), Human ratings                                                                                                 | Imagen, Stable Diffusion, Parti                                                          | No                                      |
| **AdaptiFont**                                     | 2021     | [@AdaptiFontIncreasingIndividuals2021]     | adaptive design, reading speed optimisation                                         | Text data                                             | Non-negative matrix factorization (NMF)                                             | Generative                                          | TrueType fonts                                   | NMF basis vectors                                           | Not specified                                               | 25 classic fonts                                                                                                                                                                    | 7 subjects, 250 texts each                                                                                                                                 | Custom collected from Twitter pages of news platforms                                                    | Bayesian optimization, human-in-the-loop system, generative font space                                                                  | Not specified                                   | NMF with 3 components                                                                              | Reading speed (words per minute), Bayesian ANOVA, Bayesian Pearson Correlation                                                              | Traditional fonts comparison (Kolmogorov-Smirnov test)                                   | No                                      |
| **SkelGAN**                                        | 2021     | [@SkelGANFontImage2021]                    | style transfer, skeletonization                                                     | Font images                                           | Spatial representation                                                              | Sequential                                          | Skeletons of font glyphs                         | One-pixel-width skeletons                                   | Multi-scale                                                 | Custom dataset: 70,500 glyph images                                                                                                                                                 | Train: 90%, Test: 10%                                                                                                                                      | Custom dataset                                                                                           | GANs, Style classification, Character classification, Multi-scale feature extraction                                                    | Modified U-Net                                  | 14 layers (7 encoder, 7 decoder)                                                                   | SSIM, L1 distance                                                                                                                           | Lee’s method, Pix2pix                                                                    | No                                      |
| **RCN**                                            | 2021     | [@RadicalCompositionNetwork2021]           | cross-modal: caption-to-font                                                        | Caption text, Raster images of radicals               | Sequential                                                                          | Sequential                                          | Chinese character images                         | Embeddings                                                  | Tree-structured                                             | Printed: 114,665 characters; Handwritten: 2,674,784 characters                                                                                                                      | Train: 22,933 classes, Test: 4,172 classes                                                                                                                 | Custom dataset                                                                                           | Tree-structured encoder (TRN), DenseNet, Deconvolution, Perceptual loss                                                                 | Encoder-decoder (CNN-based)                     | Tree-structured recurrent units, Deconvolution layers                                              | L1 loss, RMSE, SSIM, LPIPS                                                                                                                  | RAN, zi2zi                                                                               | No                                      |
| **DG-Font**                                        | 2021     | [@DGFontDeformableGenerative2021]          | font completion                                                                     | Raster images of glyphs                               | Spatial representation                                                              | Sequential                                          | Font glyphs                                      | Spatial features and latent vector representations          | Deformable                                                  | Custom dataset: 410 fonts, 990 characters each                                                                                                                                      | Train: 400 fonts, 800 chars/font; Test: 10 fonts, 190 chars/font                                                                                           | Custom dataset                                                                                           | Deformable convolution, Feature Deformation Skip Connection (FDSC), AdaIN                                                               | CNN-based                                       | Deformable convolutions, residual blocks, multi-task discriminator                                 | L1 loss, RMSE, SSIM, LPIPS, FID                                                                                                             | CycleGAN, EMD, Zi2zi, GANimorph, FUNIT                                                   | No                                      |
| **StrokeGAN**                                      | 2021     | [@StrokeGANReducingMode2021]               | style transfer                                                                      | Glyph images                                          | Stroke encoding representation                                                      | Sequential                                          | Glyph images                                     | Stroke-level encoding                                       | CycleGAN with stroke encoding                               | 9 different fonts datasets                                                                                                                                                          | Train: 90%, Test: 10%                                                                                                                                      | Custom collected, CASIA-HWDB1.1, Internet                                                                | Stroke encoding, CycleGAN, stroke-encoding reconstruction loss                                                                          | CycleGAN-based                                  | 2 convolutional layers (down-sampling), 9 residual modules, 2 deconvolutional layers (up-sampling) | Content accuracy, Recognition accuracy, Stroke error                                                                                        | CycleGAN, zi2zi, Chinese Typography Transfer (CTT)                                       | No                                      |
| **LF-Font**                                        | 2021     | [@LFFontFewshotFont2021]                   | font completion                                                                     | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyphs                                           | Localized style representations, factorization modules      | Factorized component and style factors                      | 19,514 characters                                                                                                                                                                   | Train: 467 fonts, Test: 15 fonts                                                                                                                           | Custom collected Chinese fonts                                                                           | Component-wise style encoding, content encoder, factorization modules                                                                   | CNN-based                                       | Style encoder, content encoder, generator with 4 convolutional layers                              | LPIPS, Accuracy, FID, User study                                                                                                            | SA-VAE, EMD, AGIS-Net, FUNIT, DM-Font                                                    | No                                      |
| **FontRL**                                         | 2021     | [@FontRLChineseFont2021]                   | font completion                                                                     | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyph images                                     | Stroke-level styles                                         | Deep reinforcement learning with TPS transformations        | 6,763 characters in 5 styles                                                                                                                                                        | Train: 775 characters, Test: 5 styles                                                                                                                      | Custom dataset                                                                                           | Deep reinforcement learning, TPS transformation, CNN-based image rendering                                                              | ResNet-18, CNN-based                            | Policy network (ResNet-18), BBoxNet (ResNet-34), StyleNet for rendering                            | L1 loss, IoU, User study                                                                                                                    | SCFont, zi2zi, DCFont, FontRNN, pix2pix                                                  | No                                      |
| **Perceptual Manifold of Fonts**                   | 2021     | [@LearningPerceptualManifold2021]          | gont exploration, style transfer                                                    | Raster images                                         | Latent space representation                                                         | Sequential                                          | Glyph images                                     | Perceptual manifolds                                        | Continuous latent space                                     | Google Fonts: 2169 fonts                                                                                                                                                            | Train: 90%, Test: 10%                                                                                                                                      | Google Fonts                                                                                             | Variational Autoencoder (VAE), t-SNE for manifold learning, kernel density estimation                                                   | VAE-based                                       | Encoder: 4 convolutional layers, Decoder: 2 convolutional layers                                   | SSIM, User study                                                                                                                            | Comparison with traditional font exploration interfaces                                  | Yes                                     |
| **Implicit Glyph Shape**                           | 2021     | [@LearningImplicitGlyph2021]               | interpolation, style transfer                                                       | Raster images                                         | Implicit representation                                                             | Implicit function decoding                          | Glyph images                                     | Signed distance functions with quadratic curves             | Continuous 2D space                                         | 26390 glyph images                                                                                                                                                                  | Train: 26390 images, Validation: dataset split                                                                                                             | Custom dataset                                                                                           | Implicit representation, quadratic curves, disentangled encoder, auxiliary character classifier                                         | CNN-based, ResNet-18                            | ResNet-18 encoder, MLP for curve parameters                                                        | SSIM, LPIPS, L1 distance, User study                                                                                                        | VAE, pix2pix, AGIS-Net, FANnet                                                           | No                                      |
| **CycleFont**                                      | 2021     | [@FontCompletionManipulation2021]          | font completion, interpolation, manipulation                                        | Raster images, SVG curves, point sets                 | Multi-modality representation (image-to-graph-to-image)                             | Multi-modality (graph-based)                        | Glyph images                                     | Graph-based representation                                  | Latent space with graph representation                      | Google Fonts: 2693 fonts, 55,554 glyphs                                                                                                                                             | Train: 95%, Test: 5%                                                                                                                                       | Google Fonts dataset                                                                                     | Cross-modality auto-encoder, graph-based representation                                                                                 | Graph-based, auto-encoder                       | Image encoder (Conv2D), point set decoder, graph constructor, neural renderer                      | MSE, PSNR, SSIM                                                                                                                             | TCN                                                                                      | No                                      |
| **DeepVecFont**                                    | 2021     | [@DeepVecFontSynthesizingHighquality2021]  | font completion, interpolation                                                      | Raster images, vector outlines                        | Dual-modality representation                                                        | Sequential                                          | Vector glyphs                                    | Image-aspect and sequence-aspect features                   | Latent space with Gaussian priors                           | 8K fonts for training, 1.5K for testing                                                                                                                                             | Train: 8K fonts, Test: 1.5K fonts                                                                                                                          | SVG-Fonts Dataset                                                                                        | Dual-modality learning, differentiable rasterization, Mixture Density Network                                                           | CNN-based, RNN-based                            | Convolutional layers, LSTM layers                                                                  | L1 loss, Perceptual loss, Cross-Entropy loss, MDN loss                                                                                      | SVG-VAE, DeepSVG, Im2Vec                                                                 | No                                      |
| **ZiGAN**                                          | 2021     | [@ZiGANFinegrainedChinese2021]             | style transfer                                                                      | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyphs                                           | Character-level styles                                      | Learned correlation between structures of different styles  | 61,151 images, 6560 characters                                                                                                                                                      | Train: 100 or 200 shots, Test: remaining images                                                                                                            | Chinese calligraphy character website                                                                    | GAN-based, CAM attention module, CycleGAN                                                                                               | GAN-based                                       | Encoder: 8 convolutional layers, Decoder: 8 deconvolutional layers                                 | FID, IOU, Top-1 Accuracy, User study                                                                                                        | zi2zi, pix2pix, U-GAT-IT, CycleGAN, StarGAN, CalliGAN                                    | No                                      |
| **Dual Latent Manifolds**                          | 2021     | [@ScalableFontReconstruction2021]          | reconstruction                                                                      | Glyph images                                          | Dual latent manifolds representation                                                | Matrix factorization                                | Glyph images                                     | Vector representations for font style and character shape   | Dual latent spaces with Gaussian priors                     | Google Fonts: 2017 fonts, Chinese Simplified: 623 fonts                                                                                                                             | Train: 60%, Dev: 20%, Test: 20%                                                                                                                            | Google Fonts, Chinese Simplified dataset                                                                 | Dual manifold model, adaptive wavelet loss, U-Net architecture                                                                          | U-Net-based                                     | Encoder: convolutional layers, Decoder: transposed convolutional layers with MLP parameters        | SSIM, L2, Human evaluation (Amazon Mechanical Turk)                                                                                         | EMD, Nearest Neighbor                                                                    | No                                      |
| **CKFont**                                         | 2021     | [@CKFontFewShotKorean2021]                 | font completion                                                                     | Glyph images                                          | Spatial representation                                                              | Sequential                                          | Glyphs                                           | Character-level styles                                      | Pre-trained with self-supervised signals                    | 2,350 glyphs                                                                                                                                                                        | Train: 2,000, Test: 350                                                                                                                                    | Hangul standard code system (KS X 1001)                                                                  | Conditional GAN, dual encoders, style extraction from components                                                                        | GAN-based                                       | 6 convolutional layers in each encoder, 6 deconvolutional layers in the decoder                    | L1, L2, SSIM, FID                                                                                                                           | zi2zi, SKFont                                                                            | No                                      |
| **Neural Style Difference Transfer**               | 2020     | [@NeuralStyleDifference2020]               | style transfer, interpolation, font completion                                      | Font images                                           | Convolutional Neural Network (CNN)                                                  | Sequential                                          | Font images                                      | Feature maps, Gram matrices                                 | Not specified                                               | Various combinations of input fonts                                                                                                                                                 | Not specified                                                                                                                                              | Not specified                                                                                            | Neural style transfer, Style difference loss, Content difference loss                                                                   | VGGNet                                          | Multiple layers (conv1_2, conv2_2, conv3_2, conv4_2, conv5_2)                                      | Mean Squared Error (MSE)                                                                                                                    | NST, GAN-based methods                                                                   | No                                      |
| **JointFontGAN**                                   | 2020     | [@JointFontGANJointGeometryContent2020]    | style transfer                                                                      | Gray-scale glyph images                               | Multi-stream extended conditional GAN (XcGAN) models                                | Two-stream generative process                       | Glyph images                                     | Font skeletons and glyph representations                    | Not specified                                               | 20K fonts with different styles                                                                                                                                                     | Not specified                                                                                                                                              | Collected datasets                                                                                       | Two-stream GAN, few-shot learning, skeleton and content consistency                                                                     | GAN                                             | Two-stream GAN                                                                                     | Structural similarity (SSIM), Mean Squared Error (MSE), L1 loss                                                                             | zi2zi, Glyph Network in MC-GAN                                                           | No                                      |
| **TNet**                                           | 2020     | [@TNetGANBasedUnpaired2020]                | style transfer                                                                      | Chinese character images                              | Skeleton extraction, GAN-based transformation and rendering                         | Sequential                                          | Chinese character images                         | Skeleton and stroke style representation                    | Not specified                                               | StdFont-4: 6,700 characters per font, Calli-5: 1,200 characters per style                                                                                                           | Not specified                                                                                                                                              | StdFont-4, Calli-5                                                                                       | Three-stage GAN model, Skeleton extraction, Stroke rendering, Unpaired training data                                                    | GAN-based                                       | Not specified                                                                                      | Style Error Rate (SER), Content Error Rate (CER), Intersection over Union (IoU), MS Accuracy                                                | Various GAN models, Pix2Pix, CycleGAN, StarGAN                                           | No                                      |
| **DM-Font**                                        | 2020     | [@DMFontFewShotCompositional2020]          | font completion, style transfer, interpolation                                      | Images of glyphs                                      | Dual memory-augmented structure                                                     | Sequential                                          | Glyph images                                     | Component-wise encoded features                             | Fixed persistent memory, dynamic memory                     | Korean-handwriting: 86 fonts, 2448 glyphs per font; Thai-printing: 105 fonts                                                                                                        | Korean-handwriting: Train 80% fonts, 90% glyphs; Thai-printing: similar split; Korean-unrefined for validation                                             | Korean-handwriting dataset (refined by expert designer), Korean-unrefined dataset, Thai-printing dataset | Dual memory structure, compositional generator, self-attention, global-context block                                                    | Dual memory-augmented font generation network   | Encoder: multi-head structure; Decoder: hourglass block, multi-task discriminator                  | SSIM, MS-SSIM, perceptual distance (PD), mean FID (mFID), human preference                                                                  | EMD, FUNIT, AGIS-Net                                                                     | No                                      |
| **RD-GAN**                                         | 2020     | [@RDGANFewZeroShot2020]                    | style transfer, interpolation                                                       | Glyph images                                          | Radical decomposition-and-rendering-based GAN                                       | Sequential                                          | Stylized glyph images                            | Radical embeddings, Style embeddings                        | Not specified                                               | 1473 classes with 50 samples each (D1), 5 samples each (D2), 1473 unseen categories (D3)                                                                                            | D1: same category in training and test, D2: 5 samples per category, D3: unseen categories                                                                  | TKH Dataset (Tripitaka paragraph images)                                                                 | Radical Extraction Module (REM), Radical Rendering Module (RRM), Multi-level Discriminator (MLD)                                        | CNN-based encoder-decoder                       | 2-layer Bi-directional LSTM (BLSTM), convolutional layers, 2D attention mechanism                  | L1 loss, Root Mean Square Error (RMSE), Structural Similarity Index (SSIM)                                                                  | Pix2pix, Cycle-GAN, MC-GAN, Zi2zi, EMD                                                   | No                                      |
| **EmoGAN**                                         | 2020     | [@EmoGanAutomaticChinese2020]              | style transfer, interpolation, font completion                                      | Glyph images                                          | Hierarchical encoder-decoder with Emotion Guidance Module (EGM)                     | Sequential                                          | Glyph images                                     | Emotion embeddings, Style embeddings                        | Not specified                                               | 30 fonts for training, 27 fonts for fine-tuning                                                                                                                                     | Train: 27 fonts (1000 chars each), Fine-tune: 6 fonts (3000 chars each)                                                                                    | Questionnaire system (Tencent platform)                                                                  | Emotional Guidance GAN (EG-GAN), EM Distance, Gradient Penalty, Classification loss                                                     | CNN-based encoder-decoder                       | Multiple convolutional layers, EGM                                                                 | SSIM, PSNR, evaluation questionnaire                                                                                                        | Zi2Zi, EG-GAN 1 (without Gradient Penalty)                                               | Yes                                     |
| **Attribute2Font**                                 | 2020     | [@Attribute2FontCreatingFonts2020]         | style transfer, interpolation, font completion, editing                             | Glyph images                                          | Hierarchical encoder-decoder with Attribute Attention Module (AAM)                  | Sequential                                          | Glyph images                                     | Attribute embeddings                                        | Not specified                                               | 148 labeled fonts, 968 unlabeled fonts                                                                                                                                              | Train: 120 fonts, Val: 28 fonts                                                                                                                            | AttrFont-ENG (O'Donovan et al., 2014)                                                                    | Attribute Attention Module, Semi-supervised learning, Visual Style Transformer                                                          | CNN-based encoder-decoder                       | 16 residual blocks, 4 up-sampling layers, AAM                                                      | IS, FID, LPIPS, SSIM, pixel-level accuracy (pix-acc), Hausdorff, Chamfer                                                                    | AttGAN, StarGAN, RelGAN, STGAN, O'Donovan et al., Chen et al.                            | Yes                                     |
| **CalliGAN**                                       | 2020     | [@CalliGANStyleStructureaware2020]         | style transfer                                                                      | Grayscale images of glyphs                            | Component-based encoder-decoder with multi-domain translation                       | Sequential                                          | Grayscale glyphs                                 | Embedding and component encoding                            | Not specified                                               | 29 calligraphy styles, 47552 images                                                                                                                                                 | Train: 39815 images, Test: 7737 images                                                                                                                     | Constructed by authors                                                                                   | Component-based encoder, U-Net-based generator, multi-domain translation                                                                | GAN-based                                       | 8 encoder and 8 decoder layers, Component encoder with LSTM                                        | MSE, SSIM, Human subject study                                                                                                              | zi2zi, AEGG                                                                              | No                                      |
| **Font2Fonts**                                     | 2020     | [@Font2FontsModifiedImagetoImage2020]      | style transfer, font completion                                                     | Grayscale images of glyphs                            | Conditional GAN with multi-domain translation                                       | Sequential                                          | Grayscale glyphs                                 | Local and global feature representation                     | Not specified                                               | 20 Korean fonts, 2,350 most commonly used Korean Hangul characters                                                                                                                  | Train: 75% (15 fonts), Test: 25% (5 fonts)                                                                                                                 | Constructed by authors                                                                                   | Conditional GAN, Multi-domain translation, Unicode-based font dataset generator                                                         | GAN-based                                       | 7 down-sampling and 7 up-sampling layers with Instance Normalization                               | L1 loss, GAN loss, Style classification loss, MAE, SSIM                                                                                     | pix2pix                                                                                  | No                                      |
| **DeepSVG**                                        | 2020     | [@DeepSVGHierarchicalGenerative2020]       | interpolation, animation, manipulation                                              | SVG commands                                          | Hierarchical Transformer-based architecture                                         | Non-autoregressive                                  | SVG images                                       | Discrete continuous embedding                               | Not specified                                               | 100,000 high-quality icons                                                                                                                                                          | Train/Test split not specified                                                                                                                             | SVG-Icons8, constructed by authors                                                                       | Hierarchical generative network, Non-autoregressive feed-forward model                                                                  | Transformer-based                               | 4 layers in encoder and decoder with 512 feed-forward dimension                                    | Chamfer distance, Reconstruction Error (RE), Interpolation Smoothness (IS)                                                                  | One-stage autoregressive, One-stage feed-forward, SVG-VAE                                | No                                      |
| **Fontender**                                      | 2019     | [@FontenderInteractiveJapanese2019]        | font fusion, text design                                                            | Japanese font images                                  | Dynamic font fusion algorithm                                                       | Not specified                                       | Blended font images                              | Core and thickness of fonts expressed mathematically        | Not specified                                               | 18 types of fonts evaluated by 17 participants                                                                                                                                      | Not specified                                                                                                                                              | Custom dataset (not specified)                                                                           | Dynamic font fusion, impression-based font selection                                                                                    | Not specified                                   | Not specified                                                                                      | User satisfaction (Likert scale), qualitative comparison                                                                                    | Pull down interface, map interface without font fusion                                   | No                                      |
| **Deep Factor**                                    | 2019     | [@DeepFactorizationStyle2019]              | reconstruction, style transfer, interpolation                                       | Grayscale glyph images (64x64)                        | Variational Autoencoder (VAE)                                                       | Transpose Convolutional Process                     | Grayscale glyph images (64x64)                   | Character embeddings and font latent variables              | Not specified                                               | 10,682 fonts                                                                                                                                                                        | Train: 7,649 fonts, Dev: 1,473 fonts, Test: 1,560 fonts                                                                                                    | Capitals64 dataset                                                                                       | Deep matrix factorization, Gaussian prior, orthonormal DCT-II transformation                                                            | VAE                                             | Convolutional layers with transpose convolutions                                                   | L2 reconstruction error, human evaluation (AMT)                                                                                             | GlyphNet, nearest neighbors                                                              | No                                      |
| **Handwritten Chinese Font Generation**            | 2019     | [@HandwrittenChineseFont2019]              | style transfer                                                                      | 64x64 grayscale pixel images of glyphs                | CNN with encoder-decoder and collaborative stroke refinement                        | Not specified                                       | 64x64 grayscale pixel images                     | Not explicitly specified                                    | Not specified                                               | 750 paired training samples                                                                                                                                                         | Train: 750 paired samples                                                                                                                                  | Not specified                                                                                            | Collaborative stroke refinement, online zoom-augmentation, adaptive pre-deformation                                                     | CNN                                             | Encoder-decoder with multiple convolution layers                                                   | RMSE, qualitative human evaluation, user study                                                                                              | HAN, EMD                                                                                 | No                                      |
| **Stroke-Based Representation**                    | 2019     | [@LearningStrokeBasedRepresentation2019]   | interpolation, font completion                                                      | Glyph outlines, stroke-based representations          | Stroke-based geometric model, Bezier curves                                         | Not specified                                       | Vector glyphs                                    | Stroke-based template, Bezier curves                        | PCA, EM-PCA                                                 | 570 fonts                                                                                                                                                                           | Not specified                                                                                                                                              | Online font database                                                                                     | Stroke-based geometric model, PCA, EM-PCA                                                                                               | VAE                                             | Two fully connected layers of sizes 256 and 10                                                     | Fitting error, Interpolation quality, Qualitative analysis                                                                                  | Campbell and Kautz [CK14], Raster-based methods                                          | No                                      |
| **FontRNN**                                        | 2019     | [@FontRNNGeneratingLargescale2019]         | font completion, style transfer                                                     | Sequences of points, stroke skeletons                 | Sequence-to-sequence model with monotonic attention                                 | Sequential                                          | Chinese character skeletons                      | Sequences of points                                         | Not specified                                               | 775 samples for optimal set, 2000 samples for handwriting trajectories                                                                                                              | Optimal set: 775 samples, Handwriting: 2000 samples                                                                                                        | Various Chinese font libraries, CASIA handwriting dataset                                                | Monotonic attention mechanism, Long Short-Term Memory (LSTM), Sequence style transfer                                                   | RNN-based                                       | Encoder with 256 neurons, Decoder with 256 neurons                                                 | DTW (Dynamic Time Warping), User study, Style classification accuracy, Content evaluation via VGG19                                         | pix2pix, DCFont, zi2zi, FontSL                                                           | No                                      |
| **SCFont**                                         | 2019     | [@SCFontStructureGuidedChinese2019]        | style transfer, interpolation, font completion                                      | Glyph images                                          | Deep stacked networks with SkelNet and StyleNet                                     | Sequential                                          | Glyph images                                     | Stroke category prior, Style embeddings                     | Not specified                                               | 70 Chinese font libraries with 6763 characters each                                                                                                                                 | Train: 6000 characters per font, Fine-tune: 775 characters per font                                                                                        | Self-collected and manually corrected strokes                                                            | Skeleton transformation network (SkelNet), Style rendering network (StyleNet), spatial feature transformation (SFT)                     | CNN-based                                       | Contracting and expanding layers, residual blocks, deconvolution layers                            | L1 loss, IOU, user study, visual quality assessment (human judgement)                                                                       | pix2pix, DCFont, zi2zi, FontSL                                                           | No                                      |
| **SVG-VAE**                                        | 2019     | [@SVGVAELearnedRepresentation2019]         | reconstruction, font completion                                                     | SVG commands                                          | Variational Autoencoder (VAE) with convolutional encoder                            | Autoregressive (LSTM)                               | SVG commands                                     | Latent vector z (32-dimensional)                            | Smooth, semantically meaningful                             | 14M font characters                                                                                                                                                                 | Train: 12.6M characters, Test: 1.4M characters                                                                                                             | Google Fonts                                                                                             | Convolutional VAE, Autoregressive SVG decoder, Mixture Density Network (MDN), UMAP visualization of latent space                        | VAE and LSTM-based                              | Convolutional layers for encoder and decoder, 4 stacked LSTM layers for SVG decoder                | Negative log-likelihood, Variance of latent space z                                                                                         | Qualitative assessments, Quantitative assessment using log-likelihood and variance       | No                                      |
| **AGIS-Net**                                       | 2019     | [@AGISNetArtisticGlyph2019]                | style transfer, font completion                                                     | Glyph images                                          | Two encoders for content and style, collaborative decoders for shape and texture    | Sequential                                          | Stylized glyph images                            | Disentangled content and style features                     | Not specified                                               | English: 32,046 synthetic artistic fonts, 35 professional-designed fonts; Chinese: 1,571,940 synthetic artistic glyphs, 256,410 glyphs from 35 professional fonts                   | Train: large-scale dataset for pre-training; Few-shot learning for fine-tuning with English (26 glyphs) and Chinese (7,326 glyphs)                         | Azadi et al. (2018), Guo et al. (2018), Jiang et al. (2017, 2019)                                        | Disentangled content and style, collaborative encoder-decoder architecture, local texture refinement loss                               | GAN (Generative Adversarial Network)            | Six convolution layers and six up-convolution layers in the generator, three discriminators        | Inception Score (IS), Fréchet Inception Distance (FID), structural similarity (SSIM), pixel-level accuracy (pix-acc), user preference study | MC-GAN, TET-GAN, BicycleGAN, MS-Pix2Pix                                                  | No                                      |
| **GlyphGAN**                                       | 2019     | [@GlyphGANStyleconsistentFont2019]         | style transfer, interpolation                                                       | Glyph images                                          | Deep convolutional GAN (DCGAN) architecture                                         | Sequential                                          | Glyph images                                     | Character class vector, Style vector                        | Not specified                                               | 6,561 fonts, 26 uppercase alphabet letters                                                                                                                                          | Train: 90%, Test: 10% of 6,561 fonts                                                                                                                       | Self-collected from various sources                                                                      | Wasserstein GAN (WGAN), gradient penalty, DCGAN, character class and style vectors                                                      | DCGAN-based                                     | Fractionally strided convolutions, strided convolutions in discriminator                           | Legibility (recognition accuracy), Diversity (pseudo-Hamming distance), Style consistency (Cs metric)                                       | DCGAN, WGAN-Clipping                                                                     | No                                      |
| **Font Style Transfer Using Deep Learning**        | 2018     | [@FontStyleTransfer]                       | style transfer                                                                      | Raster images of glyphs                               | Convolutional and fully-connected neural networks                                   | Sequential                                          | Raster images                                    | Vector representation for output                            | Not specified                                               | 1,839 fonts                                                                                                                                                                         | Not specified                                                                                                                                              | Not specified                                                                                            | Convolutional neural networks, Fully-connected neural networks, Generative adversarial networks (GAN), Image as function representation | Encoder-decoder, GAN                            | Convolutional layers, Fully-connected layers                                                       | DSSIM, L1 loss                                                                                                                              | Not specified                                                                            | No                                      |
| **TypeCompGAN**                                    | 2018     | [@TypefaceCompletionGenerative2018]        | font completion                                                                     | Grayscale character images (128x128)                  | GAN (Typeface Completion Network - TCN)                                             | Generative                                          | Grayscale character images (128x128)             | Typeface and content latent vectors                         | Not specified                                               | Chinese: 137,839 images, English: 23,583 images                                                                                                                                     | Train: Chinese: 96,426, English: 16,495; Val: Chinese: 13,776, English: 2,357; Test: Chinese: 27,637, English: 4,733                                       | Collected from TTF and OTF files                                                                         | Multi-domain image-to-image translation, SSIM loss, adversarial loss, perceptual reconstruction loss                                    | ResNet-based GAN                                | ResNet encoders, deconvolutional generator                                                         | SSIM, L1 distance, classification accuracy                                                                                                  | CycleGAN, MUNIT, StarGAN                                                                 | No                                      |
| **Learning to Draw Vector Graphics**               | 2018     | [@LearningDrawVector2018]                  | font completion                                                                     | SVG paths                                             | Variational Autoencoder (VAE)                                                       | Sequential                                          | SVG drawings                                     | Feature vectors for SVG commands                            | Gaussian latent space                                       | 2,552 font faces, 877 font families                                                                                                                                                 | Train: 1920 SVGs per glyph, Test: 240 SVGs per glyph, Validation: 240 SVGs per glyph                                                                       | Google Fonts                                                                                             | End-to-end pipeline, Variational Autoencoder, Bidirectional LSTM, GMM for pen coordinates, Feature encoding variants                    | Variational Autoencoder                         | Dual RNNs with LSTM cells, Layer normalization, GMM in decoder                                     | Hausdorff Distance, Visual inspection                                                                                                       | Comparison with input images and random noise                                            | No                                      |
| **FontGAN**                                        | 2018     | [@FontGANCreatingNew2018]                  | style transfer, interpolation, contour completion                                   | Glyph images, stroke and shape vectors                | Convolutional neural networks (CNN) with manifold learning                          | Sequential                                          | Chinese glyphs                                   | Skeleton and shape vectors                                  | Non-linear manifold (GP-LVM)                                | 72 font libraries, each with 2000 manually labeled characters                                                                                                                       | Train: 72 font libraries, 2000 characters each                                                                                                             | Manually labeled font libraries                                                                          | GAN-based image synthesis, non-rigid point set registration, manifold learning                                                          | CNN, GP-LVM                                     | 7 convolution layers, 7 up-convolution layers                                                      | Pixel-wise loss, Adversarial loss, Qualitative analysis                                                                                     | Comparison with CK14, pix2pix                                                            | No                                      |
| **EasyFont**                                       | 2018     | [@EasyFontStyleLearningBased2018]          | style transfer, cross-modal: text-to-font, contour completion                       | Handwritten character images                          | Non-linear manifold with Gaussian Process Latent Variable Model (GP-LVM)            | Sequential                                          | Synthesized handwriting fonts                    | Stroke skeleton representation                              | Low-dimensional latent space                                | 27,533 Chinese characters for training, smaller subsets for testing                                                                                                                 | Train: multiple subsets (639, 266, 775 characters) for style learning and evaluation                                                                       | Manually created handwriting samples                                                                     | Stroke extraction, non-rigid point set registration, manifold learning                                                                  | GP-LVM, neural networks                         | Not specified                                                                                      | MSE, R values, Turing tests                                                                                                                 | Comparison with Rewrite, pix2pix, zi2zi, NN-Fonts, NN-Manifold                           | Yes                                     |
| **zi2zi**                                          | 2017     | [@Zi2ziMasterChinese2017]                  | style transfer                                                                      | Character images                                      | Conditional generative adversarial network (cGAN)                                   | Sequential                                          | Character images                                 | Continuous embeddings                                       | Continuous latent space                                     | 27 different fonts, approximately 29,000 examples                                                                                                                                   | Train: 29,000 examples, Fine-tune: 2,000-4,000 characters per font                                                                                         | Various sources                                                                                          | Multi-class category loss, Continuous embeddings, Conditional GAN                                                                       | Encoder-Decoder with Unet                       | Encoder: 8 layers (Conv, CIN, ReLU), Decoder: 8 layers (ConvT, CIN, ReLU)                          | Reconstruction loss, Adversarial loss, Category loss                                                                                        | Rewrite, DCFont, FontSL                                                                  | No                                      |
| **DCFont**                                         | 2017     | [@DCFontEndtoendDeep2017]                  | font completion, style transfer                                                     | Handwritten character images                          | Convolutional neural network                                                        | Generative adversarial network (GAN)                | GB2312 font library with 6763 Chinese characters | Deep font features                                          | Not specified                                               | 775 human-written characters plus 5988 machine-generated characters                                                                                                                 | Train: 775 human-written characters, Test: 5988 machine-generated characters                                                                               | Not specified                                                                                            | Font feature reconstruction network, Font style transfer network, Adversarial training                                                  | VGG16 and residual blocks                       | 16-layer VGG for feature extraction, 5 residual blocks for style transfer                          | MSE loss for reconstruction, Adversarial loss for style transfer                                                                            | zi2zi, FontSL, Rewrite                                                                   | No                                      |
| **(MC-GAN)**                                       | 2017     | [@MCGANMultiContentGAN2017]                | font completion, style transfer                                                     | Partial glyph images in various styles                | Stacked conditional GAN with separate networks for glyph and ornamentation          | Sequential                                          | Full glyph sets                                  | Glyph and ornamentation vectors                             | Learned low-dimensional manifold                            | 10,000 fonts with different styles                                                                                                                                                  | Randomly selected subsets from each font for training and testing                                                                                          | Custom dataset created for the study                                                                     | End-to-end GAN pipeline, Conditional GANs, Ornamentation transfer network                                                               | cGAN, ResNet                                    | Six ResNet blocks for each generator; LSGAN loss functions for discriminators                      | L1 loss, LSGAN loss, Perceptual evaluation via user study                                                                                   | Comparison with baseline glyph-outline inference network and text effect transfer method | No                                      |
| **Handwriting Fonts via Style Learning**           | 2016     | [@AutomaticGenerationLargescale2016]       | style transfer                                                                      | Handwritten samples, glyph images                     | Artificial Neural Networks (ANNs)                                                   | Vectorized                                          | Handwritten fonts                                | Trajectories, stroke shape and layout differences           | Not specified                                               | 87 billion Chinese characters in dataset; MinSet: 266 characters, OptSet: 775 characters                                                                                            | Train: not specified, Test: not specified                                                                                                                  | Personal handwriting samples collected through a web application                                         | Artificial Neural Networks (ANNs), stroke trajectory extraction, style learning and synthesis, Coherent Point Drift (CPD) registration  | Feed-forward Neural Network (FFNN)              | 1 hidden layer, 40 units in input, hidden, and output layers                                       | Turing tests with 69 participants, accuracy of distinguishing machine-generated from original handwritings                                  | FlexyFont, FounderType, HAND, Lake et al. (2015)                                         | No                                      |
| **A2Z**                                            | 2016     | [@A2ZSupervisedTransfer2016]               | style transfer, interpolation, font completion                                      | Handwritten character images                          | Variational autoencoder (VAE)                                                       | Extrapolation, generative adversarial network (GAN) | 62-letter fonts with known content and style     | Multivariate Gaussians                                      | Organized latent space, linear combinations of latent means | 1,839 fonts                                                                                                                                                                         | Train: 1,556 fonts, Val: 92 fonts, Test: 191 fonts                                                                                                         | openfontlibrary.org, Fonts used by [21]                                                                  | Extrapolation layer, SSIM cost function, Adversarial sub-networks, In-network and out-of-network image quality assessment               | Variational autoencoder (VAE)                   | Two hidden layers with 500 nodes each, Multilayer perceptron as image generator                    | Mean DSSIM, Structured similarity objective (SSIM), Negative similarity as decoder loss                                                     | M2, Ours-SSIM, Ours-Adv                                                                  | No                                      |
| **FlexyFont**                                      | 2015     | [@FlexyFontLearningTransferring2015]       | font completion, interpolation                                                      | Outline-based glyphs                                  | Stroke-based representation, Part-Similarity Vector (PSV)                           | Part assembly                                       | Complete typefaces                               | Similarity vectors for parts                                | Bayesian Gaussian Process Latent Variable Model (BGPLVM)    | 88 training fonts for uppercase, 57 training fonts for lowercase                                                                                                                    | 60% training, 40% testing                                                                                                                                  | Public font dataset                                                                                      | Decomposition of glyphs into semantic parts, part assembly approach, Bayesian Gaussian Process Latent Variable Model (BGPLVM)           | Generative probabilistic model                  | BGPLVM with mixture density model                                                                  | Similarity between reconstructed parts and reference parts, t-test, visual comparison                                                       | Compared with Suveeranont and Igarashi (2010)                                            | No                                      |
| **Font-MF**                                        | 2014     | [@LearningManifoldFonts2014]               | interpolation, style transfer                                                       | Vector outlines of glyphs                             | Gaussian Process Latent Variable Model (GP-LVM)                                     | Parametric                                          | Font outlines                                    | High dimensional outline vectors                            | Low dimensional manifold (latent space)                     | 46 fonts                                                                                                                                                                            | Not specified                                                                                                                                              | Google Fonts                                                                                             | Energy-based optimization, Dense character matching, Coarse-to-fine approach, GP-LVM                                                    | Gaussian Process Latent Variable Model (GP-LVM) | Not specified                                                                                      | Qualitative visual inspection, Chamfer distance                                                                                             | Not specified                                                                            | No                                      |
| **Easy Chinese Handwritten Fonts**                 | 2011     | [@EasyGenerationPersonal2011]              | reconstruction                                                                      | Handwritten character images                          | Chinese Character Radical Composition Model                                         | Not specified                                       | Handwritten character images                     | Not explicitly specified                                    | Not specified                                               | 522 characters for input samples, 2,500 characters in the output set                                                                                                                | Input: 522 characters, Output: 2,500 characters                                                                                                            | Not specified                                                                                            | Radical reuse, contour curve-based radical clustering, segmentation and construction of characters                                      | Not specified                                   | Not specified                                                                                      | Qualitative comparison with original handwritten fonts                                                                                      | Not specified                                                                            | No                                      |
| **EFG**                                            | 2010     | [@ExampleBasedAutomaticFont2010]           | font completion, style transfer                                                     | Single character outline                              | Weighted blend of outlines and skeletons                                            | Parametric                                          | Complete font set                                | Morphable font model with blending weights                  | Not specified                                               | 32 template fonts representing various styles                                                                                                                                       | Not specified                                                                                                                                              | Not specified                                                                                            | Skin-skeleton model, Blending weights, Gradient descent optimization                                                                    | Not specified                                   | Not specified                                                                                      | Qualitative visual inspection, User study                                                                                                   | Not specified                                                                            | No                                      |
| **ParamFont**                                      | 2001     | [@ParamFontParameterizableFonts2001]       | interpolation, style transfer                                                       | Vector outlines of glyphs                             | Shape components with global, group, and local parameters                           | Parametric                                          | Font outlines                                    | Component-based with parameterizable geometric shapes       | Not specified                                               | Not specified (component-based fonts)                                                                                                                                               | Not specified                                                                                                                                              | Not specified                                                                                            | Shape components, Parameterizable geometric shapes, Global and local parameters                                                         | Not specified                                   | Not specified                                                                                      | Qualitative visual inspection, Parameter variation study                                                                                    | Not specified                                                                            | Yes                                     |