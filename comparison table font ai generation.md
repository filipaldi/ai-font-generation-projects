| Citkey                                     | Short Name              | Name                                                                                                         | Year | Tasks                                                                     | Input Type                             | Input Detail                                        | Encoding Representation                                                             | Decoding Modality                                   | Output Type            | Output Detail                                    | Representation                                               | Latent Space                                                | Datasets Size                                                                                      | Training / Testing Distribution                                                                                                                    | Dataset Source                                                                                               | Techniques and Features                                                                                                                      | Architecture Base                               | Layers                                                                                      | Output Evaluation Methods                                                                                  | Evaluation Comparison                                                              | Type Designer Involvement as expert     |
| ------------------------------------------ | ----------------------- | ------------------------------------------------------------------------------------------------------------ | ---- | ------------------------------------------------------------------------- | -------------------------------------- | --------------------------------------------------- | ----------------------------------------------------------------------------------- | --------------------------------------------------- | ---------------------- | ------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------- | ------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- | --------------------------------------- |
| [@FontStyleInterpolation2024]              | **FontStyleDiff**       | Font Style Interpolation with Diffusion Models                                                               | 2024 | interpolation                                                             | raster images                          | Latin alphabet images (64x64 pixels)                | Conditional diffusion model (U-Net architecture)                                    | Iterative denoising process                         | raster images          | Font images (64x64 pixels)                       | Real-valued condition vectors, noise images                  | Not specified                                               | MyFonts: 17,412 fonts; GoogleFonts: 2,545 fonts                                                    | Train: 13,938 fonts, Val: 1,734 fonts, Test: 1,740 fonts                                                                                           | MyFonts, GoogleFonts                                                                                         | Image-blending, condition-blending, noise-blending approaches                                                                                | Diffusion model, U-Net                          | Denoising U-Net with several layers                                                         | Recognition accuracy, qualitative comparison                                                               | FANnet, Diff-Font                                                                  | No                                      |
| [@EfficientScalableChinese2024]            | **VecFontComp**         | Efficient and Scalable Chinese Vector Font Generation via Component Composition                              | 2024 | reconstruction, zero-shot font extension                                  | vector paths                           | Chinese character components                        | Affine transformation using Spatial Transformer Network                             | Component-based synthesis                           | vector paths           | Chinese character vectors                        | Affine transformation matrices                               | Not specified                                               | 92,560 characters                                                                                  | Train: 80%, Val: 20% from each font dataset                                                                                                        | Created dataset, SourceHanSans, BableStone, AlibabaPuHuiTi, OPPOSansR, SmileySans, YouAiYuanTi, WenDingKaiTi | Affine transformation, component composition                                                                                                 | Spatial Transformer Network                     | Feature extractor (VGG19), Fusion module (Stack, AdaIN, Cross Attention), Regressor (MLP)   | MAE, RMSE, FID, LPIPS                                                                                      | DVF-v2, GAN                                                                        | Font Designer                           |
| [@NeuralStyleTransfer2023a]                | **VectorNST**           | Neural Style Transfer for Vector Graphics                                                                    | 2023 | style transfer                                                            | vector images                          | SVG images with Bezier curves                       | Differentiable Rasterization (DiffVG)                                               | Real-time style transfer                            | vector images          | Stylized SVG images                              | LPIPS features, contour features                             | Differentiable, real-time updated latent space              | 500 vector images                                                                                  | Not specified                                                                                                                                      | FreeSVG                                                                                                      | LPIPS, Contour Loss                                                                                                                          | VGG                                             | VGG 19, 16 Convolutional layers, differentiable rasterization                               | User studies, qualitative comparison                                                                       | DiffVG, Gatys et al.                                                               | Not specified                           |
| [@VecFusionVectorFont2023]                 | **VecFusion**           | VecFusion: Vector Font Generation with Diffusion                                                             | 2023 | missing glyph generation, few-shot vector glyph generation, interpolation | raster images                          | Glyph images (low-resolution)                       | Cascaded diffusion model, transformer-based vector diffusion model                  | Image generation, vector generation                 | vector paths           | Generated vector glyphs                          | Discrete-continuous mixed representation, control points     | Not specified                                               | 1424 fonts, 324K glyphs                                                                            | Train: 314K glyphs, Val: 5K glyphs, Test: 5K glyphs                                                                                                | Google Fonts dataset                                                                                         | Cascaded diffusion, transformer architecture, discrete-continuous representation                                                             | Diffusion model, Transformer                    | U-Net, transformer layers                                                                   | L1 distance, Chamfer distance, control point count difference, vector path count difference                | ChiroDiff, DeepVecFont-v2                                                          | Not specified                           |
| [@FewShotFont2023]                         | **VQ-Font**             | Few-Shot Font Generation via Transferring Similarity-Guided Global Style and Quantization Local Style        | 2023 | few-shot font generation                                                  | raster images                          | Glyph images                                        | VQ-VAE, CNN, cross-attention transformer                                            | Image generation                                    | raster images          | Generated glyph images                           | Global style features, component-level latent codes          | Not specified                                               | 386 fonts, 3,500 characters each                                                                   | Train: 370 fonts, 3,000 characters each; Test: 15 unseen fonts, 3,000 seen characters each; 15 unseen fonts, 500 unseen characters each            | Generated from existing font collections                                                                     | Global and local style aggregation, cross-attention mechanism, contrastive learning, VQ-VAE                                                  | GAN, Transformer                                | Convolutional layers, transformer layers                                                    | RMSE, SSIM, LPIPS, FID, User Study                                                                         | FUNIT, MX-Font, LF-Font, DG-Font, AGIS-Net, FS-Font                                | Not specified                           |
| [@JointImplicitNeural2023]                 | **JINR**                | Joint Implicit Neural Representation for High-fidelity and Compact Vector Fonts                              | 2023 | reconstruction, interpolation                                             | raster images                          | Pixelated font images                               | Joint neural representation (SDF and CF)                                            | Image generation, vector generation                 | vector paths           | Compact vector fonts                             | Signed distance field (SDF), probabilistic corner field (CF) | Not specified                                               | Not specified                                                                                      | Not specified                                                                                                                                      | Not specified                                                                                                | Joint neural representation, corner detection, vectorization, Neural Implicit Fields                                                         | Implicit neural network                         | MLP, HyperNetworks                                                                          | L1 error, SSIM, s-mIoU                                                                                     | Im2Vec, Multi-Implicit, DeepVecFont, Attr2Font                                     | Not specified                           |
| [@DiverseConsistentTypography2023]         | **ConTypeGen**          | Towards Diverse and Consistent Typography Generation                                                         | 2023 | typography generation                                                     | text, vector graphics                  | Text elements, background images, text positions    | Transformer with self-attention                                                     | Autoregressive model                                | vector graphics        | Generated typographic designs                    | Semantic and geometric attributes                            | Not specified                                               | 23,475 templates                                                                                   | Train: 18,780 templates; Test: 2,347 templates; Val: 2,347 templates                                                                               | Crello dataset                                                                                               | Context awareness, structure-preserved sampling, attribute metrics, structure score, diversity score                                         | Transformer                                     | BART-style Transformer blocks, skip connections, MLP layers                                 | Accuracy, MAE, CIEDE2000 color difference, structure score, diversity score                                | MFC, CanvasVAE                                                                     | Not specified                           |
| [@DualVectorUnsupervisedVector2023]        | **DualVector**          | DualVector: Unsupervised Vector Font Synthesis with Dual-Part Representation                                 | 2023 | font reconstruction, font generation                                      | raster images                          | Glyph images                                        | Dual-part representation, Bezier paths                                              | Vectorization, image generation                     | vector paths           | High-quality vector fonts                        | Dual-part vector representation, Bezier paths                | Not specified                                               | 8035 fonts for training, 1425 fonts for evaluation                                                 | Not specified                                                                                                                                      | SVG-Fonts dataset from SVG-VAE                                                                               | Dual-part representation, contour refinement, differentiable rendering, SDF, UDF, Dual-modality learning                                     | Implicit neural network                         | Bezier curves, contour refinement layers                                                    | SSIM, L1, s-IoU                                                                                            | DeepVecFont, Im2Vec, Multi-Implicits, Attr2Font                                    | Not specified                           |
| [@ContourCompletionTransformers2023]       | **Contour Completion**  | Contour Completion by Transformers and Its Application to Vector Font Data                                   | 2023 | contour completion                                                        | contour sequences                      | Contour sequences with missing points               | Sequence embedding                                                                  | Sequence-to-sequence                                | vector paths           | Completed contour sequences                      | 5D vectors (x, y, Contour ID, Point ID, curve flag)          | Not specified                                               | Google Fonts: 489 Serif, 1,275 Sans-Serif, 327 Display, 91 Handwriting                             | Train: 1,777 fonts, Val: 200 fonts, Test: 205 fonts                                                                                                | Google Fonts                                                                                                 | Multi-task learning, Loss functions for contour, point, coordinate, and flags                                                                | Transformer                                     | 4 Transformer layers (Encoder & Decoder)                                                    | L1 distance, Hausdorff distance                                                                            | Standard Transformer-Encoder                                                       | No                                      |
| [@DeepVecFontv2ExploitingTransformers2023] | **DeepVecFont-v2**      | DeepVecFont-v2: Exploiting Transformers to Synthesize Vector Fonts with Higher Quality                       | 2023 | font reconstruction, interpolation, few-shot vector font generation       | raster images, vector graphics         | Glyph images, vector outlines                       | Transformer-based encoder, relaxation representation                                | Autoregressive model, image-to-image translation    | vector paths           | High-quality vector glyphs                       | Relaxation representation, Bezier curves                     | Not specified                                               | 8035 fonts for training, 1425 fonts for evaluation; 212 Chinese fonts for training, 34 for testing | Train: 8035 fonts (English), 212 fonts (Chinese); Test: 1425 fonts (English), 34 fonts (Chinese)                                                   | Publicly available dataset                                                                                   | Relaxation representation, Bezier curve alignment loss, context-based self-refinement, dual-branch architecture                              | Transformer, CNN                                | Transformer layers, CNN layers, MLP layers                                                  | L1 error, IoU, SSIM, qualitative analysis                                                                  | DeepVecFont, DeepSVG                                                               | Not specified                           |
| [@VecFontSDFLearningReconstruct2023]       | **VecFontSDF**          | VecFontSDF: Learning to Reconstruct and Synthesize High-quality Vector Fonts via Signed Distance Functions   | 2023 | font reconstruction, interpolation, few-shot vector font synthesis        | raster images                          | Glyph images                                        | Signed Distance Functions (SDFs)                                                    | Vectorization, image generation                     | vector paths           | High-quality vector fonts                        | Signed Distance Field representation                         | Not specified                                               | 1116 fonts, 128x128 resolution images                                                              | Train: 1000 fonts; Test: 116 fonts                                                                                                                 | Publicly available dataset                                                                                   | SDF-based implicit shape representation, parabolic curves, differentiable rendering, pseudo distance functions                               | Implicit neural network                         | ResNet-18, MLP layers                                                                       | L1 distance, IoU, PSNR, LPIPS, SSIM                                                                        | BSP-Net, IGSR, Im2Vec, Multi-Implicits, DeepVecFont                                | Not specified                           |
| [@FewshotFontGeneration2023]               | **DS-Font**             | Few-shot Font Generation by Learning Style Difference and Similarity                                         | 2023 | font generation                                                           | raster images                          | Glyph images                                        | Multi-layer style projector, contrastive learning                                   | Image-to-image translation                          | raster images          | Generated glyph images                           | Style codes                                                  | Not specified                                               | 847 fonts, 1000 Chinese characters, 52 Latin letters each                                          | Train: 847 fonts; Test: UCSF, UFSC sets                                                                                                            | FTransGAN dataset                                                                                            | Multi-layer style projector, cluster-level contrastive style loss, multi-task patch discriminator                                            | GAN, attention mechanism                        | Convolutional layers, MLP layers                                                            | L1 loss, LPIPS, RMSE, accuracy, FID                                                                        | DG-Font, MX-Font, LF-Font, MF-Net, FTransGAN                                       | Not specified                           |
| [@SVGformerRepresentationLearning2023]     | **SVGformer**           | SVGformer: Representation Learning for Continuous Vector Graphics Using Transformers                         | 2023 | reconstruction, classification, interpolation, retrieval                  | vector graphics                        | SVG commands                                        | Transformer-based model, geometric self-attention                                   | Sequence generation                                 | vector graphics        | SVG commands                                     | Geometric segments, continuous token embedding               | Not specified                                               | Not specified                                                                                      | Not specified                                                                                                                                      | Publicly available datasets                                                                                  | Geometric self-attention, 1D convolutional embedding, graph convolution network (GCN)                                                        | Transformer                                     | Geometric self-attention layers, GCN layers, fully connected layers                         | Chamfer distance, classification accuracy, retrieval accuracy                                              | DeepSVG, LayoutTransformer                                                         | Not specified                           |
| [@UsingAutoencodersGenerate2023]           | **SkeletonGenType**     | Using Autoencoders to Generate Skeleton-Based Typography                                                     | 2023 | interpolation, font completion                                            | raster images                          | Skeleton images of Latin capital letters (64x64px)  | Variational Autoencoder (VAE) with Sketch Decoder                                   | Image generation                                    | raster images          | Interpolated and generated skeleton images       | Skeleton points and stroke width                             | Not specified                                               | 2623 fonts, 26 characters each                                                                     | Not specified                                                                                                                                      | Google Fonts, custom dataset                                                                                 | VAE, LSTM, differentiable rasterization, stroke width interpolation                                                                          | VAE, LSTM                                       | Convolutional layers, LSTM, transpose layers                                                | Reconstruction quality, user study                                                                         | Not specified                                                                      | Not specified                           |
| [@CharacterAwareModelsImprove2022]         | **CharAw**              | Character-Aware Models Improve Visual Text Rendering                                                         | 2022 | text rendering, spelling correction                                       | text                                   | Text input with character-level features            | Character-aware text encoder, token-level encoder                                   | Text-to-image generation                            | raster images          | Rendered text in images                          | Character-level embeddings, token embeddings                 | Not specified                                               | Laion-400M                                                                                         | Not specified                                                                                                                                      | Publicly available dataset                                                                                   | Character-aware text encoding, hybrid encoding, WikiSpell, DrawText benchmark                                                                | Transformer                                     | Self-attention layers, embedding layers, convolutional layers                               | OCR-based metrics, human ratings, DrawText benchmark                                                       | Stable Diffusion, DALL-E, Imagen, Parti                                            | Not specified                           |
| [@FewShotCrossLingualFont2022]             | **GAS-NeXt**            | GAS-NeXt: Few-Shot Cross-Lingual Font Generator                                                              | 2022 | cross-modal                                                               | raster images                          | Font glyph images                                   | Layer attention, context-aware attention                                            | Image generation                                    | raster images          | Cross-lingual stylized font images               | Shape, texture, local feature vectors                        | Not specified                                               | Not specified                                                                                      | Not specified                                                                                                                                      | Multiple languages and datasets                                                                              | Layer attention, context-aware attention, shape, texture, and local discriminators                                                           | GAN                                             | Convolutional layers, attention layers                                                      | FID, SSIM, Pixel-level Accuracy                                                                            | Font Translator GAN, AGIS-Net                                                      | Not specified                           |
| [@DiffFontDiffusionModel2022]              | **Diff-Font**           | Diff-Font: Diffusion Model for Robust One-Shot Font Generation                                               | 2022 | font completion                                                           | raster images                          | Font glyph images                                   | Conditional diffusion model                                                         | Image generation                                    | raster images          | Generated font images                            | Stroke encoding, style encoding                              | Not specified                                               | 410 fonts, 6625 characters each                                                                    | Train: 400 fonts, 800 characters each; Test: 10 fonts, 800 characters each                                                                         | Collected from various sources                                                                               | Stroke-aware conditional module, count encoding for strokes, multi-attribute conditional diffusion model                                     | Diffusion model, U-Net                          | Convolutional layers, attention layers                                                      | SSIM, RMSE, LPIPS, FID                                                                                     | FUNIT, MX-Font, DG-Font                                                            | Not specified                           |
| [@NeuralFontRendering2022]                 | **NeuralFontRendering** | Neural Font Rendering                                                                                        | 2022 | font rendering                                                            | vector graphics                        | Glyph outlines                                      | Implicit neural representation                                                      | Rasterization                                       | raster images          | Glyph bitmaps                                    | Neural implicit functions                                    | Not specified                                               | Not specified                                                                                      | Not specified                                                                                                                                      | Not specified                                                                                                | Implicit neural representation, frequency encoding, multi-resolution outputs, rasterization via sampling                                     | Implicit neural network                         | MLP layers                                                                                  | Pixelwise loss, mean pixel error                                                                           | Traditional rasterization with hinting                                             | Not specified                           |
| [@FontRepresentationLearning2022]          | **PGM**                 | Font Representation Learning via Paired-glyph Matching                                                       | 2022 | font retrieval, font style transfer, font generation                      | raster images                          | Glyph images                                        | Paired-glyph matching-based font representation                                     | Not applicable                                      | vector representations | Font embeddings                                  | Latent space embeddings                                      | Not specified                                               | O’Donovan dataset: 1,088 fonts; Open Font Library (OFL): 3,802 fonts; Capitals64: 10,682 fonts     | Train: O’Donovan (1,088 fonts), OFL (3,702 fonts), Capitals64 (7,649 fonts); Test: O’Donovan (28 fonts), OFL (100 fonts), Capitals64 (1,560 fonts) | O’Donovan, Open Font Library, Capitals64                                                                     | Paired-glyph matching, cosine similarity, temperature-scaled cross-entropy loss                                                              | ResNet                                          | ResNet 18, Convolutional layers, fully connected layers                                     | Retrieval mean accuracy (MACCRet)                                                                          | Classification, Style Transfer, Autoencoder, Attribute Prediction                  | Not specified                           |
| [@FSFontFewShotFont2022]                   | **FS-Font**             | FS-Font: Few-Shot Font Generation by Learning Fine-Grained Local Styles                                      | 2022 | font completion                                                           | raster images                          | Glyph images                                        | Cross-attention based style aggregation                                             | Image generation                                    | raster images          | Generated font images                            | Fine-grained local style representations                     | Not specified                                               | 407 fonts, 3396 characters each                                                                    | Train: 397 fonts, 2896 characters; Test: 10 fonts, 2896 characters                                                                                 | Various fonts including handwriting, printed, and artistic fonts                                             | Style aggregation module, self-reconstruction branch, reference selection                                                                    | GAN                                             | Convolutional blocks, residual blocks, attention layers                                     | L1 loss, RMSE, SSIM, LPIPS, user studies                                                                   | FUNIT, DG-Font, MX-Font, AGIS-Net, LF-Font                                         | Not specified                           |
| [@GenTextUnsupervisedArtistic2022]         | **GenText**             | GenText: Unsupervised Artistic Text Generation via Decoupled Font and Texture Manipulation                   | 2022 | style transfer, font transfer                                             | raster images                          | Artistic text images                                | Unified encoder, separate style generators                                          | Image generation                                    | raster images          | Generated artistic text images                   | Spatial code, global style code                              | Not specified                                               | TE141K dataset: 152 textures, including Chinese, English, and symbols                              | Train: Chinese characters; Test: English alphabets and special symbols                                                                             | TE141K dataset                                                                                               | Style aggregation, unsupervised learning, three-stage generation (stylization, destylization, font transfer)                                 | GAN                                             | Encoder with residual blocks, generators with upsampling blocks                             | PSNR, SSIM, perceptual loss, style loss                                                                    | AdaIN, StyleGAN2, TET-GAN                                                          | Not specified                           |
| [@SVGVecFontSVGVector2022]                 | **SVGVecFont**          | SVGVecFont: SVG Vector Font Generation for Chinese Characters with Transformer                               | 2022 | font generation, style transfer                                           | vector graphics                        | SVG paths                                           | Transformer-based hierarchical encoder                                              | Sequence generation                                 | vector graphics        | SVG paths                                        | Style features, content features                             | Not specified                                               | 66 sans-serif fonts, 800 characters each                                                           | Train: 59 fonts; Test: 7 fonts                                                                                                                     | Products of Fontworks Inc. and free fonts from the Web                                                       | Hierarchical Transformer, AdaIN, Chamfer loss, argument loss                                                                                 | Transformer                                     | Transformer blocks, MLP layers                                                              | Rasterized pixel distance, Chamfer distance                                                                | DeepSVG, DeepVecFont                                                               | Not specified                           |
| [@FontGenerationMissing2022]               | **FontGenImpression**   | Font Generation with Missing Impression Labels                                                               | 2022 | font generation                                                           | raster images                          | Font glyph images                                   | Co-occurrence-based missing label estimator, impression label space compressor      | Image generation                                    | raster images          | Generated font images                            | Impression labels, character class condition                 | Not specified                                               | 17,202 fonts, 1,430 impression labels                                                              | Not specified                                                                                                                                      | MyFonts dataset                                                                                              | Co-occurrence-based missing label estimator, impression label space compressor, progressive structure, style consistency discriminator       | GAN                                             | Convolutional layers, encoder-decoder layers                                                | FID, Intra-FID, mAP-train, mAP-test                                                                        | C-GAN, AC-GAN, CP-GAN, Imp2Font                                                    | Not specified                           |
| [@FontNetClosingGap2022]                   | **FontNet**             | FontNet: Closing the gap to font designer performance in font synthesis                                      | 2022 | font generation                                                           | raster images                          | Font glyph images                                   | StyleGAN-based font separator network                                               | Image generation                                    | raster images          | Generated font images                            | Style embeddings, content embeddings                         | Not specified                                               | 90 Korean fonts, 2,350 Korean characters                                                           | Train: 75% fonts, 2,000 characters; Test: 25% fonts, 350 characters                                                                                | Naver public fonts                                                                                           | Style embedding learning, triplet loss, modified StyleGAN generator                                                                          | GAN                                             | Convolutional layers, encoder-decoder layers                                                | SSIM, mean FID (mFID), top-1 accuracy                                                                      | MX-Font, FUNIT                                                                     | Not specified                           |
| [@SEGANSkeletonEnhanced2022]               | **SE-GAN**              | SE-GAN: Skeleton Enhanced GAN-based Model for Brush Handwriting Font Generation                              | 2022 | style transfer                                                            | raster images                          | Brush handwriting font images                       | GAN with Self-attentive Refined Attention Module (SAttRAM)                          | Skeleton-enhanced GAN                               | raster images          | Generated brush handwriting font images          | Skeleton and style features                                  | Disentangled latent space                                   | 15,799 images                                                                                      | Train: 80%, Dev: 10%, Test: 10%                                                                                                                    | Collected dataset of brush handwriting font images                                                           | GAN, SAttRAM, skeleton extraction, multi-domain translation                                                                                  | GAN                                             | Residual blocks, SAttRAM, dual discriminators                                               | Content accuracy, FID, user preference                                                                     | zi2zi, CycleGAN, StarGAN, DF-Font                                                  | Fine Arts Students                      |
| [@ArbitraryFontGeneration2022]             | **ArbitFontGen*         | Arbitrary Font Generation by Encoder Learning of Disentangled Features                                       | 2022 | style transfer                                                            | raster images                          | Raster images of fonts                              | Spatial representation                                                              | Image-to-image translation                          | raster images          | Font images                                      | Disentangled features of text content and font style         | N/A                                                         | Korean: 238 train, 40 test; Chinese: 185 train, 15 test; English: 185 train, 15 test               | Train: 85%, Test: 15%                                                                                                                              | Noonnu, Internet, Chinese Font Design                                                                        | Stacked input, Consistency loss, VGG-19, AdaIN, Hallucinated stack                                                                           | VGG                                             | VGG 19, 16 Convolutional layers, AdaIN layers, ConvBlock layers                             | FID, L1 distance, Perceptual distance                                                                      | FUNIT, EMD                                                                         | No                                      |
| [@CVFontSynthesizingChinese2022]           | **CVFont**              | CVFont: Synthesizing Chinese Vector Fonts via Deep Layout Inferring                                          | 2022 | style transfer                                                            | raster images                          | Raster images of glyphs                             | Hierarchical approach to component extraction, using CPD algorithm for registration | Sequential                                          | vector paths           | Chinese vector fonts                             | Components and strokes                                       | Multi-scale                                                 | GB2312 Kaiti font library (6763 characters), 70 Chinese fonts                                      | Pre-train: 60 fonts, Online: 10 fonts, Testing: 69 fonts                                                                                           | Founder Group                                                                                                | Layout prediction with Faster R-CNN, U-Net based generator, Skeleton extraction, Shape decomposition                                         | ResNet, U-Net                                   | ResNet-101 backbone, U-Net generator with 3 downsampling layers, Faster R-CNN detector      | IoU scores, Qualitative user study                                                                         | Rewrite, pix2pix, CycleGAN, EasyFont, zi2zi                                        | Yes                                     |
| [@XMPFontSelfSupervisedCrossModality2022]  | **XMP-Font**            | XMP-Font: Self-Supervised Cross-Modality Pre-Training for Few-Shot Font Generation                           | 2022 | font completion                                                           | raster images                          | Glyph images, stroke labels                         | Cross-modality representation                                                       | Cross-modality                                      | raster images          | Glyphs                                           | Stroke-level, component-level, character-level styles        | Pre-trained with self-supervised signals                    | 100 font styles                                                                                    | Train: 90%, Test: 10%                                                                                                                              | Founder font libraries                                                                                       | Cross-modality transformer-based encoder, ECA modules, LSTM-based stroke loss                                                                | Transformer                                     | Cross-modality encoder with BERT layers, 4 ECA modules                                      | FID, PSNR, SSIM, L1, User study                                                                            | StarGAN-v2, FUNIT, LF-Font, MX-Font, DG-Font                                       | No                                      |
| [@SharedLatentSpace2022]                   | **NoisyImpressions**    | Shared Latent Space of Font Shapes and Their Noisy Impressions.                                              | 2022 | cross-modal: shape-to-impression, impression-to-shape                     | raster images                          | Glyph images, impression words                      | Shared latent space representation                                                  | Cross-modal                                         | raster images          | Glyph images, impression words                   | Vector representations for font shapes and impression words  | Shared latent space with DeepSets                           | MyFonts: 18,815 fonts                                                                              | Train: 9,980, Validation: 2,992, Test: 1,223                                                                                                       | MyFonts dataset                                                                                              | DeepSets for shape-relevant impression filtering, cross-modal autoencoders                                                                   | Autoencoder, ResNet                             | ResNet 18 encoder, deconvolutional layers for decoder                                       | Precision@K, average retrieval rank, Hausdorff distance                                                    | Impressions2Font                                                                   | No                                      |
| [@StrokeStylesStrokebasedSegmentation2022] | **StrokeStyles**        | Stroke-based Segmentation and Stylization of Fonts.                                                          | 2022 | style transfer                                                            | vector paths                           | Glyph outlines                                      | Stroke-based segmentation with curvilinear shape features and augmented medial axis | Parametric                                          | raster images          | Stylized glyphs                                  | Shape components and stroke-based representation             | Not specified                                               | Not specified                                                                                      | Not specified                                                                                                                                      | Not specified                                                                                                | Stroke-based segmentation, Curvilinear shape features, Augmented medial axis, Junction types                                                 | Not specified                                   | Not specified                                                                               | Qualitative visual inspection, User study                                                                  | Not specified                                                                      | No                                      |
| [@FontRepresentationLearning2022]          | **PGM**                 | Font Representation Learning via Paired-glyph Matching                                                       | 2022 | font generation, style transfer                                           | raster images                          | Glyph images (62 alphanumeric characters)           | ResNet18 with cosine similarity                                                     | Image generation                                    | raster images          | Generated glyph images                           | Font embeddings in latent space                              | 512-dimensional latent space                                | 1,088 fonts (O’Donovan), 3,802 fonts (OFL), 7,649 fonts (Capitals64)                               | 1,088 training, 28 validation (O’Donovan), 3,702 training, 100 validation (OFL), 7,649 training, 1,473 validation (Capitals64)                     | O’Donovan, OFL, Capitals64                                                                                   | Paired-glyph matching, cosine similarity, temperature scaling                                                                                | ResNet                                          | ResNet 18, Convolutional layers, projection head, L2 normalization                          | MACC Ret, qualitative analysis                                                                             | Classification, Style Transfer, Autoencoder                                        | Not specified                           |
| [@CKFontFewShotKorean2021]                 | **CKFont**              | CKFont: Few-Shot Korean Font Generation based on Hangul Composability                                        | 2021 | font completion                                                           | raster images                          | Glyph images                                        | Spatial representation                                                              | Sequential                                          | raster images          | Glyphs                                           | Character-level styles                                       | Pre-trained with self-supervised signals                    | 2,350 glyphs                                                                                       | Train: 2,000, Test: 350                                                                                                                            | Hangul standard code system (KS X 1001)                                                                      | Conditional GAN, dual encoders, style extraction from components                                                                             | GAN                                             | 6 convolutional layers in each encoder, 6 deconvolutional layers in the decoder             | L1, L2, SSIM, FID                                                                                          | zi2zi, SKFont                                                                      | No                                      |
| [@ScalableFontReconstruction2021]          | **DualFont-MF**         | Scalable Font Reconstruction with Dual Latent Manifolds                                                      | 2021 | reconstruction                                                            | raster images                          | Glyph images                                        | Dual latent manifolds representation                                                | Matrix factorization                                | raster images          | Glyph images                                     | Vector representations for font style and character shape    | Dual latent spaces with Gaussian priors                     | Google Fonts: 2017 fonts, Chinese Simplified: 623 fonts                                            | Train: 60%, Dev: 20%, Test: 20%                                                                                                                    | Google Fonts, Chinese Simplified dataset                                                                     | Dual manifold model, adaptive wavelet loss, U-Net architecture                                                                               | U-Net                                           | Encoder: convolutional layers, Decoder: transposed convolutional layers with MLP parameters | SSIM, L2, Human evaluation (Amazon Mechanical Turk)                                                        | EMD, Nearest Neighbor                                                              | No                                      |
| [@CCFontComponentBasedChinese2022]         | **CCFont**              | CCFont: Component-Based Chinese Font Generation Model Using Generative Adversarial Networks (GANs)           | 2022 | style transfer, zero-shot font generation                                 | vector images                          | Chinese character components                        | Component-based GAN                                                                 | End-to-end GAN model                                | vector images          | Generated Chinese character components           | Component vectors                                            | Component-based latent space                                | 2003 TC characters, 15 SC characters                                                               | Train: 2003 TC characters, 19 font styles                                                                                                          | Collected dataset, GB2312, GBK21003                                                                          | Component-based decomposition and recombination, zero-shot font generation                                                                   | GAN                                             | Convolutional layers, instance normalization, skip connections                              | Character and style loss, L1 loss, GAN loss                                                                | zi2zi, DCFont, SCFont                                                              | Not specified                           |
| [@DeepVecFontSynthesizingHighquality2021]  | **DeepVecFont**         | DeepVecFont: Synthesizing High-quality Vector Fonts via Dual-modality Learning                               | 2021 | font completion, interpolation                                            | raster images, vector paths            | Raster images, vector outlines                      | Dual-modality representation                                                        | Sequential                                          | vector paths           | Vector glyphs                                    | Image-aspect and sequence-aspect features                    | Latent space with Gaussian priors                           | 8K fonts for training, 1.5K for testing                                                            | Train: 8K fonts, Test: 1.5K fonts                                                                                                                  | SVG-Fonts Dataset                                                                                            | Dual-modality learning, differentiable rasterization, Mixture Density Network                                                                | CNN, RNN                                        | Convolutional layers, LSTM layers                                                           | L1 loss, Perceptual loss, Cross-Entropy loss, MDN loss                                                     | SVG-VAE, DeepSVG, Im2Vec                                                           | No                                      |
| [@FontCompletionManipulation2021]          | **CycleFont**           | Font Completion and Manipulation by Cycling Between Multi-Modality Representations                           | 2021 | font completion, interpolation, manipulation                              | raster images, vector paths, poit sets | Raster images, SVG curves, point sets               | Multi-modality representation (image-to-graph-to-image)                             | Multi-modality (graph-based)                        | raster images          | Glyph images                                     | Graph-based representation                                   | Latent space with graph representation                      | Google Fonts: 2693 fonts, 55,554 glyphs                                                            | Train: 95%, Test: 5%                                                                                                                               | Google Fonts dataset                                                                                         | Cross-modality auto-encoder, graph-based representation                                                                                      | Graph-based, Autoencoder                        | Image encoder (Conv2D), point set decoder, graph constructor, neural renderer               | MSE, PSNR, SSIM                                                                                            | TCN                                                                                | No                                      |
| [@LearningImplicitGlyph2021]               | **ImplicitGlyph**       | Learning Implicit Glyph Shape Representation                                                                 | 2021 | interpolation, style transfer                                             | raster images                          | Raster images                                       | Implicit representation                                                             | Implicit function decoding                          | raster images          | Glyph images                                     | Signed distance functions with quadratic curves              | Continuous 2D space                                         | 26390 glyph images                                                                                 | Train: 26390 images, Validation: dataset split                                                                                                     | Custom dataset                                                                                               | Implicit representation, quadratic curves, disentangled encoder, auxiliary character classifier                                              | CNN, ResNet                                     | ResNet-18 encoder, MLP for curve parameters                                                 | SSIM, LPIPS, L1 distance, User study                                                                       | VAE, pix2pix, AGIS-Net, FANnet                                                     | No                                      |
| [@LearningPerceptualManifold2021]          | **PerceptFont-MF**      | Learning Perceptual Manifold of Fonts                                                                        | 2021 | font generation, style transfer                                           | raster images                          | Glyph images of Latin capital letters (28x28px)     | Variational Autoencoder (VAE)                                                       | Image generation                                    | raster images          | Generated glyph images                           | Latent space, perceptual adjustment                          | 5-dimensional latent space                                  | 2169 fonts, capital letter 'A'                                                                     | Not specified                                                                                                                                      | Google Fonts                                                                                                 | VAE, manifold learning, t-SNE, user interface for perceptual adjustment                                                                      | VAE                                             | Convolutional layers, latent layers                                                         | SSIM, user study                                                                                           | Traditional font-exploring interface                                               | Not specified                           |
| [@FontRLChineseFont2021]                   | **FontRL**              | FontRL: Chinese Font Synthesis via Deep Reinforcement Learning                                               | 2021 | font completion                                                           | raster images                          | Font glyph images                                   | Deep reinforcement learning, Thin-Plate Spline (TPS) transformation                 | Image generation                                    | raster images          | Generated Chinese font images                    | Character skeleton, stroke skeleton                          | Not specified                                               | 6763 Chinese characters in 5 different font styles                                                 | 775 Chinese characters for training                                                                                                                | Jiang et al. (2019) dataset                                                                                  | Deep reinforcement learning, TPS transformation, bounding box prediction, image-to-image translation                                         | CNN                                             | ResNet18, ResNet34, convolutional layers                                                    | L1 loss, IoU                                                                                               | FontSL, FontRNN, SCFont, zi2zi, DCFont, pix2pix                                    | Not specified                           |
| [@LFFontFewshotFont2021]                   | **LF-Font**             | Few-shot Font Generation with Localized Style Representations and Factorization                              | 2021 | font completion                                                           | raster images                          | Glyph images                                        | Localized style representations, factorization modules                              | Image generation                                    | raster images          | Generated font images                            | Component-wise local style representations                   | Not specified                                               | 482 Chinese fonts, 19,514 characters each                                                          | Train: 467 fonts, 19,234 characters; Test: 15 fonts, 280 characters                                                                                | Public Chinese font library                                                                                  | Localized style encoder, component factorization, adversarial loss, consistency loss                                                         | GAN                                             | Convolutional layers, encoder-decoder layers                                                | LPIPS, style-aware accuracy, content-aware accuracy, FID                                                   | SA-VAE, EMD, AGIS-Net, FUNIT, DM-Font                                              | Not specified                           |
| [@StrokeGANReducingMode2021]               | **StrokeGAN**           | StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke Encoding                             | 2021 | font completion                                                           | raster images                          | Font glyph images                                   | One-bit stroke encoding                                                             | Image generation                                    | raster images          | Generated Chinese font images                    | Stroke encoding                                              | Not specified                                               | 9 datasets with different fonts                                                                    | 90% training, 10% testing                                                                                                                          | Collected from internet, CASIA-HWDB1.1                                                                       | One-bit stroke encoding, stroke-encoding reconstruction loss, CycleGAN                                                                       | CycleGAN                                        | Convolutional layers, residual blocks                                                       | Content accuracy, recognition accuracy, stroke error                                                       | CycleGAN, zi2zi, Chinese typography transfer (CTT)                                 | Not specified                           |
| [@DGFontDeformableGenerative2021]          | **DG-Font**             | DG-Font: Deformable Generative Networks for Unsupervised Font Generation                                     | 2021 | font completion                                                           | raster images                          | Font glyph images                                   | Feature deformation skip connection (FDSC), deformable convolution                  | Image generation                                    | raster images          | Generated Chinese font images                    | Style and content separation                                 | Not specified                                               | 410 fonts, 990 characters each                                                                     | Train: 400 fonts, 800 characters; Test: 10 fonts, 190 characters                                                                                   | Collected from internet, handwritten and printed fonts                                                       | FDSC, deformable convolution layers, multi-task discriminator, reconstruction losses                                                         | GAN                                             | Convolutional layers, residual blocks                                                       | L1 loss, RMSE, SSIM, LPIPS, FID                                                                            | CycleGAN, Zi2zi, GANimorph, FUNIT, EMD                                             | Not specified                           |
| [@RadicalCompositionNetwork2021]           | **RCN**                 | Radical Composition Network for Chinese Character Generation                                                 | 2021 | style transfer                                                            | raster images                          | Chinese character images                            | Tree-structured RNN, DenseNet                                                       | Image generation                                    | raster images          | Generated Chinese characters                     | Radical vectors, spatial vectors                             | Not specified                                               | 114,665 printed characters, 2,674,784 handwritten characters                                       | Train: 114,665 printed characters, Test: 20,860 printed characters; Train: 2,674,784 handwritten characters, Test: 3,277 handwritten characters    | Generated from existing Chinese characters, HWDB1.0, HWDB1.1, HWDB1.2                                        | Radical combination, perceptual loss, self-recurrent structure                                                                               | Tree-structured RNN, GAN                        | DenseNet, GRU, deconvolution layers                                                         | Recognition rate, qualitative analysis                                                                     | Not specified                                                                      | Not specified                           |
| [@SkelGANFontImage2021]                    | **SkelGAN**             | SkelGAN: A Font Image Skeletonization Method                                                                 | 2021 | skeletonization                                                           | raster images                          | Font character images (256x256 pixels, RGB)         | Modified U-Net with style and character class vectors                               | Image-to-image translation                          | raster images          | Skeletonized font images                         | Style vectors, character class vectors                       | Not specified                                               | 30 different font files, 2,350 characters each                                                     | Not specified                                                                                                                                      | Generated from existing font files                                                                           | Style classification, character classification, adversarial loss, L1 loss                                                                    | GAN                                             | Modified U-Net, convolutional layers, fully connected layers                                | SSIM, L1 loss, qualitative comparison                                                                      | Pix2pix                                                                            | Not specified                           |
| [@AdaptiFontIncreasingIndividuals2021]     | **AdaptiFont**          | AdaptiFont: Increasing Individuals                                                                           | 2021 | adaptive design, reading speed optimisation                               | text data                              | Text data                                           | Non-negative matrix factorization (NMF)                                             | Generative                                          | vector paths           | TrueType fonts                                   | NMF basis vectors                                            | Not specified                                               | 25 classic fonts                                                                                   | 7 subjects, 250 texts each                                                                                                                         | Custom collected from Twitter pages of news platforms                                                        | Bayesian optimization, human-in-the-loop system, generative font space                                                                       | Not specified                                   | NMF with 3 components                                                                       | Reading speed (words per minute), Bayesian ANOVA, Bayesian Pearson Correlation                             | Traditional fonts comparison (Kolmogorov-Smirnov test)                             | No                                      |
| [@FewShotFontStyle2021]                    | **FTransGAN**           | Few-Shot Font Style Transfer Between Different Languages                                                     | 2021 | style transfer, few-shot font generation                                  | raster images                          | English and Chinese character images (64x64 pixels) | Context-aware Attention Network, Layer Attention Network, Conditional GAN           | Forward pass image generation                       | raster images          | Generated cross-language font images             | Content and style feature vectors                            | Not specified                                               | 847 fonts                                                                                          | Train: 818 fonts, Test: 29 fonts                                                                                                                   | Created dataset from various fonts                                                                           | Context-aware attention, Layer attention, few-shot learning                                                                                  | Conditional GAN                                 | Convolutional layers, ResNet blocks                                                         | MAE, SSIM, MS-SSIM, FID, User preference                                                                   | EMD, DFS                                                                           | Not specified                           |
| [@DeepSVGHierarchicalGenerative2020]       | **DeepSVG**             | DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation                                     | 2020 | interpolation, animation, manipulation                                    | vector images                          | SVG images with paths and Bézier curves             | Hierarchical Transformer-based network                                              | Non-autoregressive decoding                         | vector images          | Generated SVG images                             | Latent vectors                                               | Hierarchical latent space                                   | 100,000 SVG icons                                                                                  | Not specified                                                                                                                                      | SVG-Icons8                                                                                                   | Feed-forward prediction, positional embedding, hierarchical encoding                                                                         | Transformer                                     | Transformer layers with feed-forward prediction                                             | Human study, Chamfer distance, Reconstruction Error (RE), Interpolation Smoothness (IS)                    | One-stage autoregressive, SVG-VAE, Sketchformer                                    | Not specified                           |
| [@Font2FontsModifiedImagetoImage2020]      | **Font2Fonts**          | Font2Fonts: A modified Image-to-Image translation framework for font generation                              | 2020 | style transfer, font completion                                           | raster images                          | Grayscale images of glyphs                          | Conditional GAN with multi-domain translation                                       | Sequential                                          | raster images          | Grayscale glyphs                                 | Local and global feature representation                      | Not specified                                               | 20 Korean fonts, 2,350 most commonly used Korean Hangul characters                                 | Train: 75% (15 fonts), Test: 25% (5 fonts)                                                                                                         | Constructed by authors                                                                                       | Conditional GAN, Multi-domain translation, Unicode-based font dataset generator                                                              | GAN                                             | 7 down-sampling and 7 up-sampling layers with Instance Normalization                        | L1 loss, GAN loss, Style classification loss, MAE, SSIM                                                    | pix2pix                                                                            | No                                      |
| [@CalliGANStyleStructureaware2020]         | **CalliGAN**            | CalliGAN: Style and Structure-aware Chinese Calligraphy Character Generator                                  | 2020 | style transfer                                                            | raster images                          | Chinese calligraphy character images                | Component encoder, conditional GAN                                                  | Image-to-image translation                          | raster images          | Generated calligraphy characters                 | Component and style vectors                                  | Not specified                                               | 47,552 images                                                                                      | Train: 39,815 images, Test: 7,737 images                                                                                                           | Chinese calligraphy character image repository                                                               | Component encoder, multi-style image translation, U-Net based generator                                                                      | GAN                                             | Convolutional layers, U-Net                                                                 | MSE, SSIM, human subject study                                                                             | zi2zi, AEGG                                                                        | Calligraphy experts, college students   |
| [@Attribute2FontCreatingFonts2020]         | **Attribute2Font**      | Attribute2Font: Creating Fonts You Want From Attributes                                                      | 2020 | style transfer, interpolation, font completion, editing                   | raster images                          | Glyph images                                        | Hierarchical encoder-decoder with Attribute Attention Module (AAM)                  | Sequential                                          | raster images          | Glyph images                                     | Attribute embeddings                                         | Not specified                                               | 148 labeled fonts, 968 unlabeled fonts                                                             | Train: 120 fonts, Val: 28 fonts                                                                                                                    | AttrFont-ENG (O'Donovan et al., 2014)                                                                        | Attribute Attention Module, Semi-supervised learning, Visual Style Transformer                                                               | CNN, encoder-decoder                            | 16 residual blocks, 4 up-sampling layers, AAM                                               | IS, FID, LPIPS, SSIM, pixel-level accuracy (pix-acc), Hausdorff, Chamfer                                   | AttGAN, StarGAN, RelGAN, STGAN, O'Donovan et al., Chen et al.                      | Yes                                     |
| [@AutomaticChineseFont2020]                | **EmoGAN**              | EmoGAN: Automatic Chinese Font Generation System Reflecting Emotions Based on Generative Adversarial Network | 2020 | style transfer                                                            | raster images                          | Chinese character images                            | Conditional GAN with emotion-guided operation                                       | Image-to-image translation                          | raster images          | Emotion-reflective font images                   | Feature vectors, emotion vectors                             | Not specified                                               | 110 Chinese fonts, multiple samples per font                                                       | Not specified                                                                                                                                      | Tencent, questionnaire system, multiple Chinese font datasets                                                | EM Distance, Gradient Penalty, classification loss, emotion-guided GAN                                                                       | GAN                                             | Convolutional layers, ResBlocks, emotion recognition module                                 | SSIM, PSNR, user study                                                                                     | Zi2Zi, WGAN-GP                                                                     | Calligraphy experts, common respondents |
| [@RDGANFewZeroShot2020]                    | **RD-GAN**              | RD-GAN: Few/Zero-Shot Chinese Character Style Transfer via Radical Decomposition and Rendering               | 2020 | style transfer                                                            | raster images                          | Chinese character images                            | Radical extraction module, conditional GAN                                          | Image generation                                    | raster images          | Stylized Chinese character images                | Feature vectors, 2D attention maps                           | Not specified                                               | 150,000 samples, 47,552 images                                                                     | Train: 150,000 samples, Test: 47,552 images                                                                                                        | Synthetic data, TKH dataset                                                                                  | Radical extraction, rendering module, multi-level discriminator                                                                              | GAN                                             | Convolutional layers, Bi-LSTM                                                               | L1 loss, RMSE, SSIM                                                                                        | Pix2pix, CycleGAN, MC-GAN, Zi2zi, EMD                                              | Not specified                           |
| [@DMFontFewShotCompositional2020]          | **DM-Font**             | Few-shot Compositional Font Generation with Dual Memory                                                      | 2020 | font completion                                                           | raster images                          | Glyph images                                        | Dual memory-augmented representation, persistent memory, dynamic memory             | Image generation                                    | raster images          | Generated Korean and Thai font images            | Component-wise local style representations                   | Not specified                                               | 86 Korean-handwriting fonts, 105 Thai-printing fonts                                               | Train: 80% fonts, 90% characters; Test: 20% fonts, 10% characters                                                                                  | Public fonts from internet                                                                                   | Dual memory structure, component decomposition, adversarial loss, feature matching loss, component classification loss                       | GAN                                             | Convolutional layers, residual blocks, self-attention blocks, hourglass blocks              | SSIM, MS-SSIM, content accuracy, style accuracy, perceptual distance (PD), mean FID (mFID), user study     | EMD, AGIS-Net, FUNIT                                                               | Not specified                           |
| [@GANBasedUnpairedChinese2020]             | **ChiroGAN**            | GAN-Based Unpaired Chinese Character Image Translation via Skeleton Transformation and Stroke Rendering      | 2020 | style transfer                                                            | raster images                          | Chinese character images                            | Skeleton extraction, conditional GAN                                                | Skeleton transformation and stroke rendering        | raster images          | Stylized Chinese character images                | Skeleton vectors                                             | Not specified                                               | Not specified                                                                                      | Not specified                                                                                                                                      | Standard font libraries, real calligraphy datasets                                                           | Skeleton extraction, stroke rendering, multi-chirography translation                                                                         | GAN                                             | Convolutional layers, ResBlocks                                                             | Style error rate, content error rate, IoU, user study                                                      | Pix2pix, CycleGAN, StarGAN, Zi2zi, Rewrite                                         | Not specified                           |
| [@JointFontGANJointGeometryContent2020]    | **JointFontGAN**        | Joint Geometry-Content GAN for Font Generation via Few-Shot Learning                                         | 2020 | style transfer                                                            | raster images                          | Gray-scale glyph images                             | Multi-stream extended conditional GAN (XcGAN) models                                | Two-stream generative process                       | raster images          | Glyph images                                     | Font skeletons and glyph representations                     | Not specified                                               | 20K fonts with different styles                                                                    | Not specified                                                                                                                                      | Collected datasets                                                                                           | Two-stream GAN, few-shot learning, skeleton and content consistency                                                                          | GAN                                             | Two-stream GAN                                                                              | Structural similarity (SSIM), Mean Squared Error (MSE), L1 loss                                            | zi2zi, Glyph Network in MC-GAN                                                     | No                                      |
| [@NeuralStyleDifference2020]               | **NeuralStyleDiff**     | Neural Style Difference Transfer and Its Application to Font Generation                                      | 2020 | style transfer                                                            | raster images                          | Font images                                         | Neural Style Transfer with VGGNet                                                   | Image-to-image translation                          | raster images          | Generated font images                            | Feature maps, Gram matrices                                  | Not specified                                               | Not specified                                                                                      | Not specified                                                                                                                                      | Not specified                                                                                                | Neural style difference, content difference loss, Gram matrices                                                                              | VGGNet                                          | Convolutional layers, feature maps                                                          | Qualitative comparison                                                                                     | Not specified                                                                      | Not specified                           |
| [@GlyphGANStyleconsistentFont2019]         | **GlyphGAN**            | Style-consistent font generation based on generative adversarial networks                                    | 2019 | style transfer, interpolation                                             | raster images                          | Glyph images                                        | Deep convolutional GAN (DCGAN) architecture                                         | Image-to-image translation                          | raster images          | Glyph images                                     | Character class vector, Style vector                         | Not specified                                               | 6,561 fonts, 26 uppercase alphabet letters                                                         | Train: 90%, Test: 10% of 6,561 fonts                                                                                                               | Self-collected from various sources                                                                          | Wasserstein GAN (WGAN), gradient penalty, DCGAN, character class and style vectors                                                           | DCGAN                                           | Fractionally strided convolutions, strided convolutions in discriminator                    | Legibility (recognition accuracy), Diversity (pseudo-Hamming distance), Style consistency (Cs metric)      | DCGAN, WGAN-Clipping                                                               | No                                      |
| [@AGISNetArtisticGlyph2019]                | **AGIS-Net**            | Artistic Glyph Image Synthesis via One-Stage Few-Shot Learning                                               | 2019 | style transfer                                                            | raster images                          | Glyph images (English and Chinese)                  | Content and style disentanglement using two encoders                                | Image generation                                    | raster images          | Synthesized artistic glyph images                | Content and style features, local texture refinement         | Not specified                                               | 35 artistic fonts with 7,326 characters; 2,460 synthetic artistic fonts with 639 characters each   | Not specified                                                                                                                                      | Created by authors, public datasets                                                                          | Two encoders for content and style, two decoders for shape and texture, local texture refinement loss, contextual loss, adversarial training | GAN                                             | Convolutional layers, up-convolution layers, skip connections                               | IS, FID, SSIM, pixel accuracy, user study                                                                  | MC-GAN, TET-GAN                                                                    | Not specified                           |
| [@SVGVAELearnedRepresentation2019]         | **SVG-VAE**             | A Learned Representation for Scalable Vector Graphics                                                        | 2019 | reconstruction, font completion                                           | vector paths                           | SVG commands                                        | Variational Autoencoder (VAE) with convolutional encoder                            | Autoregressive (LSTM)                               | vector paths           | SVG commands                                     | Latent vector z (32-dimensional)                             | Smooth, semantically meaningful                             | 14M font characters                                                                                | Train: 12.6M characters, Test: 1.4M characters                                                                                                     | Google Fonts                                                                                                 | Convolutional VAE, Autoregressive SVG decoder, Mixture Density Network (MDN), UMAP visualization of latent space                             | VAE, LSTM                                       | Convolutional layers for encoder and decoder, 4 stacked LSTM layers for SVG decoder         | Negative log-likelihood, Variance of latent space z                                                        | Qualitative assessments, Quantitative assessment using log-likelihood and variance | No                                      |
| [@SCFontStructureGuidedChinese2019]        | **SCFont**              | SCFont: Structure-Guided Chinese Font Generation via Deep Stacked Networks                                   | 2019 | font generation                                                           | raster images                          | Font glyph images                                   | SkelNet, CNN model                                                                  | Image generation                                    | raster images          | Generated Chinese font images                    | Skeleton flow vectors, stroke category embedding             | Not specified                                               | 70 Chinese fonts with 6,763 characters each                                                        | Not specified                                                                                                                                      | Collected from various sources, including public datasets                                                    | SkelNet, StyleNet, skeleton transformation network, generative model, adversarial loss, consistency loss, pixel space loss                   | GAN, CNN                                        | Convolutional layers, downsampling layers, upsampling layers, residual blocks               | L1 loss, IoU, user study                                                                                   | pix2pix, DCFont, zi2zi, FontSL                                                     | Not specified                           |
| [@FontRNNGeneratingLargescale2019]         | **FontRNN**             | FontRNN: Generating Large-scale Chinese Fonts via Recurrent Neural Network                                   | 2019 | font completion                                                           | points                                 | Sequential data (points)                            | Recurrent neural network with monotonic attention mechanism                         | Sequential point generation                         | points                 | Generated Chinese font points                    | Writing trajectories, points sequences                       | Not specified                                               | 6763 Chinese characters in each font                                                               | 775 characters for training                                                                                                                        | CASIA handwriting dataset                                                                                    | Monotonic attention mechanism, bidirectional RNN, dynamic time warping (DTW) for evaluation                                                  | RNN                                             | Bidirectional RNN, monotonic attention layer, Gaussian mixture model                        | DTW, content accuracy, style classification accuracy, user study                                           | pix2pix, DCFont, zi2zi, FontSL                                                     | Not specified                           |
| [@LearningStrokeBasedRepresentation2019]   | **StrokeRep**           | Learning A Stroke-Based Representation for Fonts                                                             | 2019 | interpolation, font completion                                            | vector paths                           | Glyph outline segments                              | Stroke-based geometric model                                                        | Vector path generation                              | vector paths           | Generated font outlines                          | Stroke-based representation, skeleton control points         | Low-dimensional manifold                                    | 570 fonts                                                                                          | Not specified                                                                                                                                      | Public fonts from internet                                                                                   | Stroke-based model, template fitting, manifold learning, EM-PCA                                                                              | VAE                                             | Bezier curves, stroke templates, skeleton fitting                                           | Reconstruction error, user study                                                                           | Campbell and Kautz, Phan et al.                                                    | Not specified                           |
| [@HandwrittenChineseFont2019]              | **HCF-Gen**             | Handwritten Chinese Font Generation with Collaborative Stroke Refinement                                     | 2019 | style transfer                                                            | raster images                          | 64x64 grayscale pixel images of glyphs              | CNN with encoder-decoder and collaborative stroke refinement                        | Image generation                                    | raster images          | 64x64 grayscale pixel images                     | Not explicitly specified                                     | Not specified                                               | 750 paired training samples                                                                        | Train: 750 paired samples                                                                                                                          | Not specified                                                                                                | Collaborative stroke refinement, online zoom-augmentation, adaptive pre-deformation                                                          | CNN                                             | Encoder-decoder with multiple convolution layers                                            | RMSE, qualitative human evaluation, user study                                                             | HAN, EMD                                                                           | No                                      |
| [@DeepFactorizationStyle2019]              | **DeepFactor**          | A Deep Factorization of Style and Structure in Fonts                                                         | 2019 | reconstruction, style transfer, interpolation                             | raster images                          | Grayscale glyph images (64x64)                      | Variational Autoencoder (VAE)                                                       | Transpose Convolutional Process                     | raster images          | Grayscale glyph images (64x64)                   | Character embeddings and font latent variables               | Not specified                                               | 10,682 fonts                                                                                       | Train: 7,649 fonts, Dev: 1,473 fonts, Test: 1,560 fonts                                                                                            | Capitals64 dataset                                                                                           | Deep matrix factorization, Gaussian prior, orthonormal DCT-II transformation                                                                 | VAE                                             | Convolutional layers with transpose convolutions                                            | L2 reconstruction error, human evaluation (AMT)                                                            | GlyphNet, nearest neighbors                                                        | No                                      |
| [@FontenderInteractiveJapanese2019]        | **Fontender**           | Fontender: Interactive Japanese Text Design with Dynamic Font Fusion Method for Comics                       | 2019 | font fusion, text design                                                  | raster images                          | Japanese font images                                | Dynamic font fusion algorithm                                                       | Not specified                                       | raster images          | Blended font images                              | Core and thickness of fonts expressed mathematically         | Not specified                                               | 18 types of fonts evaluated by 17 participants                                                     | Not specified                                                                                                                                      | Custom dataset (not specified)                                                                               | Dynamic font fusion, impression-based font selection                                                                                         | Not specified                                   | Not specified                                                                               | User satisfaction (Likert scale), qualitative comparison                                                   | Pull down interface, map interface without font fusion                             | No                                      |
| [@EasyFontStyleLearningBased2018]          | **EasyFont**            | A Style Learning-Based System to Easily Build Your Large-Scale Handwriting Fonts                             | 2018 | style transfer, cross-modal: text-to-font, contour completion             | raster images                          | Handwritten character images                        | Non-linear manifold with Gaussian Process Latent Variable Model (GP-LVM)            | Sequential                                          | raster images          | Synthesized handwriting fonts                    | Stroke skeleton representation                               | Low-dimensional latent space                                | 27,533 Chinese characters for training, smaller subsets for testing                                | Train: multiple subsets (639, 266, 775 characters) for style learning and evaluation                                                               | Manually created handwriting samples                                                                         | Stroke extraction, non-rigid point set registration, manifold learning                                                                       | Gaussian Process Latent Variable Model (GP-LVM) | Not specified                                                                               | MSE, R values, Turing tests                                                                                | Comparison with Rewrite, pix2pix, zi2zi, NN-Fonts, NN-Manifold                     | Yes                                     |
| [@FontGANCreatingNew2018]                  | **FontGAN-MF**          | Creating New Chinese Fonts based on Manifold Learning and Adversarial Networks                               | 2018 | reconstruction, interpolation                                             | raster images                          | Chinese character images                            | Manifold learning with CNN                                                          | Image generation                                    | raster images          | Generated font images                            | Feature vectors (skeleton and shape vectors)                 | Non-linear manifold                                         | 72 font libraries                                                                                  | Not specified                                                                                                                                      | Generated from existing font libraries                                                                       | Manifold learning, Gaussian Process Latent Variable Model, Generative Adversarial Network                                                    | GAN                                             | Convolutional layers, up-convolution layers                                                 | Modified pixel-wise loss, qualitative analysis                                                             | Not specified                                                                      | Not specified                           |
| [@LearningDrawVector2018]                  | **Draw-VG**             | Learning to Draw Vector Graphics: Applying Generative Modeling to Font Glyphs                                | 2018 | font generation                                                           | vector paths                           | SVG commands                                        | Variational Autoencoder (VAE)                                                       | Vector path generation                              | vector paths           | Generated SVG font glyphs                        | SVG command sequences                                        | 128-dimensional latent space                                | 2552 font faces                                                                                    | 1920 training, 240 validation, 240 test                                                                                                            | Google Fonts                                                                                                 | VAE, SVG feature encoding, style-content separation                                                                                          | VAE                                             | Bidirectional RNN, LSTM, convolutional layers                                               | Hausdorff distance, qualitative analysis                                                                   | None specified                                                                     | Not specified                           |
| [@TypefaceCompletionGenerative2018]        | **TCN**                 | Typeface Completion Network: Typeface Completion with Generative Adversarial Networks                        | 2018 | reconstruction                                                            | raster images                          | Character images (Chinese and English)              | Content and Typeface Encoder, Conditional GAN                                       | Image generation                                    | raster images          | Completed typeface character images              | Content and typeface latent vectors                          | Not specified                                               | 137,839 Chinese character images, 23,583 English character images                                  | Train: 96,426 Chinese, 16,495 English; Val: 13,776 Chinese, 2,357 English; Test: 27,637 Chinese, 4,733 English                                     | Generated from TTF and OTF files, CelebA dataset                                                             | Adversarial loss, SSIM loss, perceptual loss, reconstruction loss                                                                            | Conditional GAN, ResNet                         | ResNet-based encoder, deconvolutional generator                                             | SSIM, L1 distance, classification accuracy                                                                 | CycleGAN, MUNIT, StarGAN                                                           | Not specified                           |
| [@FontStyleTransfer2018]                   | **FontStyleGAN**        | Font Style Transfer Using Deep Learning                                                                      | 2018 | style transfer                                                            | raster images                          | Character images                                    | Generative Adversarial Network                                                      | Image generation                                    | raster images          | Generated character images                       | Style and content separation                                 | Not specified                                               | 858 fonts, 52 characters each                                                                      | 600 training, 128 validation, 130 test fonts                                                                                                       | Google Fonts                                                                                                 | GAN, unconditional order discriminators, image function representations, adversarial training                                                | GAN                                             | Convolutional layers, fully-connected layers                                                | Quantitative and qualitative evaluation                                                                    | Previous method by the author                                                      | Not specified                           |
| [@MultiContentGANFewShot2017]              | **MC-GAN**              | Multi-Content GAN for Few-Shot Font Style Transfer                                                           | 2017 | style transfer, few-shot font generation                                  | raster images                          | Font glyph images (64x64 pixels)                    | Conditional GAN with stacked architecture                                           | Image-to-image translation                          | raster images          | Stylized font images                             | Feature maps, style vectors                                  | Not specified                                               | 10,000 fonts                                                                                       | Not specified                                                                                                                                      | Collected dataset, synthetic data                                                                            | Conditional GAN, multi-content representation, stacked networks                                                                              | GAN                                             | ResNet blocks, convolutional layers                                                         | Qualitative comparison, user preference                                                                    | Patch-based texture synthesis                                                      | Not specified                           |
| [@DCFontEndtoendDeep2017]                  | **DCFont**              | DCFont: An end-to-end deep Chinese font generation system                                                    | 2017 | font completion, style transfer                                           | raster images                          | Handwritten character images                        | Convolutional neural network                                                        | Generative adversarial network (GAN)                | raster images          | GB2312 font library with 6763 Chinese characters | Deep font features                                           | Not specified                                               | 775 human-written characters plus 5988 machine-generated characters                                | Train: 775 human-written characters, Test: 5988 machine-generated characters                                                                       | Not specified                                                                                                | Font feature reconstruction network, Font style transfer network, Adversarial training                                                       | VGG, ResNet                                     | 16-layer VGG for feature extraction, 5 residual blocks for style transfer                   | MSE loss for reconstruction, Adversarial loss for style transfer                                           | zi2zi, FontSL, Rewrite                                                             | No                                      |
| [@Zi2ziMasterChinese2017]                  | **zi2zi**               | Master Chinese Calligraphy with Conditional Adversarial Networks                                             | 2017 | style transfer                                                            | raster images                          | Chinese character images                            | Conditional GAN                                                                     | Image generation                                    | raster images          | Generated Chinese calligraphy images             | Character and style embeddings                               | Not specified                                               | 27 fonts, 1000-2000 characters each                                                                | Not specified                                                                                                                                      | Created by the author                                                                                        | Conditional GAN, category embedding, multi-class category loss, constant loss                                                                | GAN                                             | Encoder-decoder, convolutional layers                                                       | Content accuracy, style classification accuracy, user study                                                | Rewrite                                                                            | Not specified                           |
| [@SupervisedTransferStyle2016]             | **A2Z**                 | From A to Z: Supervised Transfer of Style and Content Using Deep Neural Network Generators                   | 2016 | style transfer, interpolation, font completion                            | raster images                          | Handwritten character images                        | Variational autoencoder (VAE)                                                       | Extrapolation, generative adversarial network (GAN) | raster images          | 62-letter fonts with known content and style     | Multivariate Gaussians                                       | Organized latent space, linear combinations of latent means | 1,839 fonts                                                                                        | Train: 1,556 fonts, Val: 92 fonts, Test: 191 fonts                                                                                                 | openfontlibrary.org, Fonts used by [21]                                                                      | Extrapolation layer, SSIM cost function, Adversarial sub-networks, In-network and out-of-network image quality assessment                    | VAE                                             | Two hidden layers with 500 nodes each, Multilayer perceptron as image generator             | Mean DSSIM, Structured similarity objective (SSIM), Negative similarity as decoder loss                    | M2, Ours-SSIM, Ours-Adv                                                            | No                                      |
| [@FontasticVoyageGenerative2016]           | **Fontastic**           | A Fontastic Voyage: Generative Fonts with Adversarial Networks                                               | 2016 | reconstruction, interpolation                                             | raster images                          | Grayscale font images (64x64 pixels)                | Variational Autoencoder (VAE), Generative Adversarial Network (GAN)                 | GAN discriminator                                   | raster images          | Generated font images (64x64 pixels)             | Latent vectors                                               | Latent space visualization                                  | 56,443 fonts                                                                                       | Not specified                                                                                                                                      | Erik Bernhardsson’s fonts dataset                                                                            | VAE, GAN, Gaussian filtering                                                                                                                 | VAE, GAN                                        | Convolutional layers, GAN layers                                                            | Visual inspection, qualitative analysis                                                                    | Not specified                                                                      | Not specified                           |
| [@AutomaticGenerationLargescale2016]       | **AGLH**                | Automatic generation of large-scale handwriting fonts via style learning                                     | 2016 | style transfer                                                            | raster images                          | Handwritten samples, glyph images                   | Artificial Neural Networks (ANNs)                                                   | Vectorized                                          | raster images          | Handwritten fonts                                | Trajectories, stroke shape and layout differences            | Not specified                                               | 87 billion Chinese characters in dataset; MinSet: 266 characters, OptSet: 775 characters           | Train: not specified, Test: not specified                                                                                                          | Personal handwriting samples collected through a web application                                             | Artificial Neural Networks (ANNs), stroke trajectory extraction, style learning and synthesis, Coherent Point Drift (CPD) registration       | Feed-forward Neural Network (FFNN)              | 1 hidden layer, 40 units in input, hidden, and output layers                                | Turing tests with 69 participants, accuracy of distinguishing machine-generated from original handwritings | FlexyFont, FounderType, HAND, Lake et al. (2015)                                   | No                                      |
| [@LearningTransferringRules2015]           | **FlexyFont**           | Learning Transferring Rules for Flexible Typeface Synthesis                                                  | 2015 | font completion, interpolation                                            | vector paths                           | Outline-based glyphs                                | Stroke-based representation, Part-Similarity Vector (PSV)                           | Part assembly                                       | vector paths           | Complete typefaces                               | Similarity vectors for parts                                 | Bayesian Gaussian Process Latent Variable Model (BGPLVM)    | 88 training fonts for uppercase, 57 training fonts for lowercase                                   | 60% training, 40% testing                                                                                                                          | Public font dataset                                                                                          | Decomposition of glyphs into semantic parts, part assembly approach, Bayesian Gaussian Process Latent Variable Model (BGPLVM)                | Generative probabilistic model                  | BGPLVM with mixture density model                                                           | Similarity between reconstructed parts and reference parts, t-test, visual comparison                      | Compared with Suveeranont and Igarashi (2010)                                      | No                                      |
| [@LearningManifoldFonts2014]               | **Font-MF**             | Learning a manifold of fonts                                                                                 | 2014 | interpolation, style transfer                                             | vector paths                           | Vector outlines of glyphs                           | Gaussian Process Latent Variable Model (GP-LVM)                                     | Parametric                                          | vector paths           | Font outlines                                    | High dimensional outline vectors                             | Low dimensional manifold (latent space)                     | 46 fonts                                                                                           | Not specified                                                                                                                                      | Google Fonts                                                                                                 | Energy-based optimization, Dense character matching, Coarse-to-fine approach, GP-LVM                                                         | Gaussian Process Latent Variable Model (GP-LVM) | Not specified                                                                               | Qualitative visual inspection, Chamfer distance                                                            | Not specified                                                                      | No                                      |
| [@EasyGenerationPersonal2011]              | **EasyHandFonts**       | Easy generation of personal Chinese handwritten fonts                                                        | 2011 | reconstruction                                                            | raster images                          | Handwritten character images                        | Chinese Character Radical Composition Model                                         | Not specified                                       | raster images          | Handwritten character images                     | Not explicitly specified                                     | Not specified                                               | 522 characters for input samples, 2,500 characters in the output set                               | Input: 522 characters, Output: 2,500 characters                                                                                                    | Not specified                                                                                                | Radical reuse, contour curve-based radical clustering, segmentation and construction of characters                                           | Not specified                                   | Not specified                                                                               | Qualitative comparison with original handwritten fonts                                                     | Not specified                                                                      | No                                      |
| [@ExampleBasedAutomaticFont2010]           | **EFG**                 | Example-Based Automatic Font Generation                                                                      | 2010 | font completion, style transfer                                           | vector paths                           | Single character outline                            | Weighted blend of outlines and skeletons                                            | Parametric                                          | vector paths           | Complete font set                                | Morphable font model with blending weights                   | Not specified                                               | 32 template fonts representing various styles                                                      | Not specified                                                                                                                                      | Not specified                                                                                                | Skin-skeleton model, Blending weights, Gradient descent optimization                                                                         | Not specified                                   | Not specified                                                                               | Qualitative visual inspection, User study                                                                  | Not specified                                                                      | No                                      |
| [@ParamFontParameterizableFonts2001]       | **ParamFont**           | Parameterizable fonts based on shape components                                                              | 2001 | interpolation, style transfer                                             | vector paths                           | Vector outlines of glyphs                           | Shape components with global, group, and local parameters                           | Parametric                                          | vector paths           | Font outlines                                    | Component-based with parameterizable geometric shapes        | Not specified                                               | Not specified (component-based fonts)                                                              | Not specified                                                                                                                                      | Not specified                                                                                                | Shape components, Parameterizable geometric shapes, Global and local parameters                                                              | Not specified                                   | Not specified                                                                               | Qualitative visual inspection, Parameter variation study                                                   | Not specified                                                                      | Yes                                     |
| [@ZiGANFinegrainedChinese2021]             | **ZiGAN**               | ZiGAN: Fine-grained Chinese Calligraphy Font Generation via a Few-shot Style Transfer Approach               | 2021 | style transfer                                                            | raster images                          | Chinese calligraphy characters                      | Conditional GAN, cycle-consistent adversarial network                               | Image generation                                    | raster images          | Calligraphy characters                           | Feature distributions, Hilbert space mapping                 | Not specified                                               | Not specified                                                                                      | Train: 6200 Song style images, Test: 100-200 calligraphy images                                                                                    | Generated using TrueType fonts, Standard font library                                                        | Few-shot learning, style loss, alignment loss, CAM loss                                                                                      | GAN                                             | Encoder-decoder with multiple layers                                                        | Fréchet Inception Distance (FID), Turing test                                                              | zi2zi, pix2pix, U-GAT-IT, CycleGAN, StarGAN, CalliGAN                              | Not specified                           |