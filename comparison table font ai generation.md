| **Citkey**                                 | **Short Name**         | **Name**                                                                                                       | **Year** | **Tasks**                                                                           | **Input Type**                         | **Input Detail**                                      | **Encoding Representation**                                                         | **Decoding Modality**                               | **Output Type** | **Output Detail**                                | **Representation**                                                | **Latent Space**                                            | **Datasets Size**                                                                                                                                                                   | **Training / Testing Distribution**                                                                                                                        | **Dataset Source**                                                                                           | **Techniques and Features**                                                                                                             | **Architecture Base**                                               | **Layers**                                                                                         | **Output Evaluation Methods**                                                                                                               | **Evaluation Comparison**                                                                | **Type Designer Involvement as expert** |
| ------------------------------------------ | ---------------------- | -------------------------------------------------------------------------------------------------------------- | -------- | ----------------------------------------------------------------------------------- | -------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------------------- | --------------------------------------------------- | --------------- | ------------------------------------------------ | ----------------------------------------------------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | --------------------------------------- |
| [@FontStyleInterpolation2024]              | **FontStyleDiff**      | Font Style Interpolation with Diffusion Models                                                                 | 2024     | interpolation                                                                       | raster images                          | Latin alphabet images (64x64 pixels)                  | Conditional diffusion model (U-Net architecture)                                    | Iterative denoising process                         | raster images   | Font images (64x64 pixels)                       | Real-valued condition vectors, noise images                       | Not specified                                               | MyFonts: 17,412 fonts; GoogleFonts: 2,545 fonts                                                                                                                                     | Train: 13,938 fonts, Val: 1,734 fonts, Test: 1,740 fonts                                                                                                   | MyFonts, GoogleFonts                                                                                         | Image-blending, condition-blending, noise-blending approaches                                                                           | U-Net (diffusion model)                                             | Denoising U-Net with several layers                                                                | Recognition accuracy, qualitative comparison                                                                                                | FANnet, Diff-Font                                                                        | No                                      |
| [@EfficientScalableChinese2024]            | **VecFontComp**        | Efficient and Scalable Chinese Vector Font Generation via Component Composition                                | 2024     | reconstruction, zero-shot font extension                                            | vector paths                           | Chinese character components                          | Affine transformation using Spatial Transformer Network                             | Component-based synthesis                           | vector paths    | Chinese character vectors                        | Affine transformation matrices                                    | Not specified                                               | 92,560 characters                                                                                                                                                                   | Train: 80%, Val: 20% from each font dataset                                                                                                                | Created dataset, SourceHanSans, BableStone, AlibabaPuHuiTi, OPPOSansR, SmileySans, YouAiYuanTi, WenDingKaiTi | Affine transformation, component composition                                                                                            | Spatial Transformer Network                                         | Feature extractor (VGG19), Fusion module (Stack, AdaIN, Cross Attention), Regressor (MLP)          | MAE, RMSE, FID, LPIPS                                                                                                                       | DVF-v2, GAN                                                                              | Font Designer                           |
| [@NeuralStyleTransfer2023a]                | **VectorNST**          | Neural Style Transfer for Vector Graphics                                                                      | 2023     | style transfer                                                                      | vector images                          | SVG images with Bezier curves                         | Differentiable Rasterization (DiffVG)                                               | Real-time style transfer                            | vector images   | Stylized SVG images                              | LPIPS features, contour features                                  | Differentiable, real-time updated latent space              | 500 vector images                                                                                                                                                                   | Not specified                                                                                                                                              | FreeSVG                                                                                                      | LPIPS, Contour Loss                                                                                                                     | VGG-19                                                              | Convolutional layers, differentiable rasterization                                                 | User studies, qualitative comparison                                                                                                        | DiffVG, Gatys et al.                                                                     | Not specified                           |
| [@VecFusionVectorFont2023]                 | **VecFusion**          | VecFusion: Vector Font Generation with Diffusion                                                               | 2023     | interpolation, completion                                                           | raster images                          | Raster images of glyphs                               | Cascaded diffusion model with vector diffusion                                      | Sequential                                          | vector paths    | Vector glyphs                                    | Mixed discrete-continuous representation for control points       | Not specified                                               | 1,424 fonts, 577 distinct Unicode glyphs                                                                                                                                            | Train: 314K glyphs, Val: 5K glyphs, Test: 5K glyphs                                                                                                        | Google Fonts                                                                                                 | Cascaded diffusion model, Mixed discrete-continuous representation, Transformer-based vector model                                      | Transformer-based                                                   | 8 Transformer layers                                                                               | L1, Chamfer Distance (CD), Control point difference (#cp diff), Vector path difference (#vp diff)                                           | ChiroDiff, DeepVecFont-v2                                                                | No                                      |
| [@VQFontFewShot2023]                       | **VQ-font**            | VQ-Font: Few shot font generation via transferring similarity guided global style and quantization local style | 2023     | font completion                                                                     | raster images                          | Raster images of glyphs                               | Similarity-guided global style and quantization local style representation          | Sequential                                          | raster images   | Font glyphs                                      | Discrete latent codes for component-level styles                  | Not specified                                               | 386 Chinese fonts, 3,500 characters each                                                                                                                                            | Train: 370 fonts, 3,000 characters each; Test: 15 unseen fonts, 3,000 seen characters each, 15 unseen fonts, 500 unseen characters each                    | Custom dataset                                                                                               | Global and local style aggregation, Cross-attention-based style transfer, GAN-based training                                            | GAN and VQ-VAE                                                      | 3 Transformer layers for cross-attention, 8 attention heads                                        | SSIM, RMSE, LPIPS, FID, User Study                                                                                                          | FUNIT, MX-Font, LF-Font, DG-Font, AGIS-net, FS-Font                                      | No                                      |
| [@JointImplicitJointImplicit2023]          | **JointImplicit**      | JointImplicit: Joint Implicit Neural Representation for High-fidelity and Compact Vector Fonts                 | 2023     | interpolation                                                                       | raster images                          | Pixelated font images                                 | Joint neural representation using SDF and probabilistic corner field (CF)           | Sequential                                          | vector paths    | Vector fonts                                     | Embeddings of SDF and CF                                          | Not specified                                               | 1,425 fonts, 52 glyphs per font                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                              | Implicit neural representation, Corner field modeling, Dual contouring for vectorization                                                | HyperNetworks-based                                                 | Multi-layer perceptrons (MLPs) for SDF and CF networks                                             | L1 error, SSIM, s-mIoU                                                                                                                      | Im2Vec, Multi-Implicit, DeepVecFont, Attr2Font                                           | No                                      |
| [@DiverseConsistentTypography2023]         | **ConTypeGen**         | Towards Diverse and Consistent Typography Generation                                                           | 2023     | style transfer                                                                      | raster images                          | Graphic documents with text elements                  | Autoregressive Transformer with attention mechanism                                 | Sequential                                          | raster images   | Typographic designs                              | Fine-grained typographic attributes                               | Not specified                                               | 23,475 design templates                                                                                                                                                             | Train: 18,780, Test: 2,347, Val: 2,347                                                                                                                     | Crello dataset                                                                                               | Structure-preserved sampling, Fine-grained attribute generation, Consistency and diversity in styling                                   | Transformer-based                                                   | 8 Transformer blocks                                                                               | Attribute metrics (accuracy, MAE, color difference), Structure score, Diversity score                                                       | CanvasVAE, MFC                                                                           | No                                      |
| [@DualVectorUnsupervisedVector2023]        | **DualVector**         | DualVector: Unsupervised Vector Font Synthesis with Dual-Part Representation                                   | 2023     | interpolation, font completion                                                      | raster images                          | Glyph images                                          | Joint vector and pixel representation                                               | Sequential                                          | vector paths    | Vector glyphs                                    | Dual-part vector representation                                   | Shared between modalities                                   | Public datasets: 1,425 fonts, 52 glyphs per font                                                                                                                                    | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                              | Dual-part representation, Differentiable rendering, Contour refinement, UDF initialization                                              | Transformer-based                                                   | Encoder: CNN + Transformer (6 layers), Decoder: Transformer + MLP                                  | SSIM, L1, s-IoU, LPIPS                                                                                                                      | DeepVecFont, Im2Vec, Multi-Implicits                                                     | No                                      |
| [@ContourCompletionTransformers2023]       | **Contour Completion** | Contour Completion by Transformers and Its Application to Vector Font Data                                     | 2023     | contour completion                                                                  | contour sequences                      | Contour sequences with missing points                 | Sequence embedding                                                                  | Sequence-to-sequence                                | vector paths    | Completed contour sequences                      | 5D vectors (x, y, Contour ID, Point ID, curve flag)               | Not specified                                               | Google Fonts: 489 Serif, 1,275 Sans-Serif, 327 Display, 91 Handwriting                                                                                                              | Train: 1,777 fonts, Val: 200 fonts, Test: 205 fonts                                                                                                        | Google Fonts                                                                                                 | Multi-task learning, Loss functions for contour, point, coordinate, and flags                                                           | Transformer-based                                                   | 4 Transformer layers (Encoder & Decoder)                                                           | L1 distance, Hausdorff distance                                                                                                             | Standard Transformer-Encoder                                                             | No                                      |
| [@DeepVecFontv2ExploitingTransformers2023] | **DeepVecFont-v2**     | DeepVecFont-v2: Exploiting Transformers to Synthesize Vector Fonts with Higher Quality                         | 2023     | interpolation, font completion                                                      | raster images                          | Raster images and vector outlines                     | Relaxation representation for vector outlines                                       | Sequence-to-sequence                                | vector paths    | Vector glyphs                                    | Embeddings of drawing commands and coordinates                    | Not specified                                               | English: 8,035 fonts, Chinese: 212 fonts                                                                                                                                            | Train: 8,035 (EN), 212 (CN), Test: 1,425 (EN), 34 (CN)                                                                                                     | Google Fonts                                                                                                 | Transformer encoder-decoder, Bezier curve alignment, Self-refinement                                                                    | Transformer-based                                                   | 6 Transformer layers                                                                               | Reconstruction errors (L1), IoU, Bezier curve alignment loss                                                                                | DeepSVG, DeepVecFont                                                                     | No                                      |
| [@VecFontSDFLearningReconstruct2023]       | **VecFontSDF**         | VecFontSDF: Learning to Reconstruct and Synthesize High-quality Vector Fonts via Signed Distance Functions     | 2023     | style transfer                                                                      | raster images                          | Raster images of glyphs                               | Spatial representation                                                              | Sequential                                          | raster images   | Font glyphs                                      | Signed Distance Function (SDF)                                    | Multi-scale                                                 | Google Fonts: 143K glyph images                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Google Fonts                                                                                                 | SDF rendering, Style transfer, Multi-scale feature extraction                                                                           | CNN-based                                                           | 16 convolutional layers                                                                            | MSE, SSIM, FID                                                                                                                              | DeepSVG, Im2vec, DeepVecFont                                                             | No                                      |
| [@DSFontFewshotFont2023]                   | **DS-Font**            | DS-Font: Few-shot Font Generation by Learning Style Difference and Similarity                                  | 2023     | font completion                                                                     | raster images                          | Raster images of glyphs                               | Style representation through multi-layer style projector (MSP)                      | Sequential                                          | raster images   | Font glyphs                                      | Embeddings of style codes                                         | Not specified                                               | 1,425 fonts, 52 glyphs per font                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                              | Multi-layer style projector (MSP), multi-task patch discriminator, contrastive learning                                                 | GAN-based                                                           | Multi-layer style projector, multi-task patch discriminator, generator with attention mechanism    | L1 loss, LPIPS, RMSE, Acc(C), Acc(S), FID(C), FID(S)                                                                                        | LF-Font, MX-Font, DG-Font, FTransGAN, MF-Net                                             | No                                      |
| [@SVGformerRepresentationLearning2023]     | **SVGformer**          | SVGformer: Representation Learning for Continuous Vector Graphics Using Transformers                           | 2023     | classification, interpolation, retrieval                                            | vector paths                           | Continuous SVG commands                               | Sequential and Geometric representation                                             | Sequential                                          | vector paths    | Vector graphics (SVGs)                           | Embeddings of continuous commands and geometric information       | Not specified                                               | Google Fonts, Icons dataset: Size not specified                                                                                                                                     | Not specified                                                                                                                                              | Google Fonts, Icons datasets                                                                                 | Geometric self-attention, Graph convolutional network (GCN), Continuous value embedding                                                 | Transformer-based                                                   | Encoder: Multiple geometric self-attention modules, Decoder: Multi-head attention                  | Chamfer distance (CD), Cross-entropy (CE)                                                                                                   | DeepSVG, LayoutTransformer                                                               | No                                      |
| [@UsingAutoencodersGenerate2023]           | **SkeletonGenType**    | Using Autoencoders to Generate Skeleton-Based Typography                                                       | 2023     | interpolation                                                                       | raster images                          | Alphabet images (64x64 pixels)                        | Variational Autoencoder (VAE), Autoregressive Sketch Decoder                        | Sketch Decoder (LSTM)                               | raster images   | Skeleton images (64x64 pixels)                   | Real-valued condition vectors, means (µ), standard deviations (σ) | Regularized, smooth latent space                            | 68,198 images                                                                                                                                                                       | Train: Not specified                                                                                                                                       | Google Fonts                                                                                                 | Skeleton extraction, Conditional VAE, Sketch Decoder                                                                                    | Variational Autoencoder (VAE)                                       | Convolutional layers, LSTM layers with dropout                                                     | Binary Cross Entropy, Kullback-Leibler Divergence                                                                                           | Not specified                                                                            | Not specified                           |
| [@CharacterAwareModelsImprove2022]         | **Character-Aware**    | Character-Aware Models Improve Visual Text Rendering                                                           | 2022     | text rendering                                                                      | raster images                          | Text inputs (character-level and token-level)         | Character-aware and character-blind representations                                 | Sequential                                          | raster images   | Visual text rendering in images                  | Token and character embeddings                                    | Not specified                                               | Not specified                                                                                                                                                                       | Train: 500,000 steps, Test: Not specified                                                                                                                  | Laion-400M                                                                                                   | Character-aware and character-blind text encoders, Hybrid models, Pretraining                                                           | T5, ByT5, Concat(T5-XXL, ByT5-Small)                                | Multiple layers (sizes not specified)                                                              | OCR-based metrics (accuracy), Human ratings                                                                                                 | Imagen, Stable Diffusion, Parti                                                          | No                                      |
| [@GASNeXtFewShotCrossLingual2022]          | **GAS-NeXt**           | GAS-NeXt: Few-Shot Cross-Lingual Font Generator                                                                | 2022     | cross-lingual font completion                                                       | raster images                          | Raster images and style reference images              | Layer attention and context-aware attention                                         | Sequential                                          | raster images   | Stylized glyph images                            | Encoded style and content features                                | Not specified                                               | Li et al. dataset                                                                                                                                                                   | Train: 90%, Test: 10%                                                                                                                                      | Li et al. dataset, Azadi et al. dataset, CASIA dataset                                                       | Layer attention, Context-aware attention, Local discriminator                                                                           | AGIS-Net and Font Translator GAN based                              | Encoder: 6 convolutional layers, Decoder: 6 deconvolutional layers                                 | FID, SSIM, Pixel-level Accuracy                                                                                                             | Font Translator GAN, AGIS-Net                                                            | No                                      |
| [@DiffFontDiffusionModel2022]              | **Diff-Font**          | Diffusion Model for Robust One-Shot Font Generation                                                            | 2022     | font completion                                                                     | raster images                          | Raster images of glyphs                               | Gaussian noise representation                                                       | Sequential                                          | raster images   | Font glyphs                                      | Character attributes embedding (content, stroke, style)           | Not specified                                               | Small: 1,000 Chinese characters, Large: 3,755 Chinese characters                                                                                                                    | Train: 80%, Test: 20%                                                                                                                                      | Custom dataset                                                                                               | Diffusion model, Stroke-wise information                                                                                                | UNet-based DDPM                                                     | Multi-scale U-Net layers                                                                           | SSIM, RMSE, LPIPS, FID                                                                                                                      | FUNIT, MX-Font, DG-Font                                                                  | No                                      |
| [@NeuralFontRendering2022]                 | **NeurFont**           | Neural Font Rendering                                                                                          | 2022     | interpolation                                                                       | vector paths                           | Vector glyph outlines                                 | Implicit neural representation                                                      | Sequential                                          | raster images   | Rasterized glyphs at various sizes               | Implicit functions                                                | Not specified                                               | Not specified                                                                                                                                                                       | Not specified                                                                                                                                              | Custom dataset                                                                                               | Implicit neural representation, Frequency encoding, Batch normalization adaptations                                                     | U-Net-based, Implicit model                                         | Encoder-decoder with multiple layers, Implicit model with 5 layers                                 | L2 pixelwise loss, Focal loss                                                                                                               | Comparison between masked MLP and implicit model                                         | No                                      |
| [@PGMFontRepresentation2022]               | **PGMh**               | PGM: Font Representation Learning via Paired-glyph Matching                                                    | 2022     | font retrieval, style transfer, font completion                                     | raster images                          | Glyph images                                          | Paired-glyph matching learning                                                      | Sequential                                          | embedings       | Font embeddings                                  | Embeddings of glyph representations                               | Not specified                                               | O’Donovan: 1,088 fonts, Capitals64: 10,682 fonts, Open Font Library (OFL): 3,802 fonts                                                                                              | O’Donovan: Train: 1,088 fonts, Val: 28 fonts, Capitals64: Train: 7,649 fonts, Val: 1,473 fonts, Test: 1,560 fonts, OFL: Train: 3,702 fonts, Val: 100 fonts | O’Donovan dataset, Capitals64, OFL                                                                           | Paired-glyph matching, Cross-entropy loss, L1 loss, Contrastive learning                                                                | ResNet18-based                                                      | ResNet18 backbone, additional layers for projection head                                           | Retrieval mean accuracy (MACC_Ret), Font attribute prediction (L1-error)                                                                    | Classification, Style Transfer, Autoencoder                                              | No                                      |
| [@FSFontFewShotFont2022]                   | **FS-Font**            | FS-Font: Few-Shot Font Generation by Learning Fine-Grained Local Styles                                        | 2022     | font completion                                                                     | raster images                          | Raster images of glyphs                               | Fine-grained local style representation through cross-attention                     | Sequential                                          | raster images   | Stylized glyph images                            | Fine-grained local style representation (FLS)                     | Not specified                                               | 407 fonts, 3,396 characters                                                                                                                                                         | Train: 397 fonts, 2,896 characters, Test: 10 fonts, 500 unseen characters (UFUC), 2,896 seen characters (UFSC)                                             | Custom dataset                                                                                               | Cross-attention based style aggregation, Self-reconstruction branch, Reference selection strategy                                       | Convolutional and Residual Blocks                                   | Multiple convolutional and residual layers                                                         | L1 loss, RMSE, SSIM, LPIPS, User Study                                                                                                      | FUNIT, DG-Font, MX-Font, AGIS-net, LF-Font                                               | No                                      |
| [@GenTextUnsupervisedArtistic2022]         | **GenText**            | GenText: Unsupervised Artistic Text Generation via Decoupled Font and Texture Manipulation                     | 2022     | text effect transfer, font style transfer, image style transfer, font interpolation | raster images                          | Content images, font images, texture reference images | Spatial and global code representation                                              | Sequence-to-sequence                                | raster images   | Artistic text images                             | Embeddings (spatial and global code)                              | Not specified                                               | Artistic text benchmarks (e.g., TE141K)                                                                                                                                             | Train: 90%, Test: 10%                                                                                                                                      | Public datasets                                                                                              | GAN, unsupervised learning, stylization and destylization                                                                               | Encoder-decoder GAN                                                 | 4 downsampling residual blocks, 2 convolution layers                                               | PSNR, SSIM, Perceptual loss, Style loss                                                                                                     | AdaIN, Dpatch, NCE, CycleGAN                                                             | No                                      |
| [@SVGVecFontSVGVector2022]                 | **SVGVecFont**         | SVGVecFont: SVG Vector Font Generation for Chinese Characters with Transformer                                 | 2022     | interpolation, completion                                                           | vector paths                           | SVG vector graphics                                   | Sequence-to-sequence                                                                | Sequence-to-sequence                                | vector paths    | Vector glyphs                                    | Commands and Coordinates                                          | Not specified                                               | Chinese: 407 fonts, 3396 characters                                                                                                                                                 | Train: 397 fonts, Test: 10 fonts                                                                                                                           | Public datasets                                                                                              | Transformer encoder-decoder, Style Aggregation Module                                                                                   | Transformer-based                                                   | Multi-head projection, Self-reconstruction branch                                                  | L1 loss, Adversarial loss, SSIM, LPIPS, FID                                                                                                 | DeepVecFont, Diff-Font, GAS-NeXt                                                         | No                                      |
| [@FontGenerationMissing2022]               | **ImpressionLabels**   | Font Generation with Missing Impression Labels                                                                 | 2022     | style transfer                                                                      | raster images                          | Raster images of glyphs                               | Conditional GAN with missing label handling                                         | Sequential                                          | raster images   | Font glyphs                                      | Impression label embeddings                                       | Not specified                                               | MyFonts: 17,202 fonts, 1,430 impression labels                                                                                                                                      | Train: 90%, Test: 10%                                                                                                                                      | MyFonts dataset                                                                                              | Co-occurrence-based missing label estimator, Impression label space compressor, Style consistency discriminator                         | GAN-based                                                           | Progressive GAN with auxiliary classifiers                                                         | FID, Intra-FID, mAP-train, mAP-test                                                                                                         | C-GAN+, AC-GAN+, CP-GAN+, Imp2Font                                                       | No                                      |
| [@FontNetClosingGap2022]                   | **FontNet**            | FontNet: Closing the gap to font designer performance in font synthesis                                        | 2022     | font style transfer, font completion                                                | raster images                          | Font images                                           | Embedding                                                                           | Adversarial generation                              | raster images   | High-resolution font images                      | Embeddings of style and content features                          | Style embedding space                                       | 90 Korean fonts, 2,350 characters                                                                                                                                                   | Train: 75% fonts, Test: 25% fonts                                                                                                                          | Naver Fonts                                                                                                  | StyleGAN, Separator network, Triplet loss                                                                                               | StyleGAN-based                                                      | Encoder-Decoder with separator network                                                             | SSIM, mFID, Top-1 accuracy                                                                                                                  | MX-Font, FUNIT                                                                           | No                                      |
| [@SEGANSkeletonEnhanced2022]               | **SE-GAN**             | SE-GAN: Skeleton Enhanced GAN-based Model for Brush Handwriting Font Generation                                | 2022     | style transfer                                                                      | raster images                          | Raster images of brush handwriting                    | Spatial representation                                                              | Sequential                                          | raster images   | Font glyphs                                      | Skeleton-based representation                                     | Multi-scale                                                 | Custom dataset: 15,799 high-resolution images                                                                                                                                       | Train: 80%, Dev: 10%, Test: 10%                                                                                                                            | Custom dataset                                                                                               | GAN-based model, Self-attentive Refined Attention Module (SAttRAM), skeleton discriminator                                              | GAN-based                                                           | 4 residual blocks for each encoder, 2 discriminators                                               | Content accuracy, FID, User preference                                                                                                      | zi2zi, CycleGAN, StarGAN, DF-Font                                                        | Yes                                     |
| [@ArbitraryFontGeneration2022]             | **ArbitFontGen*        | Arbitrary Font Generation by Encoder Learning of Disentangled Features                                         | 2022     | style transfer                                                                      | raster images                          | Raster images of fonts                                | Spatial representation                                                              | Sequential                                          | raster images   | Font images                                      | Disentangled features of text content and font style              | N/A                                                         | Korean: 238 train, 40 test; Chinese: 185 train, 15 test; English: 185 train, 15 test                                                                                                | Train: 85%, Test: 15%                                                                                                                                      | Noonnu, Internet, Chinese Font Design                                                                        | Stacked input, Consistency loss, VGG-19, AdaIN, Hallucinated stack                                                                      | VGG-19 based                                                        | VGG-19 layers, AdaIN layers, ConvBlock layers                                                      | FID, L1 distance, Perceptual distance                                                                                                       | FUNIT, EMD                                                                               | No                                      |
| [@CVFontSynthesizingChinese2022]           | **CVFont**             | CVFont: Synthesizing Chinese Vector Fonts via Deep Layout Inferring                                            | 2022     | style transfer                                                                      | raster images                          | Raster images of glyphs                               | Hierarchical approach to component extraction, using CPD algorithm for registration | Sequential                                          | vector paths    | Chinese vector fonts                             | Components and strokes                                            | Multi-scale                                                 | GB2312 Kaiti font library (6763 characters), 70 Chinese fonts                                                                                                                       | Pre-train: 60 fonts, Online: 10 fonts, Testing: 69 fonts                                                                                                   | Founder Group                                                                                                | Layout prediction with Faster R-CNN, U-Net based generator, Skeleton extraction, Shape decomposition                                    | ResNet-101 + U-Net                                                  | ResNet-101 backbone, U-Net generator with 3 downsampling layers, Faster R-CNN detector             | IoU scores, Qualitative user study                                                                                                          | Rewrite, pix2pix, CycleGAN, EasyFont, zi2zi                                              | Yes                                     |
| [@XMPFontSelfSupervisedCrossModality2022]  | **XMP-Font**           | XMP-Font: Self-Supervised Cross-Modality Pre-Training for Few-Shot Font Generation                             | 2022     | font completion                                                                     | raster images                          | Glyph images, stroke labels                           | Cross-modality representation                                                       | Cross-modality                                      | raster images   | Glyphs                                           | Stroke-level, component-level, character-level styles             | Pre-trained with self-supervised signals                    | 100 font styles                                                                                                                                                                     | Train: 90%, Test: 10%                                                                                                                                      | Founder font libraries                                                                                       | Cross-modality transformer-based encoder, ECA modules, LSTM-based stroke loss                                                           | Transformer-based                                                   | Cross-modality encoder with BERT layers, 4 ECA modules                                             | FID, PSNR, SSIM, L1, User study                                                                                                             | StarGAN-v2, FUNIT, LF-Font, MX-Font, DG-Font                                             | No                                      |
| [@SharedLatentSpace2022]                   | **NoisyImpressions**   | Shared Latent Space of Font Shapes and Their Noisy Impressions.                                                | 2022     | cross-modal: shape-to-impression, impression-to-shape                               | raster images                          | Glyph images, impression words                        | Shared latent space representation                                                  | Cross-modal                                         | raster images   | Glyph images, impression words                   | Vector representations for font shapes and impression words       | Shared latent space with DeepSets                           | MyFonts: 18,815 fonts                                                                                                                                                               | Train: 9,980, Validation: 2,992, Test: 1,223                                                                                                               | MyFonts dataset                                                                                              | DeepSets for shape-relevant impression filtering, cross-modal autoencoders                                                              | Autoencoder, ResNet18-based encoder                                 | ResNet18 encoder, deconvolutional layers for decoder                                               | Precision@K, average retrieval rank, Hausdorff distance                                                                                     | Impressions2Font                                                                         | No                                      |
| [@StrokeStylesStrokebasedSegmentation2022] | **StrokeStyles**       | Stroke-based Segmentation and Stylization of Fonts.                                                            | 2022     | style transfer                                                                      | vector paths                           | Glyph outlines                                        | Stroke-based segmentation with curvilinear shape features and augmented medial axis | Parametric                                          | raster images   | Stylized glyphs                                  | Shape components and stroke-based representation                  | Not specified                                               | Not specified                                                                                                                                                                       | Not specified                                                                                                                                              | Not specified                                                                                                | Stroke-based segmentation, Curvilinear shape features, Augmented medial axis, Junction types                                            | Not specified                                                       | Not specified                                                                                      | Qualitative visual inspection, User study                                                                                                   | Not specified                                                                            | No                                      |
| [@PGMFontRepresentation2022]               | **PGM**                | PGM: Font Representation Learning via Paired-glyph Matching                                                    | 2022     | font retrieval, style transfer                                                      | raster images                          | Glyph images of characters                            | Paired-glyph matching with contrastive learning                                     | Parametric                                          | embedings       | Font embeddings                                  | Latent space with high dimensional glyph embeddings               | Not specified                                               | O’Donovan dataset: 1,088 fonts (training), 28 fonts (validation); OFL: 3,702 fonts (training), 100 fonts (validation); Capitals64: 7,649 fonts (training), 1,473 fonts (validation) | O’Donovan: train/val (1,088/28), OFL: train/val (3,702/100), Capitals64: train/val/test (7,649/1,473/1,560)                                                | O’Donovan dataset, Open Font Library (OFL), Capitals64                                                       | Paired-glyph matching, Contrastive learning, ResNet18 backbone, Retrieval accuracy, Font attribute prediction                           | ResNet18 backbone                                                   | Not specified                                                                                      | Retrieval mean accuracy (MACCRet), Font attribute prediction L1-error, Image L1-error                                                       | Classification, Style Transfer, Autoencoder, Srivatsan et al.                            | No                                      |
| [@CKFontFewShotKorean2021]                 | **CKFont**             | CKFont: Few-Shot Korean Font Generation based on Hangul Composability                                          | 2021     | font completion                                                                     | raster images                          | Glyph images                                          | Spatial representation                                                              | Sequential                                          | raster images   | Glyphs                                           | Character-level styles                                            | Pre-trained with self-supervised signals                    | 2,350 glyphs                                                                                                                                                                        | Train: 2,000, Test: 350                                                                                                                                    | Hangul standard code system (KS X 1001)                                                                      | Conditional GAN, dual encoders, style extraction from components                                                                        | GAN-based                                                           | 6 convolutional layers in each encoder, 6 deconvolutional layers in the decoder                    | L1, L2, SSIM, FID                                                                                                                           | zi2zi, SKFont                                                                            | No                                      |
| [@ScalableFontReconstruction2021]          | **DualFont-MF**        | Scalable Font Reconstruction with Dual Latent Manifolds                                                        | 2021     | reconstruction                                                                      | raster images                          | Glyph images                                          | Dual latent manifolds representation                                                | Matrix factorization                                | raster images   | Glyph images                                     | Vector representations for font style and character shape         | Dual latent spaces with Gaussian priors                     | Google Fonts: 2017 fonts, Chinese Simplified: 623 fonts                                                                                                                             | Train: 60%, Dev: 20%, Test: 20%                                                                                                                            | Google Fonts, Chinese Simplified dataset                                                                     | Dual manifold model, adaptive wavelet loss, U-Net architecture                                                                          | U-Net-based                                                         | Encoder: convolutional layers, Decoder: transposed convolutional layers with MLP parameters        | SSIM, L2, Human evaluation (Amazon Mechanical Turk)                                                                                         | EMD, Nearest Neighbor                                                                    | No                                      |
| [@ZiGANFinegrainedChinese2021]             | **ZiGAN**              | ZiGAN: Fine-grained Chinese Calligraphy Font Generation via a Few-shot Style Transfer Approach                 | 2021     | style transfer                                                                      | raster images                          | Glyph images                                          | Spatial representation                                                              | Sequential                                          | raster images   | Glyphs                                           | Character-level styles                                            | Learned correlation between structures of different styles  | 61,151 images, 6560 characters                                                                                                                                                      | Train: 100 or 200 shots, Test: remaining images                                                                                                            | Chinese calligraphy character website                                                                        | GAN-based, CAM attention module, CycleGAN                                                                                               | GAN-based                                                           | Encoder: 8 convolutional layers, Decoder: 8 deconvolutional layers                                 | FID, IOU, Top-1 Accuracy, User study                                                                                                        | zi2zi, pix2pix, U-GAT-IT, CycleGAN, StarGAN, CalliGAN                                    | No                                      |
| [@DeepVecFontSynthesizingHighquality2021]  | **DeepVecFont**        | DeepVecFont: Synthesizing High-quality Vector Fonts via Dual-modality Learning                                 | 2021     | font completion, interpolation                                                      | raster images, vector paths            | Raster images, vector outlines                        | Dual-modality representation                                                        | Sequential                                          | vector paths    | Vector glyphs                                    | Image-aspect and sequence-aspect features                         | Latent space with Gaussian priors                           | 8K fonts for training, 1.5K for testing                                                                                                                                             | Train: 8K fonts, Test: 1.5K fonts                                                                                                                          | SVG-Fonts Dataset                                                                                            | Dual-modality learning, differentiable rasterization, Mixture Density Network                                                           | CNN-based, RNN-based                                                | Convolutional layers, LSTM layers                                                                  | L1 loss, Perceptual loss, Cross-Entropy loss, MDN loss                                                                                      | SVG-VAE, DeepSVG, Im2Vec                                                                 | No                                      |
| [@FontCompletionManipulation2021]          | **CycleFont**          | Font Completion and Manipulation by Cycling Between Multi-Modality Representations                             | 2021     | font completion, interpolation, manipulation                                        | raster images, vector paths, poit sets | Raster images, SVG curves, point sets                 | Multi-modality representation (image-to-graph-to-image)                             | Multi-modality (graph-based)                        | raster images   | Glyph images                                     | Graph-based representation                                        | Latent space with graph representation                      | Google Fonts: 2693 fonts, 55,554 glyphs                                                                                                                                             | Train: 95%, Test: 5%                                                                                                                                       | Google Fonts dataset                                                                                         | Cross-modality auto-encoder, graph-based representation                                                                                 | Graph-based, auto-encoder                                           | Image encoder (Conv2D), point set decoder, graph constructor, neural renderer                      | MSE, PSNR, SSIM                                                                                                                             | TCN                                                                                      | No                                      |
| [@LearningImplicitGlyph2021]               | **ImplicitGlyph**      | Learning Implicit Glyph Shape Representation                                                                   | 2021     | interpolation, style transfer                                                       | raster images                          | Raster images                                         | Implicit representation                                                             | Implicit function decoding                          | raster images   | Glyph images                                     | Signed distance functions with quadratic curves                   | Continuous 2D space                                         | 26390 glyph images                                                                                                                                                                  | Train: 26390 images, Validation: dataset split                                                                                                             | Custom dataset                                                                                               | Implicit representation, quadratic curves, disentangled encoder, auxiliary character classifier                                         | CNN-based, ResNet-18                                                | ResNet-18 encoder, MLP for curve parameters                                                        | SSIM, LPIPS, L1 distance, User study                                                                                                        | VAE, pix2pix, AGIS-Net, FANnet                                                           | No                                      |
| [@LearningPerceptualManifold2021]          | **PerceptFont-MF**     | Learning Perceptual Manifold of Fonts                                                                          | 2021     | gont exploration, style transfer                                                    | raster images                          | Raster images                                         | Latent space representation                                                         | Sequential                                          | raster images   | Glyph images                                     | Perceptual manifolds                                              | Continuous latent space                                     | Google Fonts: 2169 fonts                                                                                                                                                            | Train: 90%, Test: 10%                                                                                                                                      | Google Fonts                                                                                                 | Variational Autoencoder (VAE), t-SNE for manifold learning, kernel density estimation                                                   | VAE-based                                                           | Encoder: 4 convolutional layers, Decoder: 2 convolutional layers                                   | SSIM, User study                                                                                                                            | Comparison with traditional font exploration interfaces                                  | Yes                                     |
| [@FontRLChineseFont2021]                   | **FontRL**             | FontRL: Chinese Font Synthesis via Deep Reinforcement Learning                                                 | 2021     | font completion                                                                     | raster images                          | Glyph images                                          | Spatial representation                                                              | Sequential                                          | raster images   | Glyph images                                     | Stroke-level styles                                               | Deep reinforcement learning with TPS transformations        | 6,763 characters in 5 styles                                                                                                                                                        | Train: 775 characters, Test: 5 styles                                                                                                                      | Custom dataset                                                                                               | Deep reinforcement learning, TPS transformation, CNN-based image rendering                                                              | ResNet-18, CNN-based                                                | Policy network (ResNet-18), BBoxNet (ResNet-34), StyleNet for rendering                            | L1 loss, IoU, User study                                                                                                                    | SCFont, zi2zi, DCFont, FontRNN, pix2pix                                                  | No                                      |
| [@LFFontFewshotFont2021]                   | **LF-Font**            | LF-Font: Few-shot Font Generation with Localized Style Representations and Factorization                       | 2021     | font completion                                                                     | raster images                          | Glyph images                                          | Spatial representation                                                              | Sequential                                          | raster images   | Glyphs                                           | Localized style representations, factorization modules            | Factorized component and style factors                      | 19,514 characters                                                                                                                                                                   | Train: 467 fonts, Test: 15 fonts                                                                                                                           | Custom collected Chinese fonts                                                                               | Component-wise style encoding, content encoder, factorization modules                                                                   | CNN-based                                                           | Style encoder, content encoder, generator with 4 convolutional layers                              | LPIPS, Accuracy, FID, User study                                                                                                            | SA-VAE, EMD, AGIS-Net, FUNIT, DM-Font                                                    | No                                      |
| [@StrokeGANReducingMode2021]               | **StrokeGAN**          | Reducing Mode Collapse in Chinese Font Generation via Stroke Encoding                                          | 2021     | style transfer                                                                      | raster images                          | Glyph images                                          | Stroke encoding representation                                                      | Sequential                                          | raster images   | Glyph images                                     | Stroke-level encoding                                             | CycleGAN with stroke encoding                               | 9 different fonts datasets                                                                                                                                                          | Train: 90%, Test: 10%                                                                                                                                      | Custom collected, CASIA-HWDB1.1, Internet                                                                    | Stroke encoding, CycleGAN, stroke-encoding reconstruction loss                                                                          | CycleGAN-based                                                      | 2 convolutional layers (down-sampling), 9 residual modules, 2 deconvolutional layers (up-sampling) | Content accuracy, Recognition accuracy, Stroke error                                                                                        | CycleGAN, zi2zi, Chinese Typography Transfer (CTT)                                       | No                                      |
| [@DGFontDeformableGenerative2021]          | **DG-Font**            | DG-Font: Deformable Generative Networks for Unsupervised Font Generation                                       | 2021     | font completion                                                                     | raster images                          | Raster images of glyphs                               | Spatial representation                                                              | Sequential                                          | raster images   | Font glyphs                                      | Spatial features and latent vector representations                | Deformable                                                  | Custom dataset: 410 fonts, 990 characters each                                                                                                                                      | Train: 400 fonts, 800 chars/font; Test: 10 fonts, 190 chars/font                                                                                           | Custom dataset                                                                                               | Deformable convolution, Feature Deformation Skip Connection (FDSC), AdaIN                                                               | CNN-based                                                           | Deformable convolutions, residual blocks, multi-task discriminator                                 | L1 loss, RMSE, SSIM, LPIPS, FID                                                                                                             | CycleGAN, EMD, Zi2zi, GANimorph, FUNIT                                                   | No                                      |
| [@RadicalCompositionNetwork2021]           | **RCN**                | Radical Composition Network for Chinese Character Generation                                                   | 2021     | cross-modal: caption-to-font                                                        | raster images                          | Caption text, Raster images of radicals               | Sequential                                                                          | Sequential                                          | raster images   | Chinese character images                         | Embeddings                                                        | Tree-structured                                             | Printed: 114,665 characters; Handwritten: 2,674,784 characters                                                                                                                      | Train: 22,933 classes, Test: 4,172 classes                                                                                                                 | Custom dataset                                                                                               | Tree-structured encoder (TRN), DenseNet, Deconvolution, Perceptual loss                                                                 | Encoder-decoder (CNN-based)                                         | Tree-structured recurrent units, Deconvolution layers                                              | L1 loss, RMSE, SSIM, LPIPS                                                                                                                  | RAN, zi2zi                                                                               | No                                      |
| [@SkelGANFontImage2021]                    | **SkelGAN**            | SkelGAN: A Font Image Skeletonization Method                                                                   | 2021     | style transfer, skeletonization                                                     | raster images                          | Font images                                           | Spatial representation                                                              | Sequential                                          | raster images   | Skeletons of font glyphs                         | One-pixel-width skeletons                                         | Multi-scale                                                 | Custom dataset: 70,500 glyph images                                                                                                                                                 | Train: 90%, Test: 10%                                                                                                                                      | Custom dataset                                                                                               | GANs, Style classification, Character classification, Multi-scale feature extraction                                                    | Modified U-Net                                                      | 14 layers (7 encoder, 7 decoder)                                                                   | SSIM, L1 distance                                                                                                                           | Lee’s method, Pix2pix                                                                    | No                                      |
| [@AdaptiFontIncreasingIndividuals2021]     | **AdaptiFont**         | AdaptiFont: Increasing Individuals                                                                             | 2021     | adaptive design, reading speed optimisation                                         | text data                              | Text data                                             | Non-negative matrix factorization (NMF)                                             | Generative                                          | vector paths    | TrueType fonts                                   | NMF basis vectors                                                 | Not specified                                               | 25 classic fonts                                                                                                                                                                    | 7 subjects, 250 texts each                                                                                                                                 | Custom collected from Twitter pages of news platforms                                                        | Bayesian optimization, human-in-the-loop system, generative font space                                                                  | Not specified                                                       | NMF with 3 components                                                                              | Reading speed (words per minute), Bayesian ANOVA, Bayesian Pearson Correlation                                                              | Traditional fonts comparison (Kolmogorov-Smirnov test)                                   | No                                      |
| [@FewShotFontStyle2021]                    | **FTransGAN**          | FTransGAN in PyTorch                                                                                           | 2021     | style transfer, font completion                                                     | raster images                          | Grayscale images of glyphs                            | Multi-level attention with Context-aware and Layer Attention Networks               | Sequential                                          | raster images   | Grayscale glyphs                                 | Local and global feature representation                           | Not specified                                               | 847 fonts, each with 52 English letters and ~1000 Chinese characters                                                                                                                | Train: 847 fonts, Test: 29 fonts                                                                                                                           | Constructed by authors                                                                                       | Multi-level attention network, Context-aware Attention Network, Layer Attention Network                                                 | GAN-based                                                           | Encoder-Decoder structure with 3 Conv layers, 6 ResNet blocks, and 3 up-conv layers                | L1 loss, Style loss, Content loss, MAE, SSIM, MS-SSIM, mFID, Top-1 accuracy                                                                 | EMD, DFS                                                                                 | No                                      |
| [@DeepSVGHierarchicalGenerative2020]       | **DeepSVG**            | DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation                                       | 2020     | interpolation, animation, manipulation                                              | vector paths                           | SVG commands                                          | Hierarchical Transformer-based architecture                                         | Non-autoregressive                                  | vector paths    | SVG images                                       | Discrete continuous embedding                                     | Not specified                                               | 100,000 high-quality icons                                                                                                                                                          | Train/Test split not specified                                                                                                                             | SVG-Icons8, constructed by authors                                                                           | Hierarchical generative network, Non-autoregressive feed-forward model                                                                  | Transformer-based                                                   | 4 layers in encoder and decoder with 512 feed-forward dimension                                    | Chamfer distance, Reconstruction Error (RE), Interpolation Smoothness (IS)                                                                  | One-stage autoregressive, One-stage feed-forward, SVG-VAE                                | No                                      |
| [@Font2FontsModifiedImagetoImage2020]      | **Font2Fonts**         | Font2Fonts: A modified Image-to-Image translation framework for font generation                                | 2020     | style transfer, font completion                                                     | raster images                          | Grayscale images of glyphs                            | Conditional GAN with multi-domain translation                                       | Sequential                                          | raster images   | Grayscale glyphs                                 | Local and global feature representation                           | Not specified                                               | 20 Korean fonts, 2,350 most commonly used Korean Hangul characters                                                                                                                  | Train: 75% (15 fonts), Test: 25% (5 fonts)                                                                                                                 | Constructed by authors                                                                                       | Conditional GAN, Multi-domain translation, Unicode-based font dataset generator                                                         | GAN-based                                                           | 7 down-sampling and 7 up-sampling layers with Instance Normalization                               | L1 loss, GAN loss, Style classification loss, MAE, SSIM                                                                                     | pix2pix                                                                                  | No                                      |
| [@CalliGANStyleStructureaware2020]         | **CalliGAN**           | CalliGAN: Style and Structure-aware Chinese Calligraphy Character Generator                                    | 2020     | style transfer                                                                      | raster images                          | Grayscale images of glyphs                            | Component-based encoder-decoder with multi-domain translation                       | Sequential                                          | raster images   | Grayscale glyphs                                 | Embedding and component encoding                                  | Not specified                                               | 29 calligraphy styles, 47552 images                                                                                                                                                 | Train: 39815 images, Test: 7737 images                                                                                                                     | Constructed by authors                                                                                       | Component-based encoder, U-Net-based generator, multi-domain translation                                                                | GAN-based                                                           | 8 encoder and 8 decoder layers, Component encoder with LSTM                                        | MSE, SSIM, Human subject study                                                                                                              | zi2zi, AEGG                                                                              | No                                      |
| [@Attribute2FontCreatingFonts2020]         | **Attribute2Font**     | Attribute2Font: Creating Fonts You Want From Attributes                                                        | 2020     | style transfer, interpolation, font completion, editing                             | raster images                          | Glyph images                                          | Hierarchical encoder-decoder with Attribute Attention Module (AAM)                  | Sequential                                          | raster images   | Glyph images                                     | Attribute embeddings                                              | Not specified                                               | 148 labeled fonts, 968 unlabeled fonts                                                                                                                                              | Train: 120 fonts, Val: 28 fonts                                                                                                                            | AttrFont-ENG (O'Donovan et al., 2014)                                                                        | Attribute Attention Module, Semi-supervised learning, Visual Style Transformer                                                          | CNN-based encoder-decoder                                           | 16 residual blocks, 4 up-sampling layers, AAM                                                      | IS, FID, LPIPS, SSIM, pixel-level accuracy (pix-acc), Hausdorff, Chamfer                                                                    | AttGAN, StarGAN, RelGAN, STGAN, O'Donovan et al., Chen et al.                            | Yes                                     |
| [@AutomaticChineseFont2020]                | **EmoGAN**             | Automatic Chinese Font Generation System Reflecting Emotions Based on Generative Adversarial Network           | 2020     | style transfer, interpolation, font completion                                      | raster images                          | Glyph images                                          | Hierarchical encoder-decoder with Emotion Guidance Module (EGM)                     | Sequential                                          | raster images   | Glyph images                                     | Emotion embeddings, Style embeddings                              | Not specified                                               | 30 fonts for training, 27 fonts for fine-tuning                                                                                                                                     | Train: 27 fonts (1000 chars each), Fine-tune: 6 fonts (3000 chars each)                                                                                    | Questionnaire system (Tencent platform)                                                                      | Emotional Guidance GAN (EG-GAN), EM Distance, Gradient Penalty, Classification loss                                                     | CNN-based encoder-decoder                                           | Multiple convolutional layers, EGM                                                                 | SSIM, PSNR, evaluation questionnaire                                                                                                        | Zi2Zi, EG-GAN 1 (without Gradient Penalty)                                               | Yes                                     |
| [@RDGANFewZeroShot2020]                    | **RD-GAN**             | RD-GAN: Few/Zero-Shot Chinese Character Style Transfer via Radical Decomposition and Rendering                 | 2020     | style transfer, interpolation                                                       | raster images                          | Glyph images                                          | Radical decomposition-and-rendering-based GAN                                       | Sequential                                          | raster images   | Stylized glyph images                            | Radical embeddings, Style embeddings                              | Not specified                                               | 1473 classes with 50 samples each (D1), 5 samples each (D2), 1473 unseen categories (D3)                                                                                            | D1: same category in training and test, D2: 5 samples per category, D3: unseen categories                                                                  | TKH Dataset (Tripitaka paragraph images)                                                                     | Radical Extraction Module (REM), Radical Rendering Module (RRM), Multi-level Discriminator (MLD)                                        | CNN-based encoder-decoder                                           | 2-layer Bi-directional LSTM (BLSTM), convolutional layers, 2D attention mechanism                  | L1 loss, Root Mean Square Error (RMSE), Structural Similarity Index (SSIM)                                                                  | Pix2pix, Cycle-GAN, MC-GAN, Zi2zi, EMD                                                   | No                                      |
| [@DMFontFewShotCompositional2020]          | **DM-Font**            | DM-Font: Few-Shot Compositional Font Generation with Dual Memory                                               | 2020     | font completion, style transfer, interpolation                                      | raster images                          | Images of glyphs                                      | Dual memory-augmented structure                                                     | Sequential                                          | raster images   | Glyph images                                     | Component-wise encoded features                                   | Fixed persistent memory, dynamic memory                     | Korean-handwriting: 86 fonts, 2448 glyphs per font; Thai-printing: 105 fonts                                                                                                        | Korean-handwriting: Train 80% fonts, 90% glyphs; Thai-printing: similar split; Korean-unrefined for validation                                             | Korean-handwriting dataset (refined by expert designer), Korean-unrefined dataset, Thai-printing dataset     | Dual memory structure, compositional generator, self-attention, global-context block                                                    | Dual memory-augmented font generation network                       | Encoder: multi-head structure; Decoder: hourglass block, multi-task discriminator                  | SSIM, MS-SSIM, perceptual distance (PD), mean FID (mFID), human preference                                                                  | EMD, FUNIT, AGIS-Net                                                                     | No                                      |
| [@GANBasedUnpairedChinese2020]             | **TNet**               | GAN-Based Unpaired Chinese Character Image Translation via Skeleton Transformation and Stroke Rendering        | 2020     | style transfer                                                                      | raster images                          | Chinese character images                              | Skeleton extraction, GAN-based transformation and rendering                         | Sequential                                          | raster images   | Chinese character images                         | Skeleton and stroke style representation                          | Not specified                                               | StdFont-4: 6,700 characters per font, Calli-5: 1,200 characters per style                                                                                                           | Not specified                                                                                                                                              | StdFont-4, Calli-5                                                                                           | Three-stage GAN model, Skeleton extraction, Stroke rendering, Unpaired training data                                                    | GAN-based                                                           | Not specified                                                                                      | Style Error Rate (SER), Content Error Rate (CER), Intersection over Union (IoU), MS Accuracy                                                | Various GAN models, Pix2Pix, CycleGAN, StarGAN                                           | No                                      |
| [@JointFontGANJointGeometryContent2020]    | **JointFontGAN**       | Joint Geometry-Content GAN for Font Generation via Few-Shot Learning                                           | 2020     | style transfer                                                                      | raster images                          | Gray-scale glyph images                               | Multi-stream extended conditional GAN (XcGAN) models                                | Two-stream generative process                       | raster images   | Glyph images                                     | Font skeletons and glyph representations                          | Not specified                                               | 20K fonts with different styles                                                                                                                                                     | Not specified                                                                                                                                              | Collected datasets                                                                                           | Two-stream GAN, few-shot learning, skeleton and content consistency                                                                     | GAN                                                                 | Two-stream GAN                                                                                     | Structural similarity (SSIM), Mean Squared Error (MSE), L1 loss                                                                             | zi2zi, Glyph Network in MC-GAN                                                           | No                                      |
| [@NeuralStyleDifference2020]               | **NS-Diff**            | Neural Style Difference Transfer and Its Application to Font Generation.                                       | 2020     | style transfer, interpolation, font completion                                      | raster images                          | Font images                                           | Convolutional Neural Network (CNN)                                                  | Sequential                                          | raster images   | Font images                                      | Feature maps, Gram matrices                                       | Not specified                                               | Various combinations of input fonts                                                                                                                                                 | Not specified                                                                                                                                              | Not specified                                                                                                | Neural style transfer, Style difference loss, Content difference loss                                                                   | VGGNet                                                              | Multiple layers (conv1_2, conv2_2, conv3_2, conv4_2, conv5_2)                                      | Mean Squared Error (MSE)                                                                                                                    | NST, GAN-based methods                                                                   | No                                      |
| [@GlyphGANStyleconsistentFont2019]         | **GlyphGAN**           | Style-consistent font generation based on generative adversarial networks                                      | 2019     | style transfer, interpolation                                                       | raster images                          | Glyph images                                          | Deep convolutional GAN (DCGAN) architecture                                         | Sequential                                          | raster images   | Glyph images                                     | Character class vector, Style vector                              | Not specified                                               | 6,561 fonts, 26 uppercase alphabet letters                                                                                                                                          | Train: 90%, Test: 10% of 6,561 fonts                                                                                                                       | Self-collected from various sources                                                                          | Wasserstein GAN (WGAN), gradient penalty, DCGAN, character class and style vectors                                                      | DCGAN-based                                                         | Fractionally strided convolutions, strided convolutions in discriminator                           | Legibility (recognition accuracy), Diversity (pseudo-Hamming distance), Style consistency (Cs metric)                                       | DCGAN, WGAN-Clipping                                                                     | No                                      |
| [@AGISNetArtisticGlyph2019]                | **AGIS-Net**           | Artistic glyph image synthesis via one-stage few-shot learning                                                 | 2019     | style transfer, font completion                                                     | raster images                          | Glyph images                                          | Two encoders for content and style, collaborative decoders for shape and texture    | Sequential                                          | raster images   | Stylized glyph images                            | Disentangled content and style features                           | Not specified                                               | English: 32,046 synthetic artistic fonts, 35 professional-designed fonts; Chinese: 1,571,940 synthetic artistic glyphs, 256,410 glyphs from 35 professional fonts                   | Train: large-scale dataset for pre-training; Few-shot learning for fine-tuning with English (26 glyphs) and Chinese (7,326 glyphs)                         | Azadi et al. (2018), Guo et al. (2018), Jiang et al. (2017, 2019)                                            | Disentangled content and style, collaborative encoder-decoder architecture, local texture refinement loss                               | GAN (Generative Adversarial Network)                                | Six convolution layers and six up-convolution layers in the generator, three discriminators        | Inception Score (IS), Fréchet Inception Distance (FID), structural similarity (SSIM), pixel-level accuracy (pix-acc), user preference study | MC-GAN, TET-GAN, BicycleGAN, MS-Pix2Pix                                                  | No                                      |
| [@SVGVAELearnedRepresentation2019]         | **SVG-VAE**            | A Learned Representation for Scalable Vector Graphics                                                          | 2019     | reconstruction, font completion                                                     | vector paths                           | SVG commands                                          | Variational Autoencoder (VAE) with convolutional encoder                            | Autoregressive (LSTM)                               | vector paths    | SVG commands                                     | Latent vector z (32-dimensional)                                  | Smooth, semantically meaningful                             | 14M font characters                                                                                                                                                                 | Train: 12.6M characters, Test: 1.4M characters                                                                                                             | Google Fonts                                                                                                 | Convolutional VAE, Autoregressive SVG decoder, Mixture Density Network (MDN), UMAP visualization of latent space                        | VAE and LSTM-based                                                  | Convolutional layers for encoder and decoder, 4 stacked LSTM layers for SVG decoder                | Negative log-likelihood, Variance of latent space z                                                                                         | Qualitative assessments, Quantitative assessment using log-likelihood and variance       | No                                      |
| [@StructureGuidedChineseFont2019]          | **SCFont**             | Structure-Guided Chinese Font Generation via Deep Stacked Networks                                             | 2019     | style transfer, interpolation, font completion                                      | raster images                          | Glyph images                                          | Deep stacked networks with SkelNet and StyleNet                                     | Sequential                                          | raster images   | Glyph images                                     | Stroke category prior, Style embeddings                           | Not specified                                               | 70 Chinese font libraries with 6763 characters each                                                                                                                                 | Train: 6000 characters per font, Fine-tune: 775 characters per font                                                                                        | Self-collected and manually corrected strokes                                                                | Skeleton transformation network (SkelNet), Style rendering network (StyleNet), spatial feature transformation (SFT)                     | CNN-based                                                           | Contracting and expanding layers, residual blocks, deconvolution layers                            | L1 loss, IOU, user study, visual quality assessment (human judgement)                                                                       | pix2pix, DCFont, zi2zi, FontSL                                                           | No                                      |
| [@FontRNNGeneratingLargescale2019]         | **FontRNN**            | FontRNN: Generating Large-scale Chinese Fonts via Recurrent Neural Network                                     | 2019     | font completion, style transfer                                                     | sequence points, stroke skeletons      | Sequences of points, stroke skeletons                 | Sequence-to-sequence model with monotonic attention                                 | Sequential                                          | raster images   | Chinese character skeletons                      | Sequences of points                                               | Not specified                                               | 775 samples for optimal set, 2000 samples for handwriting trajectories                                                                                                              | Optimal set: 775 samples, Handwriting: 2000 samples                                                                                                        | Various Chinese font libraries, CASIA handwriting dataset                                                    | Monotonic attention mechanism, Long Short-Term Memory (LSTM), Sequence style transfer                                                   | RNN-based                                                           | Encoder with 256 neurons, Decoder with 256 neurons                                                 | DTW (Dynamic Time Warping), User study, Style classification accuracy, Content evaluation via VGG19                                         | pix2pix, DCFont, zi2zi, FontSL                                                           | No                                      |
| [@LearningStrokeBasedRepresentation2019]   | **StrokeRep**          | Learning A Stroke-Based Representation for Fonts                                                               | 2019     | interpolation, font completion                                                      | raster images                          | Glyph outlines, stroke-based representations          | Stroke-based geometric model, Bezier curves                                         | Not specified                                       | vector paths    | Vector glyphs                                    | Stroke-based template, Bezier curves                              | PCA, EM-PCA                                                 | 570 fonts                                                                                                                                                                           | Not specified                                                                                                                                              | Online font database                                                                                         | Stroke-based geometric model, PCA, EM-PCA                                                                                               | VAE                                                                 | Two fully connected layers of sizes 256 and 10                                                     | Fitting error, Interpolation quality, Qualitative analysis                                                                                  | Campbell and Kautz [CK14], Raster-based methods                                          | No                                      |
| [@HandwrittenChineseFont2019]              | **HCF-Gen**            | Handwritten Chinese Font Generation with Collaborative Stroke Refinement                                       | 2019     | style transfer                                                                      | raster images                          | 64x64 grayscale pixel images of glyphs                | CNN with encoder-decoder and collaborative stroke refinement                        | Not specified                                       | raster images   | 64x64 grayscale pixel images                     | Not explicitly specified                                          | Not specified                                               | 750 paired training samples                                                                                                                                                         | Train: 750 paired samples                                                                                                                                  | Not specified                                                                                                | Collaborative stroke refinement, online zoom-augmentation, adaptive pre-deformation                                                     | CNN                                                                 | Encoder-decoder with multiple convolution layers                                                   | RMSE, qualitative human evaluation, user study                                                                                              | HAN, EMD                                                                                 | No                                      |
| [@DeepFactorizationStyle2019]              | **DeepFactor**         | A Deep Factorization of Style and Structure in Fonts                                                           | 2019     | reconstruction, style transfer, interpolation                                       | raster images                          | Grayscale glyph images (64x64)                        | Variational Autoencoder (VAE)                                                       | Transpose Convolutional Process                     | raster images   | Grayscale glyph images (64x64)                   | Character embeddings and font latent variables                    | Not specified                                               | 10,682 fonts                                                                                                                                                                        | Train: 7,649 fonts, Dev: 1,473 fonts, Test: 1,560 fonts                                                                                                    | Capitals64 dataset                                                                                           | Deep matrix factorization, Gaussian prior, orthonormal DCT-II transformation                                                            | VAE                                                                 | Convolutional layers with transpose convolutions                                                   | L2 reconstruction error, human evaluation (AMT)                                                                                             | GlyphNet, nearest neighbors                                                              | No                                      |
| [@FontenderInteractiveJapanese2019]        | **Fontender**          | Fontender: Interactive Japanese Text Design with Dynamic Font Fusion Method for Comics                         | 2019     | font fusion, text design                                                            | raster images                          | Japanese font images                                  | Dynamic font fusion algorithm                                                       | Not specified                                       | raster images   | Blended font images                              | Core and thickness of fonts expressed mathematically              | Not specified                                               | 18 types of fonts evaluated by 17 participants                                                                                                                                      | Not specified                                                                                                                                              | Custom dataset (not specified)                                                                               | Dynamic font fusion, impression-based font selection                                                                                    | Not specified                                                       | Not specified                                                                                      | User satisfaction (Likert scale), qualitative comparison                                                                                    | Pull down interface, map interface without font fusion                                   | No                                      |
| [@EasyFontStyleLearningBased2018]          | **EasyFont**           | A Style Learning-Based System to Easily Build Your Large-Scale Handwriting Fonts                               | 2018     | style transfer, cross-modal: text-to-font, contour completion                       | raster images                          | Handwritten character images                          | Non-linear manifold with Gaussian Process Latent Variable Model (GP-LVM)            | Sequential                                          | raster images   | Synthesized handwriting fonts                    | Stroke skeleton representation                                    | Low-dimensional latent space                                | 27,533 Chinese characters for training, smaller subsets for testing                                                                                                                 | Train: multiple subsets (639, 266, 775 characters) for style learning and evaluation                                                                       | Manually created handwriting samples                                                                         | Stroke extraction, non-rigid point set registration, manifold learning                                                                  | GP-LVM, neural networks                                             | Not specified                                                                                      | MSE, R values, Turing tests                                                                                                                 | Comparison with Rewrite, pix2pix, zi2zi, NN-Fonts, NN-Manifold                           | Yes                                     |
| [@FontGANCreatingNew2018]                  | **FontGAN-MF**         | Creating New Chinese Fonts based on Manifold Learning and Adversarial Networks                                 | 2018     | style transfer, interpolation, contour completion                                   | raster images                          | Glyph images, stroke and shape vectors                | Convolutional neural networks (CNN) with manifold learning                          | Sequential                                          | raster images   | Chinese glyphs                                   | Skeleton and shape vectors                                        | Non-linear manifold (GP-LVM)                                | 72 font libraries, each with 2000 manually labeled characters                                                                                                                       | Train: 72 font libraries, 2000 characters each                                                                                                             | Manually labeled font libraries                                                                              | GAN-based image synthesis, non-rigid point set registration, manifold learning                                                          | CNN, GP-LVM                                                         | 7 convolution layers, 7 up-convolution layers                                                      | Pixel-wise loss, Adversarial loss, Qualitative analysis                                                                                     | Comparison with CK14, pix2pix                                                            | No                                      |
| [@LearningDrawVector2018]                  | **Draw-VG**            | Learning to draw vector graphics: Applying generative modeling to font glyph                                   | 2018     | font completion                                                                     | vector paths                           | SVG paths                                             | Variational Autoencoder (VAE)                                                       | Sequential                                          | vector paths    | SVG drawings                                     | Feature vectors for SVG commands                                  | Gaussian latent space                                       | 2,552 font faces, 877 font families                                                                                                                                                 | Train: 1920 SVGs per glyph, Test: 240 SVGs per glyph, Validation: 240 SVGs per glyph                                                                       | Google Fonts                                                                                                 | End-to-end pipeline, Variational Autoencoder, Bidirectional LSTM, GMM for pen coordinates, Feature encoding variants                    | Variational Autoencoder                                             | Dual RNNs with LSTM cells, Layer normalization, GMM in decoder                                     | Hausdorff Distance, Visual inspection                                                                                                       | Comparison with input images and random noise                                            | No                                      |
| [@TypefaceCompletionGenerative2018]        | **TypeCompGAN**        | Typeface Completion with Generative Adversarial Networks                                                       | 2018     | font completion                                                                     | raster images                          | Grayscale character images (128x128)                  | GAN (Typeface Completion Network - TCN)                                             | Generative                                          | raster images   | Grayscale character images (128x128)             | Typeface and content latent vectors                               | Not specified                                               | Chinese: 137,839 images, English: 23,583 images                                                                                                                                     | Train: Chinese: 96,426, English: 16,495; Val: Chinese: 13,776, English: 2,357; Test: Chinese: 27,637, English: 4,733                                       | Collected from TTF and OTF files                                                                             | Multi-domain image-to-image translation, SSIM loss, adversarial loss, perceptual reconstruction loss                                    | ResNet-based GAN                                                    | ResNet encoders, deconvolutional generator                                                         | SSIM, L1 distance, classification accuracy                                                                                                  | CycleGAN, MUNIT, StarGAN                                                                 | No                                      |
| [@FontStyleTransfer2018]                   | **FontStyle-DL**       | Font Style Transfer Using Deep Learning                                                                        | 2018     | style transfer                                                                      | raster images                          | Raster images of glyphs                               | Convolutional and fully-connected neural networks                                   | Sequential                                          | raster images   | Raster images                                    | Vector representation for output                                  | Not specified                                               | 1,839 fonts                                                                                                                                                                         | Not specified                                                                                                                                              | Not specified                                                                                                | Convolutional neural networks, Fully-connected neural networks, Generative adversarial networks (GAN), Image as function representation | Encoder-decoder, GAN                                                | Convolutional layers, Fully-connected layers                                                       | DSSIM, L1 loss                                                                                                                              | Not specified                                                                            | No                                      |
| [@MultiContentGANFewShot2017]              | **MC-GAN**             | Multi-Content GAN for Few-Shot Font Style Transfer                                                             | 2017     | font completion, style transfer                                                     | raster images                          | Partial glyph images in various styles                | Stacked conditional GAN with separate networks for glyph and ornamentation          | Sequential                                          | raster images   | Full glyph sets                                  | Glyph and ornamentation vectors                                   | Learned low-dimensional manifold                            | 10,000 fonts with different styles                                                                                                                                                  | Randomly selected subsets from each font for training and testing                                                                                          | Custom dataset created for the study                                                                         | End-to-end GAN pipeline, Conditional GANs, Ornamentation transfer network                                                               | cGAN, ResNet                                                        | Six ResNet blocks for each generator; LSGAN loss functions for discriminators                      | L1 loss, LSGAN loss, Perceptual evaluation via user study                                                                                   | Comparison with baseline glyph-outline inference network and text effect transfer method | No                                      |
| [@DCFontEndtoendDeep2017]                  | **DCFont**             | DCFont: An end-to-end deep Chinese font generation system                                                      | 2017     | font completion, style transfer                                                     | raster images                          | Handwritten character images                          | Convolutional neural network                                                        | Generative adversarial network (GAN)                | raster images   | GB2312 font library with 6763 Chinese characters | Deep font features                                                | Not specified                                               | 775 human-written characters plus 5988 machine-generated characters                                                                                                                 | Train: 775 human-written characters, Test: 5988 machine-generated characters                                                                               | Not specified                                                                                                | Font feature reconstruction network, Font style transfer network, Adversarial training                                                  | VGG16 and residual blocks                                           | 16-layer VGG for feature extraction, 5 residual blocks for style transfer                          | MSE loss for reconstruction, Adversarial loss for style transfer                                                                            | zi2zi, FontSL, Rewrite                                                                   | No                                      |
| [@Zi2ziMasterChinese2017]                  | **zi2zi**              | Zi2zi: Master Chinese Calligraphy with Conditional Adversarial Networks                                        | 2017     | style transfer                                                                      | raster images                          | Character images                                      | Conditional generative adversarial network (cGAN)                                   | Sequential                                          | raster images   | Character images                                 | Continuous embeddings                                             | Continuous latent space                                     | 27 different fonts, approximately 29,000 examples                                                                                                                                   | Train: 29,000 examples, Fine-tune: 2,000-4,000 characters per font                                                                                         | Various sources                                                                                              | Multi-class category loss, Continuous embeddings, Conditional GAN                                                                       | Encoder-Decoder with Unet                                           | Encoder: 8 layers (Conv, CIN, ReLU), Decoder: 8 layers (ConvT, CIN, ReLU)                          | Reconstruction loss, Adversarial loss, Category loss                                                                                        | Rewrite, DCFont, FontSL                                                                  | No                                      |
| [@SupervisedTransferStyle2016]             | **A2Z**                | From A to Z: Supervised Transfer of Style and Content Using Deep Neural Network Generators                     | 2016     | style transfer, interpolation, font completion                                      | raster images                          | Handwritten character images                          | Variational autoencoder (VAE)                                                       | Extrapolation, generative adversarial network (GAN) | raster images   | 62-letter fonts with known content and style     | Multivariate Gaussians                                            | Organized latent space, linear combinations of latent means | 1,839 fonts                                                                                                                                                                         | Train: 1,556 fonts, Val: 92 fonts, Test: 191 fonts                                                                                                         | openfontlibrary.org, Fonts used by [21]                                                                      | Extrapolation layer, SSIM cost function, Adversarial sub-networks, In-network and out-of-network image quality assessment               | Variational autoencoder (VAE)                                       | Two hidden layers with 500 nodes each, Multilayer perceptron as image generator                    | Mean DSSIM, Structured similarity objective (SSIM), Negative similarity as decoder loss                                                     | M2, Ours-SSIM, Ours-Adv                                                                  | No                                      |
| [@FontasticVoyageGenerative2016]           | **Fontastic**          | A Fontastic Voyage: Generative Fonts with Adversarial Networks                                                 | 2016     | reconstruction, interpolation                                                       | raster images                          | Grayscale font images (64x64 pixels)                  | Variational Autoencoder (VAE), Generative Adversarial Network (GAN)                 | GAN discriminator                                   | raster images   | Generated font images (64x64 pixels)             | Latent vectors                                                    | Latent space visualization                                  | 56,443 fonts                                                                                                                                                                        | Not specified                                                                                                                                              | Erik Bernhardsson’s fonts dataset                                                                            | VAE, GAN, Gaussian filtering                                                                                                            | Variational Autoencoder (VAE), Generative Adversarial Network (GAN) | Convolutional layers, GAN layers                                                                   | Visual inspection, qualitative analysis                                                                                                     | Not specified                                                                            | Not specified                           |
| [@AutomaticGenerationLargescale2016]       | **AGLH**               | Automatic generation of large-scale handwriting fonts via style learning                                       | 2016     | style transfer                                                                      | raster images                          | Handwritten samples, glyph images                     | Artificial Neural Networks (ANNs)                                                   | Vectorized                                          | raster images   | Handwritten fonts                                | Trajectories, stroke shape and layout differences                 | Not specified                                               | 87 billion Chinese characters in dataset; MinSet: 266 characters, OptSet: 775 characters                                                                                            | Train: not specified, Test: not specified                                                                                                                  | Personal handwriting samples collected through a web application                                             | Artificial Neural Networks (ANNs), stroke trajectory extraction, style learning and synthesis, Coherent Point Drift (CPD) registration  | Feed-forward Neural Network (FFNN)                                  | 1 hidden layer, 40 units in input, hidden, and output layers                                       | Turing tests with 69 participants, accuracy of distinguishing machine-generated from original handwritings                                  | FlexyFont, FounderType, HAND, Lake et al. (2015)                                         | No                                      |
| [@LearningTransferringRules2015]           | **FlexyFont**          | Learning Transferring Rules for Flexible Typeface Synthesis                                                    | 2015     | font completion, interpolation                                                      | vector paths                           | Outline-based glyphs                                  | Stroke-based representation, Part-Similarity Vector (PSV)                           | Part assembly                                       | vector paths    | Complete typefaces                               | Similarity vectors for parts                                      | Bayesian Gaussian Process Latent Variable Model (BGPLVM)    | 88 training fonts for uppercase, 57 training fonts for lowercase                                                                                                                    | 60% training, 40% testing                                                                                                                                  | Public font dataset                                                                                          | Decomposition of glyphs into semantic parts, part assembly approach, Bayesian Gaussian Process Latent Variable Model (BGPLVM)           | Generative probabilistic model                                      | BGPLVM with mixture density model                                                                  | Similarity between reconstructed parts and reference parts, t-test, visual comparison                                                       | Compared with Suveeranont and Igarashi (2010)                                            | No                                      |
| [@LearningManifoldFonts2014]               | **Font-MF**            | Learning a manifold of fonts                                                                                   | 2014     | interpolation, style transfer                                                       | vector paths                           | Vector outlines of glyphs                             | Gaussian Process Latent Variable Model (GP-LVM)                                     | Parametric                                          | vector paths    | Font outlines                                    | High dimensional outline vectors                                  | Low dimensional manifold (latent space)                     | 46 fonts                                                                                                                                                                            | Not specified                                                                                                                                              | Google Fonts                                                                                                 | Energy-based optimization, Dense character matching, Coarse-to-fine approach, GP-LVM                                                    | Gaussian Process Latent Variable Model (GP-LVM)                     | Not specified                                                                                      | Qualitative visual inspection, Chamfer distance                                                                                             | Not specified                                                                            | No                                      |
| [@EasyGenerationPersonal2011]              | **EasyHandFonts**      | Easy generation of personal Chinese handwritten fonts                                                          | 2011     | reconstruction                                                                      | raster images                          | Handwritten character images                          | Chinese Character Radical Composition Model                                         | Not specified                                       | raster images   | Handwritten character images                     | Not explicitly specified                                          | Not specified                                               | 522 characters for input samples, 2,500 characters in the output set                                                                                                                | Input: 522 characters, Output: 2,500 characters                                                                                                            | Not specified                                                                                                | Radical reuse, contour curve-based radical clustering, segmentation and construction of characters                                      | Not specified                                                       | Not specified                                                                                      | Qualitative comparison with original handwritten fonts                                                                                      | Not specified                                                                            | No                                      |
| [@ExampleBasedAutomaticFont2010]           | **EFG**                | Example-Based Automatic Font Generation                                                                        | 2010     | font completion, style transfer                                                     | vector paths                           | Single character outline                              | Weighted blend of outlines and skeletons                                            | Parametric                                          | vector paths    | Complete font set                                | Morphable font model with blending weights                        | Not specified                                               | 32 template fonts representing various styles                                                                                                                                       | Not specified                                                                                                                                              | Not specified                                                                                                | Skin-skeleton model, Blending weights, Gradient descent optimization                                                                    | Not specified                                                       | Not specified                                                                                      | Qualitative visual inspection, User study                                                                                                   | Not specified                                                                            | No                                      |
| [@ParamFontParameterizableFonts2001]       | **ParamFont**          | Parameterizable fonts based on shape components                                                                | 2001     | interpolation, style transfer                                                       | vector paths                           | Vector outlines of glyphs                             | Shape components with global, group, and local parameters                           | Parametric                                          | vector paths    | Font outlines                                    | Component-based with parameterizable geometric shapes             | Not specified                                               | Not specified (component-based fonts)                                                                                                                                               | Not specified                                                                                                                                              | Not specified                                                                                                | Shape components, Parameterizable geometric shapes, Global and local parameters                                                         | Not specified                                                       | Not specified                                                                                      | Qualitative visual inspection, Parameter variation study                                                                                    | Not specified                                                                            | Yes                                     |

